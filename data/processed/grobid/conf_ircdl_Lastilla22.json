{"bibliography":{"title":"Enhancement of Scribal Hands Identification Via Self-Supervised Learning (Extended Abstract)","authors":[{"person_name":{"surname":"Lastilla","first_name":"Lorenzo"},"affiliations":[{"department":"Department of Computer, Control and Management Engineering Antonio Ruberti","institution":"Sapienza University of Rome","laboratory":null}],"email":"lorenzo.lastilla@uniroma1.it"}],"date":null,"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"keywords":["Handwriting identification","Self-supervised learning","Medieval and modern manuscripts"],"citations":{"b0":{"title":"Modeling Medieval Handwriting: A New Approach to Digital Palaeography","authors":[{"person_name":{"surname":"Stokes","first_name":"P"},"affiliations":[],"email":null}],"date":{"year":"2012","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":382,"to_page":385}}},"b1":{"title":"Digital Approaches to Paleography and Book History: Some Challenges, Present and Future","authors":[{"person_name":{"surname":"Stokes","first_name":"P"},"affiliations":[],"email":null}],"date":{"year":"2015","month":null,"day":null},"ids":{"DOI":"10.3389/fdigh.2015.00005","arXiv":null},"target":"https://www.frontiersin.org/article/10.3389/fdigh.2015.00005.doi:10.3389/fdigh.2015.00005","publisher":null,"journal":"Frontiers in Digital Humanities","series":null,"scope":{"volume":2,"pages":{"from_page":5,"to_page":5}}},"b2":{"title":"Writer identification and script classification: two tasks for a common understanding of cultural heritage","authors":[{"person_name":{"surname":"Stutzmann","first_name":"D"},"affiliations":[],"email":null},{"person_name":{"surname":"Tensmeyer","first_name":"C"},"affiliations":[],"email":null},{"person_name":{"surname":"Christlein","first_name":"V"},"affiliations":[],"email":null}],"date":{"year":"2018","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"OpenX for Interdisciplinary Computational Manuscript Research","series":null,"scope":{"volume":null,"pages":{"from_page":12,"to_page":15}}},"b3":{"title":"Case study: Fine writing style classification using siamese neural network","authors":[{"person_name":{"surname":"Abdalhaleem","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Barakat","first_name":"B"},"affiliations":[],"email":null},{"person_name":{"surname":"El-Sana","first_name":"J"},"affiliations":[],"email":null}],"date":{"year":"2018","month":null,"day":null},"ids":null,"target":null,"publisher":"IEEE","journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":62,"to_page":66}}},"b4":{"title":"Writing Style Invariant Deep Learning Model for Historical Manuscripts Alignment","authors":[{"person_name":{"surname":"Kassis","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Nassour","first_name":"J"},"affiliations":[],"email":null},{"person_name":{"surname":"El-Sana","first_name":"J"},"affiliations":[],"email":null}],"date":{"year":"2018","month":null,"day":null},"ids":{"DOI":null,"arXiv":"arXiv:1806.03987"},"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"b5":{"title":"Papy-S-Net: A Siamese Network to match papyrus fragments","authors":[{"person_name":{"surname":"Pirrone","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Aimar","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Journet","first_name":"N"},"affiliations":[],"email":null}],"date":{"year":"2019","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":78,"to_page":83}}},"b6":{"title":"An end-to-end deep learning system for medieval writer identification","authors":[{"person_name":{"surname":"Cilia","first_name":"N"},"affiliations":[],"email":null},{"person_name":{"surname":"De Stefano","first_name":"C"},"affiliations":[],"email":null},{"person_name":{"surname":"Fontanella","first_name":"F"},"affiliations":[],"email":null},{"person_name":{"surname":"Marrocco","first_name":"C"},"affiliations":[],"email":null},{"person_name":{"surname":"Molinara","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Scotto","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Freca","first_name":"Di"},"affiliations":[],"email":null}],"date":{"year":"2020","month":null,"day":null},"ids":{"DOI":"10.1016/j.patrec.2019.11.025","arXiv":null},"target":"https://doi.org/10.1016/j.patrec.2019.11.025","publisher":null,"journal":"Pattern Recognition Letters","series":null,"scope":{"volume":129,"pages":{"from_page":137,"to_page":143}}},"b7":{"title":"Biblioteca Apostolica Vaticana, Website of the Biblioteca Apostolica Vaticana","authors":[],"date":{"year":"2021","month":null,"day":null},"ids":null,"target":"https://www.vaticanlibrary.va/en/","publisher":null,"journal":null,"series":null,"scope":null},"b8":{"title":"Big Self-Supervised Models are Strong Semi-Supervised Learners","authors":[{"person_name":{"surname":"Chen","first_name":"T"},"affiliations":[],"email":null},{"person_name":{"surname":"Kornblith","first_name":"S"},"affiliations":[],"email":null},{"person_name":{"surname":"Swersky","first_name":"K"},"affiliations":[],"email":null},{"person_name":{"surname":"Norouzi","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Hinton","first_name":"G"},"affiliations":[],"email":null}],"date":{"year":"2020","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"Advances in Neural Information Processing Systems","series":null,"scope":{"volume":33,"pages":{"from_page":22243,"to_page":22255}}},"b9":{"title":"Bootstrap your own latent: A new approach to self-supervised learning","authors":[{"person_name":{"surname":"Grill","first_name":"J.-B"},"affiliations":[],"email":null},{"person_name":{"surname":"Strub","first_name":"F"},"affiliations":[],"email":null},{"person_name":{"surname":"Altché","first_name":"F"},"affiliations":[],"email":null},{"person_name":{"surname":"Tallec","first_name":"C"},"affiliations":[],"email":null},{"person_name":{"surname":"Richemond","first_name":"P"},"affiliations":[],"email":null},{"person_name":{"surname":"Buchatskaya","first_name":"E"},"affiliations":[],"email":null},{"person_name":{"surname":"Doersch","first_name":"C"},"affiliations":[],"email":null},{"person_name":{"surname":"Pires","first_name":"B"},"affiliations":[],"email":null},{"person_name":{"surname":"Guo","first_name":"Z"},"affiliations":[],"email":null},{"person_name":{"surname":"Azar","first_name":"M"},"affiliations":[],"email":null}],"date":{"year":"2020","month":null,"day":null},"ids":{"DOI":null,"arXiv":"arXiv:2006.07733"},"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"b10":{"title":"Learning Representations by Maximizing Mutual Information Across Views","authors":[{"person_name":{"surname":"Bachman","first_name":"P"},"affiliations":[],"email":null},{"person_name":{"surname":"Hjelm","first_name":"R"},"affiliations":[],"email":null},{"person_name":{"surname":"Buchwalter","first_name":"W"},"affiliations":[],"email":null}],"date":{"year":"2019","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"Advances in Neural Information Processing Systems","series":null,"scope":{"volume":32,"pages":{"from_page":15535,"to_page":15545}}},"b11":{"title":"A framework for contrastive self-supervised learning and designing a new approach","authors":[{"person_name":{"surname":"Falcon","first_name":"W"},"affiliations":[],"email":null},{"person_name":{"surname":"Cho","first_name":"K"},"affiliations":[],"email":null}],"date":{"year":"2020","month":null,"day":null},"ids":{"DOI":null,"arXiv":"arXiv:2009.00104"},"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"b12":{"title":"Momentum contrast for unsupervised visual representation learning","authors":[{"person_name":{"surname":"He","first_name":"K"},"affiliations":[],"email":null},{"person_name":{"surname":"Fan","first_name":"H"},"affiliations":[],"email":null},{"person_name":{"surname":"Wu","first_name":"Y"},"affiliations":[],"email":null},{"person_name":{"surname":"Xie","first_name":"S"},"affiliations":[],"email":null},{"person_name":{"surname":"Girshick","first_name":"R"},"affiliations":[],"email":null}],"date":{"year":"2020","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":9729,"to_page":9738}}},"b13":{"title":"Representation learning with contrastive predictive coding","authors":[{"person_name":{"surname":"Oord","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Li","first_name":"Y"},"affiliations":[],"email":null},{"person_name":{"surname":"Vinyals","first_name":"O"},"affiliations":[],"email":null}],"date":{"year":"2018","month":null,"day":null},"ids":{"DOI":null,"arXiv":"arXiv:1807.03748"},"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"b14":{"title":"Learning representations by predicting bags of visual words","authors":[{"person_name":{"surname":"Gidaris","first_name":"S"},"affiliations":[],"email":null},{"person_name":{"surname":"Bursuc","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Komodakis","first_name":"N"},"affiliations":[],"email":null},{"person_name":{"surname":"Pérez","first_name":"P"},"affiliations":[],"email":null},{"person_name":{"surname":"Cord","first_name":"M"},"affiliations":[],"email":null}],"date":{"year":"2020","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":6928,"to_page":6938}}},"b15":{"title":"Unsupervised Learning of Visual Features by Contrasting Cluster Assignments","authors":[{"person_name":{"surname":"Caron","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Misra","first_name":"I"},"affiliations":[],"email":null},{"person_name":{"surname":"Mairal","first_name":"J"},"affiliations":[],"email":null},{"person_name":{"surname":"Goyal","first_name":"P"},"affiliations":[],"email":null},{"person_name":{"surname":"Bojanowski","first_name":"P"},"affiliations":[],"email":null},{"person_name":{"surname":"Joulin","first_name":"A"},"affiliations":[],"email":null}],"date":{"year":"2020","month":null,"day":null},"ids":null,"target":"https://proceedings.neurips.cc/paper/2020/file/70feb62b69f16e0238f741fab228fec2-Paper.pdf","publisher":"Curran Associates, Inc","journal":null,"series":"Advances in Neural Information Processing Systems","scope":{"volume":33,"pages":{"from_page":9912,"to_page":9924}}},"b16":{"title":"Barlow twins: Self-supervised learning via redundancy reduction","authors":[{"person_name":{"surname":"Zbontar","first_name":"J"},"affiliations":[],"email":null},{"person_name":{"surname":"Jing","first_name":"L"},"affiliations":[],"email":null},{"person_name":{"surname":"Misra","first_name":"I"},"affiliations":[],"email":null},{"person_name":{"surname":"Lecun","first_name":"Y"},"affiliations":[],"email":null},{"person_name":{"surname":"Deny","first_name":"S"},"affiliations":[],"email":null}],"date":{"year":"2021","month":null,"day":null},"ids":{"DOI":null,"arXiv":"arXiv:2103.03230"},"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"b17":{"title":"Online bag-of-visual-words generation for unsupervised representation learning","authors":[{"person_name":{"surname":"Gidaris","first_name":"S"},"affiliations":[],"email":null},{"person_name":{"surname":"Bursuc","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Puy","first_name":"G"},"affiliations":[],"email":null},{"person_name":{"surname":"Komodakis","first_name":"N"},"affiliations":[],"email":null},{"person_name":{"surname":"Cord","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Pérez","first_name":"P"},"affiliations":[],"email":null}],"date":{"year":"2020","month":null,"day":null},"ids":{"DOI":null,"arXiv":"arXiv:2012.11552"},"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"b18":{"title":"Distance metric learning for large margin nearest neighbor classification","authors":[{"person_name":{"surname":"Weinberger","first_name":"K"},"affiliations":[],"email":null},{"person_name":{"surname":"Saul","first_name":"L"},"affiliations":[],"email":null}],"date":{"year":"2009","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"Journal of machine learning research","series":null,"scope":{"volume":10,"pages":null}},"b19":{"title":"Facenet: A unified embedding for face recognition and clustering","authors":[{"person_name":{"surname":"Schroff","first_name":"F"},"affiliations":[],"email":null},{"person_name":{"surname":"Kalenichenko","first_name":"D"},"affiliations":[],"email":null},{"person_name":{"surname":"Philbin","first_name":"J"},"affiliations":[],"email":null}],"date":{"year":"2015","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":815,"to_page":823}}},"b20":{"title":"Imagenet large scale visual recognition challenge","authors":[{"person_name":{"surname":"Russakovsky","first_name":"O"},"affiliations":[],"email":null},{"person_name":{"surname":"Deng","first_name":"J"},"affiliations":[],"email":null},{"person_name":{"surname":"Su","first_name":"H"},"affiliations":[],"email":null},{"person_name":{"surname":"Krause","first_name":"J"},"affiliations":[],"email":null},{"person_name":{"surname":"Satheesh","first_name":"S"},"affiliations":[],"email":null},{"person_name":{"surname":"Ma","first_name":"S"},"affiliations":[],"email":null},{"person_name":{"surname":"Huang","first_name":"Z"},"affiliations":[],"email":null},{"person_name":{"surname":"Karpathy","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Khosla","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Bernstein","first_name":"M"},"affiliations":[],"email":null}],"date":{"year":"2015","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"International journal of computer vision","series":null,"scope":{"volume":115,"pages":{"from_page":211,"to_page":252}}},"b21":{"title":"Paleografia latina. Tavole","authors":[{"person_name":{"surname":"Cherubini","first_name":"P"},"affiliations":[],"email":null},{"person_name":{"surname":"Pratesi","first_name":"A"},"affiliations":[],"email":null}],"date":{"year":"2004","month":null,"day":null},"ids":null,"target":null,"publisher":"Diplomatica e Archivistica","journal":null,"series":null,"scope":{"volume":1,"pages":null}},"b22":{"title":"Paleografia latina. L'avventura grafica del mondo occidentale, Littera Antiqua","authors":[{"person_name":{"surname":"Cherubini","first_name":"P"},"affiliations":[],"email":null},{"person_name":{"surname":"Pratesi","first_name":"A"},"affiliations":[],"email":null}],"date":{"year":"2010","month":null,"day":null},"ids":null,"target":null,"publisher":"Scuola Vaticana di Paleografia, Diplomatica e Archivistica","journal":null,"series":null,"scope":{"volume":16,"pages":null}},"b23":{"title":"The Oxford Handbook of Latin Palaeography","authors":[{"person_name":{"surname":"Coulson","first_name":"F"},"affiliations":[],"email":null},{"person_name":{"surname":"Babcock","first_name":"R"},"affiliations":[],"email":null}],"date":{"year":"2020","month":null,"day":null},"ids":null,"target":null,"publisher":"Oxford University Press","journal":null,"series":null,"scope":null},"b24":{"title":"Deep Residual Learning for Image Recognition","authors":[{"person_name":{"surname":"He","first_name":"K"},"affiliations":[],"email":null},{"person_name":{"surname":"Zhang","first_name":"X"},"affiliations":[],"email":null},{"person_name":{"surname":"Ren","first_name":"S"},"affiliations":[],"email":null},{"person_name":{"surname":"Sun","first_name":"J"},"affiliations":[],"email":null}],"date":{"year":"2016","month":null,"day":null},"ids":{"DOI":"10.1109/CVPR.2016.90","arXiv":null},"target":null,"publisher":null,"journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":770,"to_page":778}}},"b25":{"title":"In defense of the triplet loss for person re-identification","authors":[{"person_name":{"surname":"Hermans","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Beyer","first_name":"L"},"affiliations":[],"email":null},{"person_name":{"surname":"Leibe","first_name":"B"},"affiliations":[],"email":null}],"date":{"year":"2017","month":null,"day":null},"ids":{"DOI":null,"arXiv":"arXiv:1703.07737"},"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"b26":{"title":"Triplet Loss and Online Triplet Mining in TensorFlow","authors":[{"person_name":{"surname":"Moindrot","first_name":"Olivier"},"affiliations":[],"email":null}],"date":{"year":"2018","month":null,"day":null},"ids":null,"target":"https://omoindrot.github.io/triplet-loss","publisher":null,"journal":null,"series":null,"scope":null},"b27":{"title":"Fully Convolutional Networks for Semantic Segmentation","authors":[{"person_name":{"surname":"Shelhamer","first_name":"E"},"affiliations":[],"email":null},{"person_name":{"surname":"Long","first_name":"J"},"affiliations":[],"email":null},{"person_name":{"surname":"Darrell","first_name":"T"},"affiliations":[],"email":null}],"date":{"year":"2017","month":null,"day":null},"ids":{"DOI":"10.1109/TPAMI.2016.2572683","arXiv":null},"target":null,"publisher":null,"journal":"IEEE Transactions on Pattern Analysis and Machine Intelligence","series":null,"scope":{"volume":39,"pages":{"from_page":640,"to_page":651}}},"b28":{"title":"Visualizing data using t-SNE","authors":[{"person_name":{"surname":"Van Der Maaten","first_name":"L"},"affiliations":[],"email":null},{"person_name":{"surname":"Hinton","first_name":"G"},"affiliations":[],"email":null}],"date":{"year":"2008","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"Journal of machine learning research","series":null,"scope":{"volume":9,"pages":null}},"b29":{"title":"Explaining Self-Supervised Image Representations with Visual Probing","authors":[{"person_name":{"surname":"Basaj","first_name":"D"},"affiliations":[],"email":null},{"person_name":{"surname":"Oleszkiewicz","first_name":"W"},"affiliations":[],"email":null},{"person_name":{"surname":"Sieradzki","first_name":"I"},"affiliations":[],"email":null},{"person_name":{"surname":"Górszczak","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Rychalska","first_name":"B"},"affiliations":[],"email":null},{"person_name":{"surname":"Trzcinski","first_name":"T"},"affiliations":[],"email":null},{"person_name":{"surname":"Zieliński","first_name":"B"},"affiliations":[],"email":null}],"date":{"year":"2021","month":null,"day":null},"ids":{"DOI":"10.24963/ijcai.2021/82","arXiv":null},"target":"https://doi.org/10.24963/ijcai.2021/82.doi:10.24963/ijcai.2021/82,mainTrack","publisher":null,"journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":592,"to_page":598}}},"b30":{"title":"Scribal Attribution across Multiple Scripts: A Digitally Aided Approach","authors":[{"person_name":{"surname":"Stokes","first_name":"P"},"affiliations":[],"email":null}],"date":{"year":"2017","month":null,"day":null},"ids":{"DOI":"10.1086/693968","arXiv":null},"target":"https://doi.org/10.1086/693968.doi:10.1086/693968","publisher":null,"journal":"Speculum","series":null,"scope":{"volume":92,"pages":null}}},"sections":[{"title":"Introduction and related works","paragraphs":[{"text":"In recent years, the long-standing issue of automatic handwriting identification (HI) -the subdivision of the texts into parts belonging to distinct scribes on the basis of the respective handwriting style -has been discussed both from a theoretical perspective [1,2,3] and an application point of view. Despite the increasing use of deep learning techniques to address this problem [4,5,6,7], HI continues to be carried out with traditional methods by paleographers, due to the costs, time and expertise required for data labeling.","refs":[{"start":262,"end":265,"marker":"bibr","target":"#b0"},{"start":265,"end":267,"marker":"bibr","target":"#b1"},{"start":267,"end":269,"marker":"bibr","target":"#b2"},{"start":383,"end":386,"marker":"bibr","target":"#b3"},{"start":386,"end":388,"marker":"bibr","target":"#b4"},{"start":388,"end":390,"marker":"bibr","target":"#b5"},{"start":390,"end":392,"marker":"bibr","target":"#b6"}]},{"text":"This work highlights the benefits of using a self-supervised learning (SSL) approach for the HI task on medieval and modern manuscripts (more precisely, a set of 24 digitized manuscripts selected from the Vatican Apostolic Library [8]), the vastness of which is considerable, even if most of the manuscript pages are not annotated with the information of the copyist who physically wrote them. SSL, indeed, is gradually taking hold to address the problem of learning good image representations from a few labeled examples while making best use of many unlabeled instances [9,10], which would minimize the dependence on potentially costly corpora of manually annotated data [11], and makes this strategy ideal for the HI task. In particular, SSL methods try to solve a \"pretext task\" (which is not of genuine interest) to learn -from unlabeled data -representations that can be transferred to other tasks of actual interest (the \"downstream tasks\"), which often have only a few labeled instances [12,13,14,15,16,17].","refs":[{"start":231,"end":234,"marker":"bibr","target":"#b7"},{"start":572,"end":575,"marker":"bibr","target":"#b8"},{"start":575,"end":578,"marker":"bibr","target":"#b9"},{"start":673,"end":677,"marker":"bibr","target":"#b10"},{"start":995,"end":999,"marker":"bibr","target":"#b11"},{"start":999,"end":1002,"marker":"bibr","target":"#b12"},{"start":1002,"end":1005,"marker":"bibr","target":"#b13"},{"start":1005,"end":1008,"marker":"bibr","target":"#b14"},{"start":1008,"end":1011,"marker":"bibr","target":"#b15"},{"start":1011,"end":1014,"marker":"bibr","target":"#b16"}]},{"text":"In practice, the proposed methodology consists of two main stages. First, all the pages contained in the manuscripts undergo the Online Bag-of-Visual-Words (OBoW) reconstructionbased SSL approach described in [15,18]. Then, the available copyists are split into a background set and an evaluation set (whose samples are never seen during training nor validation), and a linear layer is trained on top of the frozen base encoder, with the aim of minimizing a triplet margin loss [19,20]. The results obtained show that the visual representations learned in a self-supervised fashion outperform the ImageNet [21] ones with respect to the HI task, as well as the features learned after training the backbone model from scratch, also in terms of generalization power.","refs":[{"start":209,"end":213,"marker":"bibr","target":"#b14"},{"start":213,"end":216,"marker":"bibr","target":"#b17"},{"start":478,"end":482,"marker":"bibr","target":"#b18"},{"start":482,"end":485,"marker":"bibr","target":"#b19"},{"start":606,"end":610,"marker":"bibr","target":"#b20"}]}]},{"title":"Case study","paragraphs":[{"text":"24 high-resolution digital manuscripts, included among the tables for Latin paleography exercises published by the Vatican Apostolic Library in 2004 [22], which collect very recognizable graphic types [23,24], were selected from [8], obtaining a final corpus of 8745 pages and 27 scribes (identified in 9 manuscripts only -Vatt. latt. 4220 and 4221 share the same set of 8 copyists). The selected manuscripts, together with the number of available copyists and the century of realization, are recalled in Table 1.","refs":[{"start":149,"end":153,"marker":"bibr","target":"#b21"},{"start":201,"end":205,"marker":"bibr","target":"#b22"},{"start":205,"end":208,"marker":"bibr","target":"#b23"},{"start":229,"end":232,"marker":"bibr","target":"#b7"},{"start":511,"end":512,"marker":"table","target":"#tab_0"}]},{"text":"Starting from the overall group of selected pages, two different datasets were created: as to the pretext task, the 8745 samples -organized in 24 classes -were randomly split into training, validation and test sets according to the ratio 0.8-0.15-0.05. For the handwriting identification task, instead, only the annotated pages were selected. The available copyists were split into an evaluation set (consisting of the 4 scribes from Vat. lat. 653, excluded from the training and validation stages of this task) and a background set (including the 23 remaining scribes). ","refs":[]}]},{"title":"Methodology and results","paragraphs":[{"text":"The SSL strategy adopted in this work can be summarized as follows: a CNN-based feature extractor (or student network -a ResNet18-based encoder [25]) is trained to predict, with unlabeled data only, the BoW representation of a 380 × 380 random crop of a manuscript page given as input a set of perturbed crops of that page [18]. The BoW representation is generated by a momentum-updated teacher network, which receives as input the 380 × 380 random crop. The set of perturbed crops, instead, is obtained through several augmentations, including radiometric perturbations, Gaussian blur, random erasing, and mild geometric distortions.","refs":[{"start":144,"end":148,"marker":"bibr","target":"#b24"},{"start":323,"end":327,"marker":"bibr","target":"#b17"}]},{"text":"Once self-supervised pretraining is completed, the frozen features of the student encoder are involved in the HI task, based on the minimization of a triplet margin loss, which can be seen as learning a distance function useful for discriminating instances belonging to different classes in the embedding space. At this stage, a linear layer only, added to backbone model, is trained to extract more powerful representations with respect to the task of interest. The triplets are generated through an online batch-hard triplet mining strategy, which is the optimal configuration for this kind of task [26,27]. As to the pairwise distance function involved in the loss computation, the 𝐿 2 norm was chosen. The downstream task was carried out based on two mutually exclusive data augmentation schemes. Scheme A) is based on the extraction of a random 380 × 380 crop from the page and the application of a similar set of perturbations as the pretext task; scheme B), instead, extends the same set of perturbations to the whole page: consequently, the encoder -which receives as input a page of arbitrary size -operates as a \"fully convolutional\" network [28]. In Figure 1, a schematic representation of both the self-supervised pretraining stage and the handwriting identification task is provided.","refs":[{"start":601,"end":605,"marker":"bibr","target":"#b25"},{"start":605,"end":608,"marker":"bibr","target":"#b26"},{"start":1152,"end":1156,"marker":"bibr","target":"#b27"},{"start":1168,"end":1169,"marker":"figure","target":"#fig_0"}]},{"text":"All the experiments were carried out using a Tesla V100 SXM2 32GB GPU, and involved a ResNet18-based architecture. The source code used for the experiments is available at https://github.com/L9L4/HI-SSL. As to the BoW reconstruction task, the student encoder was trained for 100 epochs; the batch size was fixed to 64; finally, Stochastic Gradient Descent (SGD) was adopted, with learning rate set to 0.03 and progressively adjusted up to the final value of 0.00003 through a cosine scheduler with an initial warmup of 5 epochs.","refs":[]},{"text":"As to the HI task, it was faced based on both the augmentation schemes A) and B), considering 3 different configurations (and thus ending up with 6 tests in total): a linear layer was trained on top of the frozen backbone model pretrained with OBoW; a linear layer was trained on top of the ImageNet frozen features (also in this case, a ResNet18 backbone encoder -but pretrained on the ImageNet dataset -was used); a model initialized with random weights (but characterized by the same architecture as the other two cases) was fully trained from scratch directly on the downstream task. For all the 6 tests, the output dimension of the linear layer (embedding width) was fixed to 1024, while the margin 𝑚 of the triplet margin loss was set to 0.2 [20]. The model was trained for 100 epochs with SGD optimization: the learning rate, starting from 0.15, was increased up to 0.6 through a linear warmup for the first 10 epochs, and then decayed with a cosine annealing up to 0.0015. The batch size was set to 256 for the tests carried out under scheme A), and to 32 for scheme B). To quantitatively assess the performance of the single tests for the HI task, the Mean Average Precision (MAP) was computed. In Table 2, the results obtained for each test in terms of MAP are shown. It is immediately evident that the SSL-based approach is far more effective for the task of interest than the baselines, under both the A) and B) data augmentation schemes. This is true, indeed, both for the background scribes and for the evaluation ones, used to test the generalization capacity of the model, achieving a MAP of 74.8% for the background set, obtained under the B) scheme, and of 79.0% for the evaluation set -A) scheme. In Figures 2a and2b, it is possible to visualize the 2D projection of the embeddings of the manuscript pages for the best results obtained among the 6 tests, both for the background and the evaluation set (together with the respective cluster centroids), after dimensionality reduction through the t-SNE technique [29]. Figures 2a and2b are particularly helpful to appreciate the capability of the proposed framework of effectively performing the HI task, even for manuscripts excluded from training. This seems to suggest the possibility of extending the approach to any non-annotated manuscript, which could be partitioned through zero-shot learning. Figure 2a is also useful, however, to highlight the limitations of the proposed approach, showing the difficulties in properly clustering some scribes coming from very specific manuscripts (Vatt. latt. 4217 -scribes 5-7 in Figure 2a -, 4220 and 4221 -scribes 8-15), which constitute a particularly complex subset, since the copyists who realized them aimed for the maximum handwriting  uniformity. Hence, the representations extracted from the model, generally sufficient for the other manuscripts, might have been unsuitable to grasp the set of discriminating elements valid for this subgroup.","refs":[{"start":748,"end":752,"marker":"bibr","target":"#b19"},{"start":1213,"end":1214,"marker":"table","target":"#tab_2"},{"start":1727,"end":1729,"marker":"figure","target":"#fig_2"},{"start":1733,"end":1735,"marker":"figure","target":"#fig_2"},{"start":2030,"end":2034,"marker":"bibr","target":"#b28"},{"start":2044,"end":2046,"marker":"figure","target":"#fig_2"},{"start":2050,"end":2052,"marker":"figure","target":"#fig_2"},{"start":2376,"end":2378,"marker":"figure","target":"#fig_2"},{"start":2599,"end":2601,"marker":"figure","target":"#fig_2"}]}]},{"title":"Conclusion","paragraphs":[{"text":"In this paper, the task of automatic HI for ancient manuscripts was addressed in the face of the scarcity of large and annotated datasets, and the first empirical validation of the SSL framework in the medieval and modern manuscript domain was provided, assessing its capability to learn effective visual representations from a large amount of raw data and then to build a solid starting point for the task of interest, which can be performed based on just a few labeled samples, and with higher precision. The proposed approach was compared with (and outperformed, also from a generalization point of view) two common setups, namely the network initialization with general-domain (ImageNet) features, and training the full model from scratch. Regarding possible future developments, an explainability analysis of the methodology could be carried out [30]; moreover, the subset of scribes whose identification was most difficult could be analyzed in order to determine the necessary adjustments to the model to extract useful features even in complex cases like this; then, a broader experimental setup could be investigated; finally, a solution to tackle the problem of multigraphism could be included in the methodology [31].","refs":[{"start":851,"end":855,"marker":"bibr","target":"#b29"},{"start":1222,"end":1226,"marker":"bibr","target":"#b30"}]}]}],"tables":{"tab_0":{"heading":"Table 1","description":"Number of copyists and century of realization of the 24 selected manuscripts.","rows":[["Manuscript"]]},"tab_1":{"heading":"ID Number of copyists Century Manuscript ID Number of copyists Century","description":"","rows":[["Vat. lat. 12910","0","XI","Vat. lat. 4939","0","XII"],["Vat. lat. 2669","0","XIII","Vat. lat. 4958","0","XI"],["Vat. lat. 3313","0","IX","Vat. lat. 4965","2","IX"],["Vat. lat. 3317","0","X","Vat. lat. 5775","0","IX"],["Vat. lat. 378","3","XI","Vat. lat. 579","0","XI"],["Vat. lat. 3833","0","XII","Vat. lat. 588","0","XIV"],["Vat. lat. 3868","0","IX","Vat. lat. 5951","3","IX"],["Vat. lat. 42","0","XII","Vat. lat. 620","0","XII"],["Vat. lat. 4217","3","XI","Vat. lat. 653","4","XI"],["Vat. lat. 4220","8 *","XVI","Vat. lat. 8487","2","XI"],["Vat. lat. 4221","8 *","XVI","Vat. lat. 907","2","XIII"],["Vat. lat. 43","0","IX","Vat. lat. 9882","0","IX"]]},"tab_2":{"heading":"Table 2","description":"Performance obtained for the HI task for the 6 tests, with respect to the MAP metric.","rows":[["Mode","Scheme MAP [%] -Background set MAP [%] -Evaluation set"],["OBoW pretraining","B)","74.8*","72.0"],["ImageNet pretraining","B)","69.7","64.9"],["Training from scratch","B)","60.8","58.8"],["OBoW pretraining","A)","71.7","79.0*"],["ImageNet pretraining","A)","63.7","67.5"],["Training from scratch","A)","48.5","59.1"]]}},"abstract":{"title":"Abstract","paragraphs":[{"text":"In this paper, the first successful application of the recent framework of self-supervised learning to the problem of handwriting identification for medieval and modern manuscripts is presented. To this end, a novel dataset consisting of both labeled and unlabeled manuscripts extracted from the Vatican Apostolic Library was produced. Moreover, this contribution shows that pretraining a convolutional neural network by leveraging large amounts of unlabeled manuscripts and fine-tuning this model to the task of interest significantly outperforms other baselines, including the common setup of initializing the network from general-domain features, or training the model from scratch, also in terms of generalization power. Overall, these results reveal the strong potential of self-supervised techniques in the field of digital paleography, where unlabeled data is nowadays available, while labeled data is scarcer.","refs":[]}]}}