{"bibliography":{"title":"In Codice Ratio: Machine Transcription of Medieval Manuscripts","authors":[{"person_name":{"surname":"Ammirati","first_name":"Serena"},"affiliations":[{"department":"Department of Humanities","institution":"Roma Tre University","laboratory":null}],"email":"serena.ammirati@uniroma3.it"},{"person_name":{"surname":"Firmani","first_name":"Donatella"},"affiliations":[{"department":"Department of Computer Science","institution":"Roma Tre University","laboratory":null}],"email":"donatella.firmani@uniroma3.it"},{"person_name":{"surname":"Maiorino","first_name":"Marco"},"affiliations":[{"department":null,"institution":"Vatican Secret Archives","laboratory":null}],"email":"m.maiorino@asv.va"},{"person_name":{"surname":"Merialdo","first_name":"Paolo"},"affiliations":[{"department":"Department of Computer Science","institution":"Roma Tre University","laboratory":null}],"email":"paolo.merialdo@uniroma3.it"},{"person_name":{"surname":"Nieddu","first_name":"Elena"},"affiliations":[{"department":"Department of Computer Science","institution":"Roma Tre University","laboratory":null}],"email":"elena.nieddu@uniroma3.it"}],"date":null,"ids":{"DOI":"10.1007/978-3-030-11226-4_15","arXiv":null},"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"keywords":[],"citations":{"b0":{"title":"In codice ratio: scalable transcription of historical handwritten documents","authors":[{"person_name":{"surname":"Firmani","first_name":"S"},"affiliations":[],"email":null},{"person_name":{"surname":"Maiorino","first_name":"D"},"affiliations":[],"email":null},{"person_name":{"surname":"Merialdo","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Nieddu","first_name":"P"},"affiliations":[],"email":null},{"person_name":{"surname":"Rossi","first_name":"E"},"affiliations":[],"email":null}],"date":{"year":"2017","month":"06","day":"29"},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":65,"to_page":65}}},"b1":{"title":"Many hands make light work. Many hands together make merry work': transcribe Bentham and crowdsourcing manuscript collections","authors":[{"person_name":{"surname":"Causer","first_name":"T"},"affiliations":[],"email":null},{"person_name":{"surname":"Terras","first_name":"M"},"affiliations":[],"email":null}],"date":{"year":"2014","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":57,"to_page":88}}},"b2":{"title":"A comparison of string distance metrics for name-matching tasks","authors":[{"person_name":{"surname":"Cohen","first_name":"W"},"affiliations":[],"email":null},{"person_name":{"surname":"Ravikumar","first_name":"P"},"affiliations":[],"email":null},{"person_name":{"surname":"Fienberg","first_name":"S"},"affiliations":[],"email":null}],"date":{"year":"2003","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":73,"to_page":78}}},"b3":{"title":"Towards knowledge discovery from the Vatican secret archives. In codice ratio -episode 1: machine transcription of the manuscripts","authors":[{"person_name":{"surname":"Firmani","first_name":"D"},"affiliations":[],"email":null},{"person_name":{"surname":"Maiorino","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Merialdo","first_name":"P"},"affiliations":[],"email":null},{"person_name":{"surname":"Nieddu","first_name":"E"},"affiliations":[],"email":null}],"date":{"year":"2018","month":"08","day":"23"},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":263,"to_page":272}}},"b4":{"title":"In codice ratio: OCR of handwritten Latin documents using deep convolutional networks","authors":[{"person_name":{"surname":"Firmani","first_name":"D"},"affiliations":[],"email":null},{"person_name":{"surname":"Merialdo","first_name":"P"},"affiliations":[],"email":null},{"person_name":{"surname":"Nieddu","first_name":"E"},"affiliations":[],"email":null},{"person_name":{"surname":"Scardapane","first_name":"S"},"affiliations":[],"email":null}],"date":{"year":"2017","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"b5":{"title":"Automatic transcription of handwritten medieval documents","authors":[{"person_name":{"surname":"Fischer","first_name":"A"},"affiliations":[],"email":null}],"date":{"year":"2009","month":null,"day":null},"ids":null,"target":null,"publisher":"IEEE","journal":null,"series":null,"scope":null},"b6":{"title":"Research methods in the age of digital journalism: massivescale automated analysis of news-content-topics, style and gender","authors":[{"person_name":{"surname":"Flaounas","first_name":"I"},"affiliations":[],"email":null}],"date":{"year":"2013","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"Digit. J","series":null,"scope":{"volume":1,"pages":{"from_page":102,"to_page":116}}},"b7":{"title":"Multi-language online handwriting recognition","authors":[{"person_name":{"surname":"Keysers","first_name":"D"},"affiliations":[],"email":null},{"person_name":{"surname":"Deselaers","first_name":"T"},"affiliations":[],"email":null},{"person_name":{"surname":"Rowley","first_name":"H"},"affiliations":[],"email":null},{"person_name":{"surname":"Wang","first_name":"L.-L"},"affiliations":[],"email":null},{"person_name":{"surname":"Carbune","first_name":"V"},"affiliations":[],"email":null}],"date":{"year":"2017","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"IEEE Trans. Pattern Anal. Mach. Intell","series":null,"scope":{"volume":39,"pages":{"from_page":1180,"to_page":1194}}},"b8":{"title":"Character-aware neural language models","authors":[{"person_name":{"surname":"Kim","first_name":"Y"},"affiliations":[],"email":null},{"person_name":{"surname":"Jernite","first_name":"Y"},"affiliations":[],"email":null},{"person_name":{"surname":"Sontag","first_name":"D"},"affiliations":[],"email":null},{"person_name":{"surname":"Rush","first_name":"A"},"affiliations":[],"email":null}],"date":{"year":"2016","month":null,"day":null},"ids":null,"target":null,"publisher":"AAAI Press","journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":2741,"to_page":2749}}},"b9":{"title":"Text line segmentation of historical documents: a survey","authors":[{"person_name":{"surname":"Likforman-Sulem","first_name":"L"},"affiliations":[],"email":null},{"person_name":{"surname":"Zahour","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Taconet","first_name":"B"},"affiliations":[],"email":null}],"date":{"year":"2007","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"Int. J. Doc. Anal. Recogn","series":null,"scope":{"volume":9,"pages":{"from_page":123,"to_page":138}}},"b10":{"title":"ICDAR 2015 competition on keyword spotting for handwritten documents","authors":[{"person_name":{"surname":"Puigcerver","first_name":"J"},"affiliations":[],"email":null},{"person_name":{"surname":"Toselli","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Vidal","first_name":"E"},"affiliations":[],"email":null}],"date":{"year":"2015","month":null,"day":null},"ids":null,"target":null,"publisher":"IEEE","journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":1176,"to_page":1180}}},"b11":{"title":"tranScriptorium: a European project on handwritten text recognition","authors":[{"person_name":{"surname":"Sánchez","first_name":"J"},"affiliations":[],"email":null}],"date":{"year":"2013","month":null,"day":null},"ids":null,"target":null,"publisher":"ACM","journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":227,"to_page":228}}},"b12":{"title":"ICFHR 2014 competition on handwritten text recognition on tranScriptorium datasets (HTRtS)","authors":[{"person_name":{"surname":"Sánchez","first_name":"J"},"affiliations":[],"email":null},{"person_name":{"surname":"Romero","first_name":"V"},"affiliations":[],"email":null},{"person_name":{"surname":"Toselli","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Vidal","first_name":"E"},"affiliations":[],"email":null}],"date":{"year":"2014","month":null,"day":null},"ids":null,"target":null,"publisher":"IEEE","journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":785,"to_page":790}}},"b13":{"title":"PHOCNet: a deep convolutional neural network for word spotting in handwritten documents","authors":[{"person_name":{"surname":"Sudholt","first_name":"S"},"affiliations":[],"email":null},{"person_name":{"surname":"Fink","first_name":"G"},"affiliations":[],"email":null}],"date":{"year":"2016","month":null,"day":null},"ids":null,"target":null,"publisher":"IEEE","journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":277,"to_page":282}}}},"sections":[{"title":"Introduction","paragraphs":[{"text":"The research project In Codice Ratio has the goal of supporting humanities scholars in the content analysis and knowledge discovery activities on large collections of historical documents. Thanks to novel methods and tools that we aim at developing, paleographers, philologists and historians will be able to conduct data-driven studies at a large scale by quantitatively analyzing trends and evolution of writings and languages across time and countries, and by examining and discovering facts and correlations among information spread in vast corpora of documents. Our project concentrates on the collections preserved in the Vatican Secret Archives (VSA), one of the largest and most important historical archives in the world. In an extension of 85 km of shelving, it maintains more than 600 archival collections of historical sources on the Vatican activities -such as, official correspondence of the Vatican, account books, correspondence of the popes -starting from the end of the eighth century. We are currently working on the collection of the Vatican Registers, which record the inbound and outbound correspondence of the popes. A small sample is shown in Fig. 1. These registers have been continuously and systematically preserved since the middle age, hence most of these documents are manuscripts. The VSA has begun to acquire digital images of these documents but, unfortunately, complete transcriptions for the earliest registers do not exist. Therefore, a first fundamental step to develop any form of data-driven content analysis is to perform a transcription of the manuscripts. The problem is challenging: on the one hand, a manual transcription is unfeasible (at least in a reasonable amount of time), due to the volume (hundreds of thousands of pages) of the collection. On the other hand, although these manuscripts are written with a uniform style (a derivation of the Caroline style), traditional OCR does not apply here, because of irregularities of hand-writing, ligatures and abbreviations. Since segmenting words in characters is tricky with handwritten texts, recent automatic transcription approaches typically aim at recognizing entire words. However, because of the variability and the size of the lexicon, they need a huge amount of training data, i.e., hundreds of fully transcribed pages. To illustrate this problem, consider Fig. 2: it reports the distribution of the occurrences of words in a corpus composed by a partial transcription of the Registers of Innocent III (in total, it is about 68,000 words). Observe that a few words (just 9) occur more than 100 times (the most occurring word is \"et\", the Latin conjunction that corresponds to \"and\"), while the majority of words have less than 10 occurrences.","refs":[{"start":1172,"end":1173,"marker":"figure","target":"#fig_0"},{"start":2367,"end":2368,"marker":"figure","target":"#fig_1"}]},{"text":"We follow a different approach, based on character segmentation. Our idea is to govern imprecise character segmentation by considering that correct segments are those that give rise to a sequence of characters that more likely compose a Latin word. We have therefore designed a principled solution that relies on a convolutional neural network classifier and on statistical language models. For every word, we perform a segmentation that can produce more segments than those actually formed by the characters in the word. Every segment is labeled by a classifier, which essentially recognizes the most likely character. We then organize the sequence of segments in a directed acyclic graph: the paths of such a graph represent candidate transcriptions for the word, and the most likely solution is selected based on language statistics. Structure of this Paper. Section 2 contains an overview of our approach. Detailed description of our algorithms can be found in [4]. Main experimental results of [4] are reported in Sect. 3. Finally, Sects. 4 and 5 contain related work and concluding remarks. In Codice Ratio was introduced in [1]. All the code and data of the project is publicly online.1 2 Overview Fig. 3. A typical input image for our system.","refs":[{"start":965,"end":968,"marker":"bibr","target":"#b3"},{"start":999,"end":1002,"marker":"bibr","target":"#b3"},{"start":1131,"end":1134,"marker":"bibr","target":"#b0"},{"start":1192,"end":1193,"marker":null,"target":"#foot_0"},{"start":1210,"end":1211,"marker":"figure","target":null}]},{"text":"We start from a set of high-quality scanned images of whole manuscript pages. Each page undergoes three standard preprocessing steps:","refs":[]},{"text":"1. we transform the color image into a bi-chromatic one and crop white margins; 2. we correct skew and slant, i.e., page distortions due to acquisition process and calligraphy; 3. we crop lines and words according to horizontal and vertical white spaces, respectively.","refs":[]},{"text":"Each word image is finally submitted to our transcription system. Figure 3 shows a pre-processed word image, of size 178 × 67 pixels. The correct transcription of the word in the figure is the Latin word \"culpam\" -the accusative singular of \"culpa\", that means \"crime\". System Architecture. Our pipeline consists of four main components.","refs":[{"start":73,"end":74,"marker":"figure","target":null}]},{"text":"-Training samples collector. We implemented a custom crowd-sourcing platform, and employed 120 high-school students to label the dataset. To overcome the complexity of reading ancient fonts, we provided the students with positive and negative examples of each symbol. We trained a deep convolutional neural network character classifier on this dataset. -Character recognizer. Recognizing characters within a handwritten word is challenging, due to ligatures. To this end, we first partition the input word into elementary text segments. Most segments contain actual characters, but there are also segments with spurious ink strokes. Then, we submit all the segments to the trained classifier. Computed labels are very accurate when the input segment contains an actual character, but can be wrong otherwise. We take into account minuscule characters of the Latin alphabet. -Transcription generator. We reassemble noisy labels from the classifier into a set of candidate word transcriptions. Specifically, we select the best m candidate transcriptions for the input word image, using language models. -Word decoder. We consider the m transcriptions from the previous step and revise character recognition decisions in a principled way, by solving a specific decoding problem on a high-order hidden Markov model. The most promising transcriptions are finally returned to the user.","refs":[]},{"text":"Discussion. It is worth noting that compared to a segmentation-free approach, training the classifier requires labeled examples for the limited set of character symbols, with a twofold advantage. First, the size of the training set is several order of magnitude smaller, as we need to provide examples only for the limited set of character symbols, and not for a rich lexicon of words. Second, producing the examples is much easier, as it does not require to transcribe whole words, an activity that can be carried on by expert paleographers. In our system, the production of the training set is accomplished by a crowdsourcing solution that consists of simple visual pattern matching tasks, similar to captchas.","refs":[]}]},{"title":"Experiments","paragraphs":[{"text":"For our experiments we use annotations from 2 pages of Vatican Register 12. This results in approximately 15K characters. Characters with less than 1K examples were augmented to match the required quantity and balance the training set. The augmentation process involves slight random rotation, zooming, shearing and shifting, both vertical and horizontal. The final dataset comprises 23K examples evenly split between 23 classes. We test our system on four pages belonging to the same Vatican Register, but spanning different ages and writers, transcribed entirely by volunteer paleographers. After undergoing the pre-processing, each word is transcribed independently by the system. Our system currently considers only word images without abbreviated forms. This is further discussed in Sect. 5. Our language model is composed of 716 ancient Roman Latin texts, spanning different ages and subjects, for a total of over 14M words. It is worth observing that the Latin language used in the Vatican Registers exhibits some differences with the ancient Roman Latin, which is typically used in publicly available corpora. These differences introduce some drawbacks, that we are currently overcoming, as we discuss later in Sect. 5. Set-Up. We define the m-precision as the fraction of word images in our test set, for which the correct transcription is (i) generated by our system, and (ii) ranked in the top m positions. Classical definition of precision is captured by 1-precision. For the top few transcriptions, we provide edit distance statistics (ED) with respect to the correct transcription. Specifically, we use the distance metric in [3]. Our experiments are summarized below.","refs":[{"start":1640,"end":1643,"marker":"bibr","target":"#b2"}]},{"text":"Results. In the character recognition step, average precision and recall of our neural network among all classes are both 96%. Precision ranges from 86% to 99%, whereas recall ranges from 74% to 99%. As frame of comparison, we trained a logistic regression model on the same dataset. Such baseline scored 80% and 79% average precision and recall. More results on this are in [5].","refs":[{"start":375,"end":378,"marker":"bibr","target":"#b4"}]},{"text":"In the transcription generation step, the fraction of words for which our system yields the correct transcription is ≈65% (decoding can recover the correct transcription of approximately 9% of the remaining 35%), compared to much lower 20% achieved by the baseline in [1]. When the correct transcription is available, language models can rank the correct transcription of almost all the word images in the top 5. For remaining 35%, 16% of first-ranked transcriptions is at edit distance 1 from the correct transcription, 15% at distance 2 and 28% at distance 3. Figure 4 shows a sample word image of the 15% group, for which the first-ranked transcription is at distance 2 from the correct transcription. The purple bars in Fig. 5 show the 1-precision and 3-precision of our system for different q-gram sizes in the language model. The bar labeled as \"NoLM\" shows ranking results obtained without taking language models into account. The NoLM ranking was produced by multiplying network classification scores for each character. Figure 5b considers top 3 transcriptions of all the word images in the test set. We observe that, by using 6-g, almost 80% of our results are away from correct transcriptions by no more than 2 characters, and approximately 60% corresponds exactly to the underlying manuscript word. Figure 5a reports the corresponding results when considering only top 1 transcriptions. Another way for reading results in Fig. 5a is the following. Consider the 65% of the word images in our dataset for which we generate the correct transcription. Approximately 77% of the word images have the correct transcription ranked at position 1 when using 6-g (which is our default setting), but approximately 23% does not get the optimal ranking. Correct transcription, when generated, is in the top 5 for almost all the word images. Improving on the ranking produced requires a better model of the language used in the Vatican Register, included models of sentences, and is discussed in Sect. 5.","refs":[{"start":268,"end":271,"marker":"bibr","target":"#b0"},{"start":569,"end":570,"marker":"figure","target":"#fig_2"},{"start":729,"end":730,"marker":"figure","target":"#fig_3"},{"start":1036,"end":1038,"marker":"figure","target":"#fig_3"},{"start":1318,"end":1320,"marker":"figure","target":"#fig_3"},{"start":1439,"end":1441,"marker":"figure","target":"#fig_3"},{"start":1999,"end":2000,"marker":"bibr","target":"#b4"}]},{"text":"Consider now the 35% of word images for which our system does not generate the correct transcription is approximately. 2 Decoding can recover the correct transcription of approximately 9% of such word images. Other effects of the decoding phase is that top-ranked transcriptions become closer to correct transcriptions. For instance, the amount of word images having correct transcription ranked as increases by 30%. Overall, the amount of word images having correct transcription ranked as first does not change significantly.","refs":[{"start":119,"end":120,"marker":null,"target":"#foot_1"}]}]},{"title":"Related Works","paragraphs":[{"text":"Handwritten Text Recognition (or HTR) is a research topic concerning the automatic transcription of handwritten text. Even though it extends to live-captured handwriting (online recognition), that is clearly not the case for historical documents. Offline recognition is generally regarded as harder than the online, due to the lack of temporal information: online handwriting recognition can leverage the and timing of character strokes, while offline recognition cannot. Due to the many challenges involved in a fully automatic transcription system of historical handwritten documents, many researchers in the last years have focused on solving sub-problems, including word spotting [11], and text line segmentation [10]. Our goal is rather the creation of a full-fledged off-line HTR system: an effort shared by several ongoing projects, as more and more libraries and archives worldwide digitize their collections [7,13]. These systems generally work by a segmentation-free approach, where it is not necessary to individually segment each character. To deal effectively with ambiguity in segmentation and transcription, we map each word image to a lattice, whose source-to-sink paths represent alternative segmentations and corresponding transcriptions. Our approach is close to the technique in [8].","refs":[{"start":684,"end":688,"marker":"bibr","target":"#b10"},{"start":717,"end":721,"marker":"bibr","target":"#b9"},{"start":917,"end":920,"marker":"bibr","target":"#b6"},{"start":920,"end":923,"marker":"bibr","target":"#b12"},{"start":1299,"end":1302,"marker":"bibr","target":"#b7"}]},{"text":"Crowdsourcing. Crowdsourcing solution for cultural heritage has been experienced in many projects. One of the pioneering initiative to crowdsource the transcription of manuscripts is the Transcribe Bentham project, a collaborative platform for crowdsourcing the transcription of the philosopher Jeremy Bentham's unpublished manuscripts [2]. Also the Transcriptorium project [12] exposes HTR tools through specialized crowd-sourcing web portals, supporting collaborative work. Our solution is more focused than the above ones: since it aims at producing training data, it relies on a much simpler solution based on visual pattern matching task that can be performed by unskilled workers. Neural Networks. Our approach employs a convolutional neural network for character image classification. There has been an interest in applying recent results in recurrent and convolutional neural networks to achieve improved classification accuracy: [14] performs word spotting through a deep convolutional neural network, outperforming various word spotting benchmarks; while [6] adopts a bidirectional Long Short-Term Memory neural network to transcribe at word level, with high accuracy. In order to achieve complete transcriptions, these approaches would need thousands of word-level annotations, which is not a scalable task due to the expertise required. We will come back on this point when discussing future research directions for our project. Data science can deeply contribute to analyze and understand our historical and cultural heritage. Data acquisition and preparation from manuscript historical documents is done by means of a transcription process, whose scalability is limited, as it must be performed by expert paleographers. In this paper, we have presented a system, developed in the context of the In Codice Ratio project, to support the transcription of medieval manuscripts in order to improve the scalability of the process. We have followed an original approach that requires minimal training effort, and that is able to produce correct transcriptions for large portions of the manuscripts. Our approach, which relies on word segmentation, neural convolutional network, and language models, has been successfully experimented on the Vatican Registers.","refs":[{"start":336,"end":339,"marker":"bibr","target":"#b1"},{"start":374,"end":378,"marker":"bibr","target":"#b11"},{"start":938,"end":942,"marker":"bibr","target":"#b13"},{"start":1065,"end":1068,"marker":"bibr","target":"#b5"}]}]},{"title":"Conclusions and Work","paragraphs":[{"text":"We are currently working on the system in order to extend the set of symbols, and hence to improve the overall effectiveness of the process. In particular, we are adding the most frequent abbreviations, i.e., short-hands used by the scribes to save room or to speed up writing. In our process, the main issue with abbreviations is the lack of statistics on their occurrences, which prevents us to effectively apply the language models. Gathering statistics for the abbreviation is not trivial: the usage of these symbols depends both on the age and on the domain of the manuscripts. For instance, in the Vatican Registers, which have diplomatic and legal contents, some abbreviations are more frequent than in manuscripts with of literary works, even from the same age. Indeed, we have already collected training samples for the classifier also for many abbreviations: our crowdsourcing approach to collect labeled examples worked well also for these symbols, as it is based on simple visual pattern matching tasks. Figure 6 shows an example of a one of the most frequent abbreviations. The last symbol, in black, is a shorthand for the Latin desinence \"rum\": notice that it is simple, given some sample images, to recognize it also without any paleography knowledge. Also the neural network performs well with the extended set of symbols, as abbreviations are typically well distinguishable from other symbols.","refs":[{"start":1023,"end":1024,"marker":"figure","target":"#fig_4"}]},{"text":"Our plan to collect statistics for the abbreviations is to use our current system to produce partial transcriptions for a number of pages, a few dozens, highlighting the words where the character classifier recognizes an abbreviation. Then, we will ask to the paleographers to transcribe these words. Based on these semiautomatic transcriptions, we will progressively update the language models. So far, we took a probabilistic approach on language modeling: we plan, however, to investigate character-level neural language modeling, similarly to [9].","refs":[{"start":547,"end":550,"marker":"bibr","target":"#b8"}]}]}],"tables":{},"abstract":{"title":"Abstract","paragraphs":[{"text":"Our project, In Codice Ratio, is an interdisciplinary research initiative for analyzing content of historical documents conserved in the Vatican Secret Archives (VSA). As most of such documents are digitized as images, Machine Transcription is both an enabler to the application of Knowledge Discovery techniques, as well as a useful tool to the paleographer for speeding up the transcription process. Our approach involves a convolutional neural network to recognize characters, statistical language models to compose and rank word transcriptions, and crowdsourcing for scalable training data collection. We have conducted experiments on pages from the medieval manuscript collection known as the Vatican Registers. Our results show that almost all the considered words can be transcribed without significant spelling errors.","refs":[]}]}}