{"bibliography":{"title":"Storybook: A Tool for the Semi-automatic Creation of Book Trailers","authors":[{"person_name":{"surname":"Bernasconi","first_name":"Eleonora"},"affiliations":[{"department":"Department of Computer, Control, and Management Engineering Antonio Ruberti (DIAG)","institution":"Sapienza Universit√† di Roma","laboratory":null}],"email":"bernasconi@diag.uniroma1.it"},{"person_name":{"surname":"Ceriani","first_name":"Miguel"},"affiliations":[{"department":"Department of Computer Science Via Edoardo Orabona","institution":"Universit√† degli Studi di Bari Aldo Moro","laboratory":null}],"email":"miguel.ceriani@uniba.it"},{"person_name":{"surname":"De Luzi","first_name":"Francesca"},"affiliations":[{"department":"Department of Computer, Control, and Management Engineering Antonio Ruberti (DIAG)","institution":"Sapienza Universit√† di Roma","laboratory":null}],"email":"deluzi@diag.uniroma1.it"},{"person_name":{"surname":"Sapio","first_name":"Francesco"},"affiliations":[{"department":"Department of Computer, Control, and Management Engineering Antonio Ruberti (DIAG)","institution":"Sapienza Universit√† di Roma","laboratory":null}],"email":"sapio@diag.uniroma1.it"},{"person_name":{"surname":"Mecella","first_name":"Massimo"},"affiliations":[{"department":"Department of Computer, Control, and Management Engineering Antonio Ruberti (DIAG)","institution":"Sapienza Universit√† di Roma","laboratory":null}],"email":"mecella@diag.uniroma1.it"}],"date":null,"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"keywords":["Digital library","Knowledge extraction","Storytelling"],"citations":{"b0":{"title":"Modern communication technologies in education: book trailer","authors":[{"person_name":{"surname":"Nikonova","first_name":"N"},"affiliations":[],"email":null},{"person_name":{"surname":"Zalutskaya","first_name":"S"},"affiliations":[],"email":null}],"date":{"year":"2021","month":null,"day":null},"ids":{"DOI":"10.20952/revtee.v14i33.15256","arXiv":null},"target":"http://dx.doi.org/10.20952/revtee.v14i33.15256.doi:10.20952/revtee.v14i33.15256","publisher":null,"journal":"Revista Tempos e Espa√ßos em Educa√ß√£o","series":null,"scope":{"volume":14,"pages":null}},"b1":{"title":"Book trailer as a means of motivating younger schoolchildren to read","authors":[{"person_name":{"surname":"Barnych","first_name":"O"},"affiliations":[],"email":null},{"person_name":{"surname":"Naidon","first_name":"K"},"affiliations":[],"email":null},{"person_name":{"surname":"Mamchych","first_name":"O"},"affiliations":[],"email":null}],"date":{"year":"2021","month":null,"day":null},"ids":{"DOI":"10.31392/npu-nc.series5.2021.79.1.41","arXiv":null},"target":"http://dx.doi.org/10.31392/npu-nc.series5.2021.79.1.41.doi:10.31392/npu-nc.series","publisher":null,"journal":"Pedagogical sciences reality and perspectives","series":null,"scope":{"volume":1,"pages":{"from_page":192,"to_page":196}}},"b2":{"title":"The book trailer as a publishing house promotional tool","authors":[{"person_name":{"surname":"Jim√©nez-Mar√≠n","first_name":"G"},"affiliations":[],"email":null},{"person_name":{"surname":"Zambrano","first_name":"R"},"affiliations":[],"email":null}],"date":{"year":"2020","month":null,"day":null},"ids":{"DOI":"10.4018/978-1-7998-3119-8.ch011","arXiv":null},"target":"http://dx.doi.org/10.4018/978-1-7998-3119-8.ch011.doi:10.4018/978-1-7998-3119-8.ch011","publisher":null,"journal":"Advances in Business Strategy and Competitive Advantage","series":null,"scope":{"volume":null,"pages":{"from_page":147,"to_page":160}}},"b3":{"title":"Digital storytelling and digital book trailer applications for educational purposes in bulgaria","authors":[{"person_name":{"surname":"Luchev","first_name":"D"},"affiliations":[],"email":null},{"person_name":{"surname":"Paneva-Marinova","first_name":"D"},"affiliations":[],"email":null},{"person_name":{"surname":"Dimova","first_name":"M"},"affiliations":[],"email":null}],"date":{"year":"2019","month":null,"day":null},"ids":{"DOI":"10.21125/inted.2019.0211","arXiv":null},"target":"http://dx.doi.org/10.21125/inted.2019.0211.doi:10.21125/inted.2019.0211","publisher":null,"journal":null,"series":null,"scope":null},"b4":{"title":"Narrative visualization: Telling stories with data","authors":[{"person_name":{"surname":"Segel","first_name":"E"},"affiliations":[],"email":null},{"person_name":{"surname":"Heer","first_name":"J"},"affiliations":[],"email":null}],"date":{"year":"2010","month":null,"day":null},"ids":{"DOI":"10.1109/tvcg.2010.179","arXiv":null},"target":"http://dx.doi.org/10.1109/tvcg.2010.179.doi:10.1109/tvcg.2010.179,432cites","publisher":null,"journal":"IEEE Transactions on Visualization and Computer Graphics","series":null,"scope":{"volume":16,"pages":{"from_page":1139,"to_page":1148}}},"b5":{"title":"Storytelling and visualization: An extended survey","authors":[{"person_name":{"surname":"Tong","first_name":"C"},"affiliations":[],"email":null},{"person_name":{"surname":"Roberts","first_name":"R"},"affiliations":[],"email":null},{"person_name":{"surname":"Borgo","first_name":"R"},"affiliations":[],"email":null},{"person_name":{"surname":"Walton","first_name":"S"},"affiliations":[],"email":null},{"person_name":{"surname":"Laramee","first_name":"R"},"affiliations":[],"email":null},{"person_name":{"surname":"Wegba","first_name":"K"},"affiliations":[],"email":null},{"person_name":{"surname":"Lu","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Wang","first_name":"Y"},"affiliations":[],"email":null},{"person_name":{"surname":"Qu","first_name":"H"},"affiliations":[],"email":null},{"person_name":{"surname":"Luo","first_name":"Q"},"affiliations":[],"email":null},{"person_name":{"surname":"Ma","first_name":"X"},"affiliations":[],"email":null}],"date":{"year":"2018","month":null,"day":null},"ids":{"DOI":"10.3390/info9030065","arXiv":null},"target":"http://dx.doi.org/10.3390/info9030065.doi:10.3390/info9030065,25cites","publisher":null,"journal":"Information","series":null,"scope":{"volume":9,"pages":{"from_page":65,"to_page":65}}},"b6":{"title":"Datashot: Automatic generation of fact sheets from tabular data","authors":[{"person_name":{"surname":"Wang","first_name":"Y"},"affiliations":[],"email":null},{"person_name":{"surname":"Sun","first_name":"Z"},"affiliations":[],"email":null},{"person_name":{"surname":"Zhang","first_name":"H"},"affiliations":[],"email":null},{"person_name":{"surname":"Cui","first_name":"W"},"affiliations":[],"email":null},{"person_name":{"surname":"Xu","first_name":"K"},"affiliations":[],"email":null},{"person_name":{"surname":"Ma","first_name":"X"},"affiliations":[],"email":null},{"person_name":{"surname":"Zhang","first_name":"D"},"affiliations":[],"email":null}],"date":{"year":"2019","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"IEEE transactions on visualization and computer graphics","series":null,"scope":{"volume":26,"pages":{"from_page":895,"to_page":905}}},"b7":{"title":"Authoring narrative visualizations with ellipsis","authors":[{"person_name":{"surname":"Satyanarayan","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Heer","first_name":"J"},"affiliations":[],"email":null}],"date":{"year":"2014","month":null,"day":null},"ids":{"DOI":"10.1111/cgf.12392","arXiv":null},"target":"http://dx.doi.org/10.1111/cgf.12392.doi:10.1111/cgf.12392,42cites","publisher":null,"journal":"Computer Graphics Forum","series":null,"scope":{"volume":33,"pages":{"from_page":361,"to_page":370}}},"b8":{"title":"Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems","authors":[{"person_name":{"surname":"Wang","first_name":"Y"},"affiliations":[],"email":null},{"person_name":{"surname":"Zhang","first_name":"H"},"affiliations":[],"email":null},{"person_name":{"surname":"Huang","first_name":"H"},"affiliations":[],"email":null},{"person_name":{"surname":"Chen","first_name":"X"},"affiliations":[],"email":null},{"person_name":{"surname":"Yin","first_name":"Q"},"affiliations":[],"email":null},{"person_name":{"surname":"Hou","first_name":"Z"},"affiliations":[],"email":null},{"person_name":{"surname":"Zhang","first_name":"D"},"affiliations":[],"email":null},{"person_name":{"surname":"Luo","first_name":"Q"},"affiliations":[],"email":null},{"person_name":{"surname":"Qu","first_name":"H"},"affiliations":[],"email":null}],"date":{"year":"2018","month":null,"day":null},"ids":{"DOI":"10.1145/3173574.3173909","arXiv":null},"target":"http://dx.doi.org/10.1145/3173574.3173909","publisher":null,"journal":null,"series":null,"scope":null},"b9":{"title":"Chartaccent: Annotation for data-driven storytelling","authors":[{"person_name":{"surname":"Ren","first_name":"D"},"affiliations":[],"email":null},{"person_name":{"surname":"Brehmer","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Lee","first_name":"B"},"affiliations":[],"email":null},{"person_name":{"surname":"Hollerer","first_name":"T"},"affiliations":[],"email":null},{"person_name":{"surname":"Choe","first_name":"E"},"affiliations":[],"email":null}],"date":{"year":"2017","month":null,"day":null},"ids":{"DOI":"10.1109/pacificvis.2017.8031599","arXiv":null},"target":"10.1109/pacificvis.2017.8031599,25cites","publisher":null,"journal":null,"series":null,"scope":null},"b10":{"title":"Narvis: Authoring narrative slideshows for introducing data visualization designs","authors":[{"person_name":{"surname":"Wang","first_name":"Q"},"affiliations":[],"email":null},{"person_name":{"surname":"Li","first_name":"Z"},"affiliations":[],"email":null},{"person_name":{"surname":"Fu","first_name":"S"},"affiliations":[],"email":null},{"person_name":{"surname":"Cui","first_name":"W"},"affiliations":[],"email":null},{"person_name":{"surname":"Qu","first_name":"H"},"affiliations":[],"email":null}],"date":{"year":"2019","month":null,"day":null},"ids":{"DOI":"10.1109/tvcg.2018.2865232","arXiv":null},"target":"http://dx.doi.org/10.1109/tvcg.2018.2865232.doi:10.1109/tvcg.2018.2865232","publisher":null,"journal":"IEEE Transactions on Visualization and Computer Graphics","series":null,"scope":{"volume":25,"pages":{"from_page":779,"to_page":788}}},"b11":{"title":"Authoring data-driven videos with dataclips","authors":[{"person_name":{"surname":"Amini","first_name":"F"},"affiliations":[],"email":null},{"person_name":{"surname":"Riche","first_name":"N"},"affiliations":[],"email":null},{"person_name":{"surname":"Lee","first_name":"B"},"affiliations":[],"email":null},{"person_name":{"surname":"Monroy-Hernandez","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Irani","first_name":"P"},"affiliations":[],"email":null}],"date":{"year":"2017","month":null,"day":null},"ids":{"DOI":"10.1109/tvcg.2016.2598647","arXiv":null},"target":"http://dx.doi.org/10.1109/tvcg.2016.2598647.doi:10.1109/tvcg.2016.2598647,36cites","publisher":null,"journal":"IEEE Transactions on Visualization and Computer Graphics","series":null,"scope":{"volume":23,"pages":{"from_page":501,"to_page":510}}},"b12":{"title":"Vox populi: a tool for automatically generating video documentaries","authors":[{"person_name":{"surname":"Bocconi","first_name":"S"},"affiliations":[],"email":null},{"person_name":{"surname":"Nack","first_name":"F"},"affiliations":[],"email":null},{"person_name":{"surname":"Hardman","first_name":"L"},"affiliations":[],"email":null}],"date":{"year":"2005","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":292,"to_page":294}}},"b13":{"title":"Creating automatic storytelling videos from still images: a semantically-aware approach","authors":[{"person_name":{"surname":"Teixeira","first_name":"I"},"affiliations":[],"email":null},{"person_name":{"surname":"Viana","first_name":"P"},"affiliations":[],"email":null},{"person_name":{"surname":"Andrade","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Carvalho","first_name":"P"},"affiliations":[],"email":null},{"person_name":{"surname":"Vila√ßa","first_name":"L"},"affiliations":[],"email":null},{"person_name":{"surname":"Pinto","first_name":"J"},"affiliations":[],"email":null},{"person_name":{"surname":"Costa","first_name":"T"},"affiliations":[],"email":null},{"person_name":{"surname":"Rapanakis","first_name":"S"},"affiliations":[],"email":null},{"person_name":{"surname":"Jonker","first_name":"P"},"affiliations":[],"email":null}],"date":{"year":"2021","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"b14":{"title":"Newsviews: an automated pipeline for creating custom geovisualizations for news","authors":[{"person_name":{"surname":"Gao","first_name":"T"},"affiliations":[],"email":null},{"person_name":{"surname":"Hullman","first_name":"J"},"affiliations":[],"email":null},{"person_name":{"surname":"Adar","first_name":"E"},"affiliations":[],"email":null},{"person_name":{"surname":"Hecht","first_name":"B"},"affiliations":[],"email":null},{"person_name":{"surname":"Diakopoulos","first_name":"N"},"affiliations":[],"email":null}],"date":{"year":"2014","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":3005,"to_page":3014}}},"b15":{"title":"semantic exploration of a bookstore","authors":[{"person_name":{"surname":"Bernasconi","first_name":"E"},"affiliations":[],"email":null},{"person_name":{"surname":"Ceriani","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Mecella","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Catarci","first_name":"T"},"affiliations":[],"email":null},{"person_name":{"surname":"Capanna","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Fazio","first_name":"C"},"affiliations":[],"email":null},{"person_name":{"surname":"Marcucci","first_name":"R"},"affiliations":[],"email":null},{"person_name":{"surname":"Pender","first_name":"E"},"affiliations":[],"email":null},{"person_name":{"surname":"Petriccione","first_name":"F"},"affiliations":[],"email":null}],"date":{"year":"2020","month":null,"day":null},"ids":{"DOI":"10.1145/3399715.3399939","arXiv":null},"target":"http://dx.doi.org/10.1145/3399715.3399939","publisher":null,"journal":null,"series":null,"scope":null},"b16":{"title":"A streamlined pipeline to enable the semantic exploration of a bookstore","authors":[{"person_name":{"surname":"Ceriani","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Bernasconi","first_name":"E"},"affiliations":[],"email":null},{"person_name":{"surname":"Mecella","first_name":"M"},"affiliations":[],"email":null}],"date":{"year":"2020","month":"01","day":"30"},"ids":null,"target":null,"publisher":"Springer","journal":null,"series":null,"scope":{"volume":1177,"pages":{"from_page":75,"to_page":81}}},"b17":{"title":"semantic exploration of a bookstore","authors":[{"person_name":{"surname":"Bernasconi","first_name":"E"},"affiliations":[],"email":null},{"person_name":{"surname":"Ceriani","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Mecella","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Catarci","first_name":"T"},"affiliations":[],"email":null},{"person_name":{"surname":"Capanna","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Di Fazio","first_name":"C"},"affiliations":[],"email":null},{"person_name":{"surname":"Marcucci","first_name":"R"},"affiliations":[],"email":null},{"person_name":{"surname":"Pender","first_name":"E"},"affiliations":[],"email":null},{"person_name":{"surname":"Petriccione","first_name":"F"},"affiliations":[],"email":null}],"date":{"year":"2020","month":null,"day":null},"ids":{"DOI":"10.1145/3399715.3399939","arXiv":null},"target":"https://doi.org/10.1145/3399715.3399939.doi:10.1145/3399715.3399939","publisher":"Association for Computing Machinery","journal":null,"series":null,"scope":null},"b18":{"title":"A survey on knowledge graph-based recommender systems","authors":[{"person_name":{"surname":"Guo","first_name":"Q"},"affiliations":[],"email":null},{"person_name":{"surname":"Zhuang","first_name":"F"},"affiliations":[],"email":null},{"person_name":{"surname":"Qin","first_name":"C"},"affiliations":[],"email":null},{"person_name":{"surname":"Zhu","first_name":"H"},"affiliations":[],"email":null},{"person_name":{"surname":"Xie","first_name":"X"},"affiliations":[],"email":null}],"date":{"year":"2020","month":null,"day":null},"ids":null,"target":"https://ieeexplore.ieee.org/abstract/document/9216015/","publisher":null,"journal":null,"series":null,"scope":null},"b19":{"title":"A survey on application of knowledge graph","authors":[{"person_name":{"surname":"Zou","first_name":"X"},"affiliations":[],"email":null}],"date":{"year":"2020","month":null,"day":null},"ids":{"DOI":"10.1088/1742-6596/1487/1/012016","arXiv":null},"target":"https://iopscience.iop.org/article/10.1088/1742-6596/1487/1/012016/meta.doi:10.1088/1742-6596/1487/1/012016","publisher":null,"journal":"Journal of Physics: Conference Series","series":null,"scope":null}},"sections":[{"title":"Introduction","paragraphs":[{"text":"Storytelling is the act of narrating, using the principles of narratology in the audiovisual or literary field to communicate and facilitate learning and understanding. For example, in school books ( to make a concept simple), a story with characters is used; similarly, in language courses, even for adults, the contents are organized with characters who show an aspect of the language through dialogue or a text. This methodology is an experiential resource, as it promotes a generative development between experience, its observation and the resulting insights.","refs":[]},{"text":"Numerous researches [1,2,3,4] show that a book trailer fosters the desire to learn and the level of motivation to read. From publishers' point of view, the usage of promotional trailers is a response to a changing market with a high focus on digital and visual media. The goal of a digital presentation of a book is nevertheless broader than selling it and includes providing helpful information to the potential future reader.","refs":[{"start":20,"end":23,"marker":"bibr","target":"#b0"},{"start":23,"end":25,"marker":"bibr","target":"#b1"},{"start":25,"end":27,"marker":"bibr","target":"#b2"},{"start":27,"end":29,"marker":"bibr","target":"#b3"}]},{"text":"The design, implementation, and early evaluation of Storybook are described in this work.","refs":[]},{"text":"Storybook is a software tool to support the creation of book trailers by collecting and organizing relevant video content. The system users retain control on how to edit and compose the final content. The proposed process aims to semi-automatically build digital trailers that allow the viewer, generically interested in a specialized topic but not expert, to appreciate better the topic, both for their own cultural/professional enrichment and a possible purchase.","refs":[]},{"text":"The remaining sections are organized as follows. Section 2 presents related work about data-driven storytelling systems. Section 3 describes the pipeline of the proposed system and the technologies used. Section 4 reports an early evaluation. Finally, Section 5 discusses future research directions.","refs":[]}]},{"title":"Related work","paragraphs":[{"text":"This section briefly surveys relevant literature for relevant works, starting from data-driven storytelling systems. Storytelling and narrative visualization techniques are two lines of research that intertwine and have led to new methods for enhancing data understanding, information dissemination and displaying information [5,6].","refs":[{"start":326,"end":329,"marker":"bibr","target":"#b4"},{"start":329,"end":331,"marker":"bibr","target":"#b5"}]},{"text":"Users usually encounter difficulties creating a data-driven story due to technical barriers, which motivate the design and development of various automated and simplified generation tools. The creation of a data-based narrative can be divided into two branches [7]. The first focuses on authoring systems to facilitate the design process. In this case, it should be noted that users already have a deep understanding of the data and what they want to present. For instance: Ellipsis [8], InfoNice [9] and ChartAccent [10] enable dynamic annotations to support data storytelling allowing the user to integrate visualizations into an illustrative story directly through direct manipulation and reuse of existing story elements; Narvis [11] is a tool to extract the combination of visual elements of visualization and organize them as a presentation; DataClips [12] is designed to help users generate data videos.","refs":[{"start":261,"end":264,"marker":"bibr","target":"#b6"},{"start":483,"end":486,"marker":"bibr","target":"#b7"},{"start":497,"end":500,"marker":"bibr","target":"#b8"},{"start":517,"end":521,"marker":"bibr","target":"#b9"},{"start":733,"end":737,"marker":"bibr","target":"#b10"},{"start":858,"end":862,"marker":"bibr","target":"#b11"}]},{"text":"The second branch of data narration research, which is one of our interests, seeks to break down technical barriers in creating data-based stories, focuses more on automated systems to save users' efforts that take data as inputs and generate organizations of history components for users. For instance:","refs":[]},{"text":"‚Ä¢ VoxPopuli [13] is developed to generate video documentaries based on interviews about controversial topics. Via a Web interface, the user selects one of the possible topics and a point of view, and the engine assembles video material from the repository to satisfy the user request. ‚Ä¢ Fotoinmotion [14] is designed to produce automatic videos based on a still image. The tool considers semantic information to produce storytelling videos, focusing on the relevant features of the input image. ‚Ä¢ NewsViews [15] is developed to create interactive, annotated maps from news articles.","refs":[{"start":12,"end":16,"marker":"bibr","target":"#b12"},{"start":300,"end":304,"marker":"bibr","target":"#b13"},{"start":507,"end":511,"marker":"bibr","target":"#b14"}]},{"text":"The NewsViews's maps support trend identification and data comparisons relevant to a given news article.","refs":[]},{"text":"Summarizing, existing storytelling tools focus on how to tell a story but rarely base the story on original data. Moreover, these tools assume that the story content is created manually, resulting in inefficiency. In contrast, Storybook supports automatic story generation and flexible story editing features, which ensure quality, reduce the barrier and improve the efficiency of visual storytelling.","refs":[]}]},{"title":"Pipeline and discussion","paragraphs":[{"text":"A pipeline to support making book trailers has been designed and developed. The process is schematized in the Algorithm 1. The following subsections introduce the deployed pipeline's details and discussion and motivations of choices.","refs":[]}]},{"title":"Algorithm 1: The algorithm","paragraphs":[{"text":"Input : Data about a book: content (PDF) and metadata (ùë°ùëñùë°ùëôùëí and ùë°ùëúùëùùëñùëê). The process is designed to work on books with meaningful visual content in images extracted from the PDF. The idea is to find videos relevant to the domain and subject of the book that can be associated with a set of images found in the book. The underlying intuition elicited working with content experts is that the visual content included in the book, like images, is relevant to identify appropriate video content to create a book trailer.","refs":[]},{"text":"The algorithm has four main parameters: ùëò, number of images extracted from the book, it is also the number of videos provided as output; ùëô, number of named entities extracted from the book; ùëö, number of video results for each keyword and each video search service; ùëú, number of labels gathered from the classification of each image. We assume that all the considered books have at least ùëò images.","refs":[]}]},{"title":"Retrieving data for the book","paragraphs":[{"text":"The first important step in the pipeline is to retrieve/extract metadata related to the book itself (see input metadata and line 1 of Algorithm 1).","refs":[]},{"text":"We already have implemented an automatic semantic extractor of information from a digital library called Arca [16,17,18] that produces a knowledge graph (KG) [19,20] with all extracted information and integrated with KGs of the web, so we decided to use that one. However, it can be easily replaced or extended with other semantic enrichment tools as long as they process and extract relevant information from the book. In particular, we perform a SPARQL query 1to the KG and retrieve existing and extracted metadata for a specific book, including the top ùëô concepts found as named entities in the book.","refs":[{"start":110,"end":114,"marker":"bibr","target":"#b15"},{"start":114,"end":117,"marker":"bibr","target":"#b16"},{"start":117,"end":120,"marker":"bibr","target":"#b17"},{"start":158,"end":162,"marker":"bibr","target":"#b18"},{"start":162,"end":165,"marker":"bibr","target":"#b19"},{"start":461,"end":462,"marker":null,"target":"#foot_0"}]},{"text":"It is essential to notice that the whole script can run in batch mode. A web-server has been built to manage the execution of the whole Storybook process, while also providing metadata related to the book before, during, and after the process.","refs":[]}]},{"title":"Web Crawling","paragraphs":[{"text":"We consider the book metadata gathered in the previous step during this step, and we run a web craw looking for relevant videos (lines 2-9 of Algorithm 1). After experimenting with different sources of video content, we decided to focus on a single source, YouTube2 . YouTube is currently the most extensive database of videos in the world.","refs":[{"start":264,"end":265,"marker":null,"target":"#foot_1"}]},{"text":"In the interface for Storybook, the curator can also specify a keywords' whitelist and blacklist. In this way, the curator can try to steer the research of the crawler in different directions. The crawler uses the whitelist to extend the top concepts retrieved in the previous steps, extending the different keywords and searches that the crawler will perform. Instead, the blacklist is used to filter out more videos by excluding certain keywords. For example, depending on the specific search, sometimes it happens to find videos that explain a particular concept with slides (not helpful in building a trailer). Using the blacklist, the curator can cancel out some of these videos.","refs":[]},{"text":"It is crucial to note that some retrieved videos are too long to suit our purpose. Even if a long video contains a shot valuable for the trailer, searching that shot in hours of videos would be difficult for the curator. So, we decided to cap the length of the retrieved videos. By default, the limit is set to be 480 seconds, but the curator can easily change this parameter in the application's settings.","refs":[]},{"text":"We also encountered another problem in searching in such a vast and mixed database. A lot of the videos uploaded on Youtube have licenses that prohibit reuse; hence they cannot be used for our purpose of building a trailer. Therefore, we implemented another filter for retrieving only videos with the Youtube Creative Common license that allows for commercial use. Nevertheless, we can search and retrieve many videos that fit within the search parameters. The gathered video content and related metadata will be used in the last step to compose the draft of a trailer for the book.","refs":[]}]},{"title":"Image Extraction and Processing","paragraphs":[{"text":"Another fundamental step in the pipeline of Storybook is to extract images from the PDF files of the books (line 10 of Algorithm 1).","refs":[]},{"text":"Difficulties arise from the fact that many book publishers compress the PDF, hence losing the information related to the images. Thus, it is necessary for the algorithm first to detect whether the PDF file was compressed or not. This detection can be done by looking into the metadata and searching for the compressor's sign (often, it leaves a signature). As a result, we can separate the compressed PDF to pass through an OCR process that includes rebuilding the images as well; the one we found most efficient was the Adobe Acrobat one 3 .","refs":[{"start":539,"end":540,"marker":null,"target":"#foot_2"}]},{"text":"Subsequently, whether the PDF was not compressed or had been rebuilt from the OCR, the next step was to understand the color space in which the image is stored inside the PDF. In some rare cases, it is not possible to rebuild the color space, so it is impossible without analyzing the image to know if a 0 means a white or black pixel 4 . In these cases, we extract both versions of the image.","refs":[{"start":335,"end":336,"marker":null,"target":"#foot_3"}]},{"text":"Finally, we select the ùëò best images of the book. After trying different methods, the easiest one that yielded good results was sorting the images by their dimensions. We observed that book publishers tend to let essential images take up more space on the page (thus being more significant in size once extracted).","refs":[]}]},{"title":"Image Classification","paragraphs":[{"text":"An image classification process is run on each of the best ùëò images identified at the previous step (line 13 of Algorithm 1). In order to speed up the development, instead of implementing a custom image classification, we went for using an external service, Google Vision AI 5 . For each image, we retrieve up to ùëú labels, along with their confidence level. In the next step, this information is used when generating the suggestions for the trailer.","refs":[{"start":275,"end":276,"marker":null,"target":"#foot_4"}]},{"text":"An interesting piece of information is the SafeSearch detection: how likely the image contains adult, spoof, medical, violent or racy themes 6 . We do not use this information directly; however, it is available for the curator inside a comprehensive JSON file generated at the end of the process.","refs":[{"start":141,"end":142,"marker":null,"target":"#foot_5"}]}]},{"title":"Trailer Composition","paragraphs":[{"text":"The last step of the process consists in filtering videos (lines 14-16 of Algorithm 1) and organising them in a draft of the final trailer (line 18 of Algorithm 1).","refs":[]},{"text":"The algorithm assigns each video a multidimensional score (one dimension for each image). The score increases when there is a match between the image's labels and the video's metadata, such as the description. The confidence of the image-keywords association gives a score's weight (as assigned during the classification step). Once each video has a score, the algorithm matches the highest score per single image, associates that video with the specific image, and discards all the others. Afterwards, the trailer is generated by interleaving the extracted images, and their correspondent retrieved videos. This draft of the trailer is generated for compatibility reasons as an annotated PowerPoint presentation, thus allowing the curator to manipulate the content as they see fit before the actual video creation. Furthermore, all the data generated along the pipeline is packaged inside a JSON file that the curator can access to check the intermediates results and other details on the process.","refs":[]}]},{"title":"Early evaluation","paragraphs":[{"text":"The system was designed and implemented based on requirements iteratively refined with a team of curators of a publishing house. In respect to the algorithm parameters, satisfactory results were reached by choosing ùëô = ùëò = ùëú = 10 and ùëö = 12.","refs":[]},{"text":"Furthermore, the curators gave some general feedback on the system paradigm. They identified several perceived strengths and potential of the system:","refs":[]},{"text":"‚Ä¢ the transformation of the images of books into information nodes; ‚Ä¢ the control of the automatic creation process of a book trailer, through accessible configuration parameters; ‚Ä¢ the free access and management of the information output generated by Storybook.","refs":[]},{"text":"They also expressed some concerns for perceived weaknesses: the scarce availability of videos of niche topics on the web and the prolonged extraction process duration for searches involving longer crawler queries.","refs":[]}]},{"title":"Conclusions and future work","paragraphs":[{"text":"Storybook is a tool for the semi-automatic generation of book trailers. It has been designed with experts in the field, implemented, and tested on the book catalog of a publishing house. From a high-level perspective, the main novelty of the approach is that it supports the creation process while not replacing the human contribution and final choice. An early evaluation shows that expert users appreciate this aspect and react positively to how relevant videos are collected. A potential limiting factor has been found in the limited availability of online videos on niche topics, significantly restricting the search to videos with licenses that allow unrestricted reuse. For the future, we have planned a formal evaluation of the system with a larger sample of users and the integration of Storybook into the Arca system mentioned in section 3.1.","refs":[]}]}],"tables":{"tab_0":{"heading":"17 end for 18 return ùë†ùëíùëôùëíùëêùë°ùëíùëëùëâ ùëñùëëùëíùëúùë†","description":"web services offering video search capability. Input : Set of keywords ùë§‚Ñéùëñùë°ùëíùëôùëñùë†ùë° to add to the search. Input : Set of keywords ùëèùëôùëéùëêùëòùëôùëñùë†ùë° to exclude from the search. Input : Parameters ùëò (number of videos), ùëô (number of named entities extracted), ùëö (number of video results), ùëú (number of labels from image classification). Output : A set of ùëò videos relevant to the book content.","rows":[["8","end for"],["9 end for"]]}},"abstract":{"title":"Abstract","paragraphs":[{"text":"Multimedia storytelling is an effective and engaging method to convey information in multiple domains. Specifically, book trailers -video advertisements for books-positively influence the desire to learn and the motivation to read. This work describes the design and implementation of Storybook, a tool for the semi-automatic creation of book trailers aiming to support storytelling for digital libraries. Storybook supports an expert by gathering relevant crowd-sourced multimedia content, which, arranged as stories, can be used to showcase a book in the form of video clips. Crucially, the expert controls how the content is finally combined and edited rather than offering a fully automated process. In an early informal evaluation, experts consider the method favourably.","refs":[]}]}}