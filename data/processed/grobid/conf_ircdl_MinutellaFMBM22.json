{"bibliography":{"title":"Towards Unsupervised Machine Learning Approaches for Knowledge Graphs","authors":[{"person_name":{"surname":"Minutella","first_name":"Filippo"},"affiliations":[{"department":null,"institution":"Larus Business Automation","laboratory":null}],"email":"filippo.minutella@larus-ba.it"},{"person_name":{"surname":"Falchi","first_name":"Fabrizio"},"affiliations":[{"department":"Istituto di Scienza e Tecnologie dell'Informazione","institution":"Consiglio Nazionale delle Ricerche \"A. Faedo\"","laboratory":null}],"email":"fabrizio.falchi@isti.cnr.it"},{"person_name":{"surname":"Manghi","first_name":"Paolo"},"affiliations":[{"department":"Istituto di Scienza e Tecnologie dell'Informazione","institution":"Consiglio Nazionale delle Ricerche \"A. Faedo\"","laboratory":null}],"email":"paolo.manghi@isti.cnr.it"},{"person_name":{"surname":"De Bonis","first_name":"Michele"},"affiliations":[{"department":"Istituto di Scienza e Tecnologie dell'Informazione","institution":"Consiglio Nazionale delle Ricerche \"A. Faedo\"","laboratory":null}],"email":"michele.debonis@isti.cnr.it"},{"person_name":{"surname":"Messina","first_name":"Nicola"},"affiliations":[{"department":"Istituto di Scienza e Tecnologie dell'Informazione","institution":"Consiglio Nazionale delle Ricerche \"A. Faedo\"","laboratory":null}],"email":"nicola.messina@isti.cnr.it"}],"date":null,"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"keywords":["Neural networks ircdl","Unsupervised machine learning","Knowledge graphs"],"citations":{"b0":{"title":"The data model of the openaire scientific communication e-infrastructure","authors":[{"person_name":{"surname":"Manghi","first_name":"P"},"affiliations":[],"email":null},{"person_name":{"surname":"Houssos","first_name":"N"},"affiliations":[],"email":null},{"person_name":{"surname":"Mikulicic","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"J√∂rg","first_name":"B"},"affiliations":[],"email":null}],"date":{"year":"2012","month":null,"day":null},"ids":null,"target":null,"publisher":"Springer","journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":168,"to_page":180}}},"b1":{"title":"The openaire research graph data model","authors":[{"person_name":{"surname":"Manghi","first_name":"P"},"affiliations":[],"email":null},{"person_name":{"surname":"Bardi","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Atzori","first_name":"C"},"affiliations":[],"email":null},{"person_name":{"surname":"Baglioni","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Manola","first_name":"N"},"affiliations":[],"email":null},{"person_name":{"surname":"Schirrwagen","first_name":"J"},"affiliations":[],"email":null},{"person_name":{"surname":"Principe","first_name":"P"},"affiliations":[],"email":null},{"person_name":{"surname":"Artini","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Becker","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Bonis","first_name":"M"},"affiliations":[],"email":null}],"date":{"year":"2019","month":null,"day":null},"ids":null,"target":null,"publisher":"Zenodo","journal":null,"series":null,"scope":null},"b2":{"title":"Openaire research graph dump","authors":[{"person_name":{"surname":"Manghi","first_name":"P"},"affiliations":[],"email":null},{"person_name":{"surname":"Atzori","first_name":"C"},"affiliations":[],"email":null},{"person_name":{"surname":"Bardi","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Baglioni","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Schirrwagen","first_name":"J"},"affiliations":[],"email":null},{"person_name":{"surname":"Dimitropoulos","first_name":"H"},"affiliations":[],"email":null},{"person_name":{"surname":"La","first_name":"S"},"affiliations":[],"email":null},{"person_name":{"surname":"Bruzzo","first_name":"I"},"affiliations":[],"email":null},{"person_name":{"surname":"Foufoulas","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"L√∂hden","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"B√§cker","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Mannocci","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Horst","first_name":"P"},"affiliations":[],"email":null},{"person_name":{"surname":"Jacewicz","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Czerniak","first_name":"K"},"affiliations":[],"email":null},{"person_name":{"surname":"Kiatropoulou","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Kokogiannaki","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Bonis","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Artini","first_name":"E"},"affiliations":[],"email":null},{"person_name":{"surname":"Ottonello","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Lempesis","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Ioannidis","first_name":"N"},"affiliations":[],"email":null},{"person_name":{"surname":"Manola","first_name":"P"},"affiliations":[],"email":null},{"person_name":{"surname":"Principe","first_name":null},"affiliations":[],"email":null}],"date":{"year":"2020","month":null,"day":null},"ids":{"DOI":"10.5281/zenodo.4201546","arXiv":null},"target":"https://doi.org/10.5281/zenodo.4201546.doi:10.5281/zenodo.4201546","publisher":null,"journal":null,"series":null,"scope":null},"b3":{"title":"Learning visual features for relational cbir","authors":[{"person_name":{"surname":"Messina","first_name":"N"},"affiliations":[],"email":null},{"person_name":{"surname":"Amato","first_name":"G"},"affiliations":[],"email":null},{"person_name":{"surname":"Carrara","first_name":"F"},"affiliations":[],"email":null},{"person_name":{"surname":"Falchi","first_name":"F"},"affiliations":[],"email":null},{"person_name":{"surname":"Gennaro","first_name":"C"},"affiliations":[],"email":null}],"date":{"year":"2019","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"International Journal of Multimedia Information Retrieval","series":null,"scope":{"volume":null,"pages":{"from_page":1,"to_page":12}}},"b4":{"title":"Fine-grained visual textual alignment for cross-modal retrieval using transformer encoders","authors":[{"person_name":{"surname":"Messina","first_name":"N"},"affiliations":[],"email":null},{"person_name":{"surname":"Amato","first_name":"G"},"affiliations":[],"email":null},{"person_name":{"surname":"Esuli","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Falchi","first_name":"F"},"affiliations":[],"email":null},{"person_name":{"surname":"Gennaro","first_name":"C"},"affiliations":[],"email":null},{"person_name":{"surname":"Marchand-Maillet","first_name":"S"},"affiliations":[],"email":null}],"date":{"year":"2021","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM)","series":null,"scope":{"volume":17,"pages":{"from_page":1,"to_page":23}}},"b5":{"title":"Graph neural networks: A review of methods and applications","authors":[{"person_name":{"surname":"Zhou","first_name":"J"},"affiliations":[],"email":null},{"person_name":{"surname":"Cui","first_name":"G"},"affiliations":[],"email":null},{"person_name":{"surname":"Hu","first_name":"S"},"affiliations":[],"email":null},{"person_name":{"surname":"Zhang","first_name":"Z"},"affiliations":[],"email":null},{"person_name":{"surname":"Yang","first_name":"C"},"affiliations":[],"email":null},{"person_name":{"surname":"Liu","first_name":"Z"},"affiliations":[],"email":null},{"person_name":{"surname":"Wang","first_name":"L"},"affiliations":[],"email":null},{"person_name":{"surname":"Li","first_name":"C"},"affiliations":[],"email":null},{"person_name":{"surname":"Sun","first_name":"M"},"affiliations":[],"email":null}],"date":{"year":"2020","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"AI Open","series":null,"scope":{"volume":1,"pages":{"from_page":57,"to_page":81}}},"b6":{"title":"Fast and accurate network embeddings via very sparse random projection","authors":[{"person_name":{"surname":"Chen","first_name":"H"},"affiliations":[],"email":null},{"person_name":{"surname":"Sultan","first_name":"S"},"affiliations":[],"email":null},{"person_name":{"surname":"Tian","first_name":"Y"},"affiliations":[],"email":null},{"person_name":{"surname":"Chen","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Skiena","first_name":"S"},"affiliations":[],"email":null}],"date":{"year":"2019","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":399,"to_page":408}}},"b7":{"title":"Deepwalk: Online learning of social representations","authors":[{"person_name":{"surname":"Perozzi","first_name":"B"},"affiliations":[],"email":null},{"person_name":{"surname":"Al-Rfou","first_name":"R"},"affiliations":[],"email":null},{"person_name":{"surname":"Skiena","first_name":"S"},"affiliations":[],"email":null}],"date":{"year":"2014","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":701,"to_page":710}}},"b8":{"title":"node2vec: Scalable feature learning for networks","authors":[{"person_name":{"surname":"Grover","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Leskovec","first_name":"J"},"affiliations":[],"email":null}],"date":{"year":"2016","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":855,"to_page":864}}},"b9":{"title":"Line: Large-scale information network embedding","authors":[{"person_name":{"surname":"Tang","first_name":"J"},"affiliations":[],"email":null},{"person_name":{"surname":"Qu","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Wang","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Zhang","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Yan","first_name":"J"},"affiliations":[],"email":null},{"person_name":{"surname":"Mei","first_name":"Q"},"affiliations":[],"email":null}],"date":{"year":"2015","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":1067,"to_page":1077}}},"b10":{"title":"Pre-training of deep bidirectional transformers for language understanding","authors":[{"person_name":{"surname":"Devlin","first_name":"J"},"affiliations":[],"email":null},{"person_name":{"surname":"Chang","first_name":"M.-W"},"affiliations":[],"email":null},{"person_name":{"surname":"Lee","first_name":"K"},"affiliations":[],"email":null},{"person_name":{"surname":"Toutanova","first_name":"K"},"affiliations":[],"email":null}],"date":{"year":"2019","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"b11":{"title":"Tabnet: Attentive interpretable tabular learning","authors":[{"person_name":{"surname":"Arik","first_name":"S"},"affiliations":[],"email":null},{"person_name":{"surname":"Pfister","first_name":"T"},"affiliations":[],"email":null}],"date":{"year":"2021","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":{"volume":35,"pages":{"from_page":6679,"to_page":6687}}},"b12":{"title":"Language modeling with gated convolutional networks","authors":[{"person_name":{"surname":"Dauphin","first_name":"Y"},"affiliations":[],"email":null},{"person_name":{"surname":"Fan","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Auli","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Grangier","first_name":"D"},"affiliations":[],"email":null}],"date":{"year":"2017","month":null,"day":null},"ids":null,"target":null,"publisher":"PMLR","journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":933,"to_page":941}}},"b13":{"title":"Meta-path guided embedding for similarity search in large-scale heterogeneous information networks","authors":[{"person_name":{"surname":"Shang","first_name":"J"},"affiliations":[],"email":null},{"person_name":{"surname":"Qu","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Liu","first_name":"J"},"affiliations":[],"email":null},{"person_name":{"surname":"Kaplan","first_name":"L"},"affiliations":[],"email":null},{"person_name":{"surname":"Han","first_name":"J"},"affiliations":[],"email":null},{"person_name":{"surname":"Peng","first_name":"J"},"affiliations":[],"email":null}],"date":{"year":"2016","month":null,"day":null},"ids":null,"target":"1610.09769","publisher":null,"journal":null,"series":null,"scope":null},"b14":{"title":"Metapath2vec: Scalable representation learning for heterogeneous networks","authors":[{"person_name":{"surname":"Dong","first_name":"Y"},"affiliations":[],"email":null},{"person_name":{"surname":"Chawla","first_name":"N"},"affiliations":[],"email":null},{"person_name":{"surname":"Swami","first_name":"A"},"affiliations":[],"email":null}],"date":{"year":"2017","month":null,"day":null},"ids":{"DOI":"10.1145/3097983.3098036","arXiv":null},"target":"10.1145/3097983.3098036","publisher":null,"journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":135,"to_page":144}}},"b15":{"title":"Heterogeneous information network embedding for recommendation","authors":[{"person_name":{"surname":"Shi","first_name":"C"},"affiliations":[],"email":null},{"person_name":{"surname":"Hu","first_name":"B"},"affiliations":[],"email":null},{"person_name":{"surname":"Zhao","first_name":"W"},"affiliations":[],"email":null},{"person_name":{"surname":"Yu","first_name":"P"},"affiliations":[],"email":null}],"date":{"year":"2019","month":null,"day":null},"ids":{"DOI":"10.1109/TKDE.2018.2833443","arXiv":null},"target":null,"publisher":null,"journal":"IEEE Transactions on Knowledge and Data Engineering","series":null,"scope":{"volume":31,"pages":{"from_page":357,"to_page":370}}}},"sections":[{"title":"Introduction","paragraphs":[{"text":"Today, graphs are widely used to represent data in many applications over the Internet. Social networks, transaction networks, collaboration networks, and all those cases in which data is composed of entities and relations between them take advantage of the graph structure. One of the main fields in which this kind of structure is deeply used is the scholarly communication, where research products are organized in graphs, such as the OpenAIRE Research Graph [1][2] [3]. Algorithms operating on such graphs need to exploit the links among nodes to understand the whole spectrum of relationships among the different entities. With the advent of deep learning, many architectures were proposed to explicitly deal with relationships, for example in the context of information retrieval [4] or multimodal matching [5]. Over the past decade, many algorithms were proposed to operate with heterogeneous graphs, i.e. graphs that contain different types of nodes and edges. An algorithm over a heterogeneous graph works by extracting its homogeneous forms using the metapath approach. This approach consists in replacing the link chain between two entities of the same type with a direct link. For example, in a graph with actors and movies in which a relation between the entities indicates that the actor played a role in the movie, the actor-movie-actor metapath extracts the homogeneous form that contains only actor nodes, with edges encoding the played a role in the same movie relationship. Although Graph Neural Networks (GNN) seem very prominent in this field, their applicability is limited in large knowledge graphs. In many cases, in fact, a subgraph sampling may be required when the graph is dense, while the addition of virtual nodes may be necessary when the graph is too sparse.","refs":[{"start":462,"end":465,"marker":"bibr","target":"#b0"},{"start":469,"end":472,"marker":"bibr","target":"#b2"},{"start":786,"end":789,"marker":"bibr","target":"#b3"},{"start":813,"end":816,"marker":"bibr","target":"#b4"}]},{"text":"In the light of these observations, we propose an efficient and scalable pipeline to process very large heterogeneous knowledge graphs. Our objective consists in classifying the nodes in the graph given the node attributes and the node neighborhood. We target the IMDb dataset, the world's most popular and authoritative database for movie, TV, and celebrity content, where the target movie classes to infer are Action, Drama or Comedy. The proposed approach leverages the metapath approach to obtain multiple but simpler homogeneous graphs and constructs node embeddings using FastRP, a widely-used random projection algorithm. Then, an attentive neural network is trained in an unsupervised manner to aggregate information from different metapaths and produce embeddings suitable for effective node classification. We aim to train the neural network in an unsupervised way to emulate the scarcity of annotated data, a widespread scenario in large knowledge graphs scraped from the Internet. Furthermore, forging informative node embeddings without direct supervision enables the creation of features suitable for multiple downstream tasks.","refs":[]},{"text":"We show that this simple approach can obtain state-of-the-art results on node classification in the unsupervised regime on IMDb.","refs":[]}]},{"title":"Related Work","paragraphs":[{"text":"Deep learning on heterogeneous and homogeneous graphs has been deeply studied in literature from many points of view. Many of the approaches take advantage of Graph Neural Networks (GNNs) [6]. A GNN is a class of deep learning methods designed to perform inference on data described by graphs. They provide an easy way to perform node-level, edge-level, and graph-level prediction tasks. The advantage of GNNs is that they can use features and attributes of nodes in the neighborhood to create an embedding that captures the graph's topology.","refs":[{"start":188,"end":191,"marker":"bibr","target":"#b5"}]},{"text":"Differently from GNNs, different approaches try to exploit explicit mathematical formulations to aggregate information from the neighborhood. The simplest approach consists of extracting features from the nodes' observable properties in the graph, such as degree, centrality, or betweenness. Other approaches try to take advantage of the adjacency matrix using dimensionality reduction techniques to extract dense vectors for each node. An example included in this category is the FastRP algorithm [7]. Finally, the last class of approaches uses random walks, consisting of random traversals of the graph to extract sequences of nodes. This approach is very similar to word2vec algorithm on texts. Some of the methods included in this category are DeepWalk [8], Node2Vec [9], and LINE [10]. ","refs":[{"start":498,"end":501,"marker":"bibr","target":"#b6"},{"start":757,"end":760,"marker":"bibr","target":"#b7"},{"start":771,"end":774,"marker":"bibr","target":"#b8"},{"start":785,"end":789,"marker":"bibr","target":"#b9"}]}]},{"title":"Architecture","paragraphs":[{"text":"The proposed methodology is based on a three-step pipeline, consisting of (ùëñ) the definition of metapaths, (ùëñùëñ) the extraction of the embeddings using FastRP [7], and (ùëñùëñùëñ) the training of the neural network to intelligently aggregate information from different metapaths. An overview of the approach is shown in Figure 1. Steps (ùëñ) and (ùëñùëñ) can be considered as pre-processing steps, while the step (ùëñùëñùëñ) is the core of the unsupervised node embedding learning for node classification.","refs":[{"start":158,"end":161,"marker":"bibr","target":"#b6"},{"start":320,"end":321,"marker":"figure","target":"#fig_0"}]}]},{"title":"Pre-processing","paragraphs":[{"text":"In this work, we use the IMDb knowledge graph. We extract three different metapaths to obtain three homogeneous graphs: the movies linked by the same actors, the movies linked by the same directors, and the movies linked by the same plot keywords, using the movie-actor-movie, movie-director-movie, and movie-keyword-movie metapaths, respectively. In order to account for the attributes of nodes -the genre, the duration or the year of a movie, for example -virtual nodes and virtual edges are used. Those virtual elements define additional metapaths that capture the topological information from the point of view of node attributes. A feature can be categorical -for example, when the value is taken from a list that encodes the genre -or numeric. A categorical feature can be represented in the graph by adding a virtual node for each value that the feature can assume. Differently, a numeric feature can be represented in the graph as a single node. The value that an actual node assumes for that feature is represented as a weighted link, with the weight indicating the numeric value for that feature. The newly added virtual nodes define new metapaths that are treated as the standard metapaths.","refs":[]},{"text":"At this point, dense vectors computed for each node can be propagated through the graph links to neighboring nodes using a message-passing algorithm. In this work, we use FastRP [7], a very fast node embedding algorithm based on random projections.","refs":[{"start":178,"end":181,"marker":"bibr","target":"#b6"}]}]},{"title":"Unsupervised Metapaths Aggregation","paragraphs":[{"text":"At the end of the pre-processing procedure, we have a number of dense vectors encoding neighboring information for each target node. Specifically, we have a number of dense vectors for each node equal to the number of metapaths plus the number of the features of target nodes.","refs":[]},{"text":"The node embeddings obtained from different metapaths are aggregated through an attentive neural network that creates a very informative representation of each node suitable for node classification. We aim at training this neural network in an unsupervised way, emulating the scarcity of annotated data, a very common scenario in large knowledge graphs. The unsupervised training is performed using an approach very similar to masked language model pre-training, like the one employed in BERT [11]. Specifically, one of the input vectors is randomly masked by setting it to zero, and the neural network is forced to predict the values of all the vectors, including the masked one.","refs":[{"start":493,"end":497,"marker":"bibr","target":"#b10"}]},{"text":"The neural network designed in this research is inspired by Tabnet [12], and it is detailed in Figure 2. The network is composed of K blocks. Each block is fed with the input vectors, aggregates them using an attentive aggregation and outputs the aggregated vector. Specifically, each block is composed of two submodules, called metapath gating and metapath attention. The metapath gating submodule is composed of a GLU [13] (Gated Linear Unit) component, which internally performs an attentive gating of the input vectors. The second submodule is composed of a series of dense layers that return an attentive value for each of the examined metapaths. These scores are normalized to sum to 1 using a softmax output layer. The output of the entire block is the weighted average of the vectors from the gating submodule using the weights computed by the attention submodule. Finally, the K vectors computed by each block are then summed together to obtain the final node embedding used for the masked node reconstruction.","refs":[{"start":67,"end":71,"marker":"bibr","target":"#b11"},{"start":102,"end":103,"marker":"figure","target":"#fig_1"},{"start":420,"end":424,"marker":"bibr","target":"#b12"}]},{"text":"The general idea of this neural network is to try to pass the input in simple transformations (for this the choice of the GLU). In this way, the attention weights created in the second path of each block can be used to inspect which metapath contributes majorly during the reconstruction phase.","refs":[]}]},{"title":"Preliminary Experiments","paragraphs":[{"text":"We used the IMDb dataset to train and evaluate our architecture. IMDb (an acronym for Internet Movie Database) is an online database of information related to films, television programs, home videos, video games, and streaming content online. For the purpose of this research, we used the subset containing movies, actors, directors, and keywords of the movie plot. Each movie of the dataset has only one director, the three main actors, and a variable number of keywords.","refs":[]},{"text":"The goal is to infer the movie genre (Action, Drama or Comedy), so this task is framed as a node classification problem. We compared our approach with other unsupervised methods from the literature, namely Node2Vec [9], LINE [10], ESim [14], metapath2vec [15], and HERec [16]. The standard evaluation protocol consists in inferring the node embeddings on the test set and training in a supervised way a linear support vector machine (SVM) with varying training proportions. We report the average Macro-F1 and Micro-F1 of 10 runs of each embedding model in Table 1. Since each movie can have only one label, the Micro-F1 corresponds to the accuracy while Macro-F1 is the average of the F1 over each class. As it can be noticed, our approach defeats current unsupervised node embedding approaches, obtaining a performance increase of around 4.7% and 2.0% on Macro-F1 and Micro-F1, respectively, relative to the previous best performing model (node2vec).","refs":[{"start":215,"end":218,"marker":"bibr","target":"#b8"},{"start":225,"end":229,"marker":"bibr","target":"#b9"},{"start":236,"end":240,"marker":"bibr","target":"#b13"},{"start":255,"end":259,"marker":"bibr","target":"#b14"},{"start":271,"end":275,"marker":"bibr","target":"#b15"},{"start":562,"end":563,"marker":"table","target":"#tab_0"}]}]},{"title":"Conclusions","paragraphs":[{"text":"In this paper, we developed a framework to perform node classification on large heterogeneous knowledge graphs. The proposed approach employs the metapath approach to transform an heterogeneous graph into a set of homogeneous graphs that are then analyzed using a node embedding algorithm. Inspired by neural networks working on tabular data, we developed an attentive neural network that can smartly aggregate node embeddings from different metapaths. This network does not require direct supervision using the node labels; instead, it is trained in an unsupervised way by performing masked node embedding reconstruction. The final classes are learned by training a simple SVM on a slice of the test set. We compared our approach with other unsupervised methods that use the same training and evaluation protocols on the IMDb dataset, and we obtained the best results on both Macro-F1 and Micro-F1 metrics.","refs":[]}]}],"tables":{"tab_0":{"heading":"Table 1","description":"Results for node classification on the IMDb dataset.","rows":[["Metrics","Train %","LINE","node2vec","Unsupervised Methods ESim metapath","HERec","Ours"],["","","","","","2vec","",""],["Macro-F1","20% 80%","44.04 47.49","49.00 51.49","48.37 51.37","46.05 49.99","45.61 47.73","50.88 53.94"],["Micro-F1","20% 80%","45.21 48.98","49.94 52.72","49.32 52.54","47.22 50.50","46.23 49.11","50.69 53.76"]]}},"abstract":{"title":"Abstract","paragraphs":[{"text":"Nowadays, a lot of data is in the form of Knowledge Graphs aiming at representing information as a set of nodes and relationships between them. This paper proposes an efficient framework to create informative embeddings for node classification on large knowledge graphs. Such embeddings capture how a particular node of the graph interacts with his neighborhood and indicate if it is either isolated or part of a bigger clique. Since a homogeneous graph is necessary to perform this kind of analysis, the framework exploits the metapath approach to split the heterogeneous graph into multiple homogeneous graphs. The proposed pipeline includes an unsupervised attentive neural network to merge different metapaths and produce node embeddings suitable for classification. Preliminary experiments on the IMDb dataset demonstrate the validity of the proposed approach, which can defeat current state-of-the-art unsupervised methods.","refs":[]}]}}