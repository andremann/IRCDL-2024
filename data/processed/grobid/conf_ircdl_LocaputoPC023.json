{"bibliography":{"title":"Filling the Lacunae in ancient Latin inscriptions","authors":[{"person_name":{"surname":"Locaputo","first_name":"Alessandro"},"affiliations":[{"department":"Department of Mathematics, Computer Science, and Physics","institution":"University of Udine","laboratory":null}],"email":"locaputo.alessandro@spes.uniud.it"},{"person_name":{"surname":"Portelli","first_name":"Beatrice"},"affiliations":[{"department":"Department of Mathematics, Computer Science, and Physics","institution":"University of Udine","laboratory":null},{"department":"Department of Biology","institution":"University of Naples Federico II","laboratory":null}],"email":"portelli.beatrice@spes.uniud.it"},{"person_name":{"surname":"Colombi","first_name":"Emanuela"},"affiliations":[{"department":"Department of Humanities and Cultural Heritage","institution":"University of Udine","laboratory":null}],"email":"emanuela.colombi@uniud.it"},{"person_name":{"surname":"Serra","first_name":"Giuseppe"},"affiliations":[{"department":"Department of Mathematics, Computer Science, and Physics","institution":"University of Udine","laboratory":null}],"email":"giuseppe.serra@uniud.it"}],"date":null,"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"keywords":["Latin","Deep learning","Epigraphy","Digital humanities","Lacunae"],"citations":{"b0":{"title":"Manuale di epigrafia latina, Beni culturali","authors":[{"person_name":{"surname":"Buonopane","first_name":"A"},"affiliations":[],"email":null}],"date":{"year":"2009","month":null,"day":null},"ids":null,"target":null,"publisher":"Carocci","journal":"Tex.lccn","series":null,"scope":{"volume":null,"pages":{"from_page":2009478450,"to_page":2009478450}}},"b1":{"title":"The cambridge handbook of latin epigraphy","authors":[{"person_name":{"surname":"Cooley","first_name":"A"},"affiliations":[],"email":null}],"date":{"year":"2012","month":null,"day":null},"ids":null,"target":null,"publisher":"Cambridge Univ. Press","journal":null,"series":null,"scope":null},"b2":{"title":"Epigraphic Evidence","authors":[{"person_name":{"surname":"Bodel","first_name":"J"},"affiliations":[],"email":null}],"date":{"year":"2012","month":null,"day":null},"ids":null,"target":null,"publisher":"Routledge","journal":null,"series":null,"scope":null},"b3":{"title":"Corpus inscriptionum latinarum","authors":[{"person_name":{"surname":"Der Wissenschaften Zu Berlin","first_name":"D"},"affiliations":[],"email":null},{"person_name":{"surname":"Der Wissenschaften","first_name":"B.-B"},"affiliations":[],"email":null}],"date":{"year":"1862","month":null,"day":null},"ids":null,"target":null,"publisher":"Apud G. Reimerum","journal":null,"series":null,"scope":null},"b4":{"title":"L'Année épigraphique: revue des publications épigraphiques relatives a l'antiquité romaine","authors":[{"person_name":{"surname":"Organization","first_name":"J"},"affiliations":[],"email":null},{"person_name":{"surname":"D. I. . B.-L","first_name":"A"},"affiliations":[],"email":null}],"date":null,"ids":null,"target":null,"publisher":"Presses Universitaires de France","journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":1894,"to_page":1894}}},"b5":{"title":"Historical Document Processing: A Survey of Techniques","authors":[{"person_name":{"surname":"Philips","first_name":"J"},"affiliations":[],"email":null},{"person_name":{"surname":"Tabrizi","first_name":"N"},"affiliations":[],"email":null}],"date":{"year":"2020","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"Tools, and Trends","series":null,"scope":{"volume":null,"pages":{"from_page":30,"to_page":30}}},"b6":{"title":"Discovering Novelty Patterns from the Ancient Christian Inscriptions of Rome","authors":[{"person_name":{"surname":"Pio","first_name":"G"},"affiliations":[],"email":null},{"person_name":{"surname":"Fumarola","first_name":"F"},"affiliations":[],"email":null},{"person_name":{"surname":"Felle","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Malerba","first_name":"D"},"affiliations":[],"email":null},{"person_name":{"surname":"Ceci","first_name":"M"},"affiliations":[],"email":null}],"date":{"year":"2015","month":null,"day":null},"ids":{"DOI":"10.1145/2629513","arXiv":null},"target":"https://dl.acm.org/doi/10.1145/2629513.doi:10.1145/2629513","publisher":null,"journal":"Journal on Computing and Cultural Heritage","series":null,"scope":{"volume":7,"pages":{"from_page":1,"to_page":21}}},"b7":{"title":"The HisDoc Project. Automatic Analysis, Recognition, and Retrieval of Handwritten Historical Documents for Digital Libraries","authors":[{"person_name":{"surname":"Fischer","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Bunke","first_name":"H"},"affiliations":[],"email":null},{"person_name":{"surname":"Naji","first_name":"N"},"affiliations":[],"email":null},{"person_name":{"surname":"Savoy","first_name":"J"},"affiliations":[],"email":null},{"person_name":{"surname":"Baechler","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Ingold","first_name":"R"},"affiliations":[],"email":null}],"date":{"year":"2014","month":null,"day":null},"ids":{"DOI":"10.1515/9783110367317.91","arXiv":null},"target":"https://www.degruyter.com/document/doi/10.1515/9783110367317.91/html.doi:10.1515/9783110367317.91","publisher":null,"journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":91,"to_page":106}}},"b8":{"title":"Restoring ancient text using deep learning: a case study on Greek epigraphy","authors":[{"person_name":{"surname":"Assael","first_name":"Y"},"affiliations":[],"email":null},{"person_name":{"surname":"Sommerschield","first_name":"T"},"affiliations":[],"email":null},{"person_name":{"surname":"Prag","first_name":"J"},"affiliations":[],"email":null}],"date":{"year":"2019","month":null,"day":null},"ids":{"DOI":"10.18653/v1/D19-1668","arXiv":null},"target":"https://www.aclweb.org/anthology/D19-1668.doi:10.18653/v1/D19-1668","publisher":null,"journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":6367,"to_page":6374}}},"b9":{"title":"Effective Character-augmented Word Embedding for Machine Reading Comprehension","authors":[{"person_name":{"surname":"Zhang","first_name":"Z"},"affiliations":[],"email":null},{"person_name":{"surname":"Huang","first_name":"Y"},"affiliations":[],"email":null},{"person_name":{"surname":"Zhu","first_name":"P"},"affiliations":[],"email":null},{"person_name":{"surname":"Zhao","first_name":"H"},"affiliations":[],"email":null}],"date":{"year":"2021","month":null,"day":null},"ids":{"DOI":null,"arXiv":"arXiv:1808.02772"},"target":"http://arxiv.org/abs/1808.02772","publisher":null,"journal":null,"series":null,"scope":null},"b10":{"title":"Restoring and attributing ancient texts using deep neural networks","authors":[{"person_name":{"surname":"Assael","first_name":"Y"},"affiliations":[],"email":null},{"person_name":{"surname":"Sommerschield","first_name":"T"},"affiliations":[],"email":null},{"person_name":{"surname":"Shillingford","first_name":"B"},"affiliations":[],"email":null},{"person_name":{"surname":"Bordbar","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Pavlopoulos","first_name":"J"},"affiliations":[],"email":null},{"person_name":{"surname":"Chatzipanagiotou","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Androutsopoulos","first_name":"I"},"affiliations":[],"email":null},{"person_name":{"surname":"Prag","first_name":"J"},"affiliations":[],"email":null},{"person_name":{"surname":"Freitas","first_name":"N"},"affiliations":[],"email":null}],"date":{"year":"2022","month":null,"day":null},"ids":{"DOI":"10.1038/s41586-022-04448-z","arXiv":null},"target":"https://www.nature.com/articles/s41586-022-04448-z.doi:10.1038/s41586-022-04448-z","publisher":null,"journal":"Nature","series":null,"scope":{"volume":603,"pages":{"from_page":280,"to_page":283}}},"b11":{"title":"Text Infilling","authors":[{"person_name":{"surname":"Zhu","first_name":"W"},"affiliations":[],"email":null},{"person_name":{"surname":"Hu","first_name":"Z"},"affiliations":[],"email":null},{"person_name":{"surname":"Xing","first_name":"E"},"affiliations":[],"email":null}],"date":{"year":"2019","month":null,"day":null},"ids":{"DOI":null,"arXiv":"arXiv:1901.00158"},"target":"http://arxiv.org/abs/1901.00158","publisher":null,"journal":null,"series":null,"scope":null},"b12":{"title":"Enabling Language Models to Fill in the Blanks","authors":[{"person_name":{"surname":"Donahue","first_name":"C"},"affiliations":[],"email":null},{"person_name":{"surname":"Lee","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Liang","first_name":"P"},"affiliations":[],"email":null}],"date":{"year":"2020","month":null,"day":null},"ids":{"DOI":null,"arXiv":"arXiv:2005.05339"},"target":"http://arxiv.org/abs/2005.05339","publisher":null,"journal":null,"series":null,"scope":null},"b13":{"title":"Blank Language Models","authors":[{"person_name":{"surname":"Shen","first_name":"T"},"affiliations":[],"email":null},{"person_name":{"surname":"Quach","first_name":"V"},"affiliations":[],"email":null},{"person_name":{"surname":"Barzilay","first_name":"R"},"affiliations":[],"email":null},{"person_name":{"surname":"Jaakkola","first_name":"T"},"affiliations":[],"email":null}],"date":{"year":"2020","month":null,"day":null},"ids":{"DOI":null,"arXiv":"arXiv:2002.03079"},"target":"http://arxiv.org/abs/2002.03079","publisher":null,"journal":null,"series":null,"scope":null},"b14":{"title":"Restoring and Mining the Records of the Joseon Dynasty via Neural Language Modeling and Machine Translation","authors":[{"person_name":{"surname":"Kang","first_name":"K"},"affiliations":[],"email":null},{"person_name":{"surname":"Jin","first_name":"K"},"affiliations":[],"email":null},{"person_name":{"surname":"Yang","first_name":"S"},"affiliations":[],"email":null},{"person_name":{"surname":"Jang","first_name":"S"},"affiliations":[],"email":null},{"person_name":{"surname":"Choo","first_name":"J"},"affiliations":[],"email":null},{"person_name":{"surname":"Kim","first_name":"Y"},"affiliations":[],"email":null}],"date":{"year":"2021","month":null,"day":null},"ids":{"DOI":null,"arXiv":"arXiv:2104.05964"},"target":"http://arxiv.org/abs/2104.05964","publisher":null,"journal":null,"series":null,"scope":null},"b15":{"title":"Filling the Gaps in Ancient Akkadian Texts: A Masked Language Modelling Approach","authors":[{"person_name":{"surname":"Lazar","first_name":"K"},"affiliations":[],"email":null},{"person_name":{"surname":"Saret","first_name":"B"},"affiliations":[],"email":null},{"person_name":{"surname":"Yehudai","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Horowitz","first_name":"W"},"affiliations":[],"email":null},{"person_name":{"surname":"Wasserman","first_name":"N"},"affiliations":[],"email":null},{"person_name":{"surname":"Stanovsky","first_name":"G"},"affiliations":[],"email":null}],"date":{"year":"2021","month":null,"day":null},"ids":{"DOI":null,"arXiv":"arXiv:2109.04513"},"target":"http://arxiv.org/abs/2109.04513","publisher":null,"journal":null,"series":null,"scope":null},"b16":{"title":"BERT: Pre-training of deep bidirectional transformers for language understanding","authors":[{"person_name":{"surname":"Devlin","first_name":"J"},"affiliations":[],"email":null},{"person_name":{"surname":"Chang","first_name":"M.-W"},"affiliations":[],"email":null},{"person_name":{"surname":"Lee","first_name":"K"},"affiliations":[],"email":null},{"person_name":{"surname":"Toutanova","first_name":"K"},"affiliations":[],"email":null}],"date":{"year":"2019","month":null,"day":null},"ids":{"DOI":"10.18653/v1/N19-1423","arXiv":null},"target":"https://aclanthology.org/N19-1423.doi:10.18653/v1/N19-1423","publisher":"Association for Computational Linguistics","journal":null,"series":null,"scope":{"volume":1,"pages":{"from_page":4171,"to_page":4186}}},"b17":{"title":"Latin BERT: A Contextual Language Model for Classical Philology","authors":[{"person_name":{"surname":"Bamman","first_name":"D"},"affiliations":[],"email":null},{"person_name":{"surname":"Burns","first_name":"P"},"affiliations":[],"email":null}],"date":{"year":"2020","month":null,"day":null},"ids":{"DOI":null,"arXiv":"arXiv:2009.10053"},"target":"http://arxiv.org/abs/2009.10053","publisher":null,"journal":null,"series":null,"scope":null},"b18":{"title":"An ELECTRA Model for Latin Token Tagging Tasks","authors":[{"person_name":{"surname":"Mercelis","first_name":"W"},"affiliations":[],"email":null},{"person_name":{"surname":"Keersmaekers","first_name":"A"},"affiliations":[],"email":null}],"date":{"year":"2022","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":{"volume":4,"pages":null}},"b19":{"title":"Context-based Surface Pattern Completion of Ancient Pottery","authors":[{"person_name":{"surname":"Lengauer","first_name":"S"},"affiliations":[],"email":null},{"person_name":{"surname":"Preiner","first_name":"R"},"affiliations":[],"email":null},{"person_name":{"surname":"Sipiran","first_name":"I"},"affiliations":[],"email":null},{"person_name":{"surname":"Karl","first_name":"S"},"affiliations":[],"email":null},{"person_name":{"surname":"Trinkl","first_name":"E"},"affiliations":[],"email":null},{"person_name":{"surname":"Bustos","first_name":"B"},"affiliations":[],"email":null},{"person_name":{"surname":"Schreck","first_name":"T"},"affiliations":[],"email":null}],"date":{"year":"2022","month":null,"day":null},"ids":{"DOI":"10.2312/GCH.20221234","arXiv":null},"target":"https://diglib.eg.org/handle/10.2312/gch20221234.doi:10.2312/GCH.20221234","publisher":"The Eurographics Association","journal":null,"series":null,"scope":{"volume":9,"pages":null}},"b20":{"title":"RePaint: Inpainting using Denoising Diffusion Probabilistic Models","authors":[{"person_name":{"surname":"Lugmayr","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Danelljan","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Romero","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Yu","first_name":"F"},"affiliations":[],"email":null},{"person_name":{"surname":"Timofte","first_name":"R"},"affiliations":[],"email":null},{"person_name":{"surname":"Van Gool","first_name":"L"},"affiliations":[],"email":null}],"date":{"year":"2022","month":null,"day":null},"ids":{"DOI":null,"arXiv":"arXiv:2201.09865"},"target":"http://arxiv.org/abs/2201.09865","publisher":null,"journal":null,"series":null,"scope":null},"b21":{"title":"DiffusER: Discrete Diffusion via Edit-based Reconstruction","authors":[{"person_name":{"surname":"Reid","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Hellendoorn","first_name":"V"},"affiliations":[],"email":null},{"person_name":{"surname":"Neubig","first_name":"G"},"affiliations":[],"email":null}],"date":{"year":"2022","month":null,"day":null},"ids":{"DOI":null,"arXiv":"arXiv:2210.16886"},"target":"http://arxiv.org/abs/2210.16886","publisher":null,"journal":null,"series":null,"scope":null},"b22":{"title":"Diffusion-LM Improves Controllable Text Generation","authors":[{"person_name":{"surname":"Li","first_name":"X"},"affiliations":[],"email":null},{"person_name":{"surname":"Thickstun","first_name":"J"},"affiliations":[],"email":null},{"person_name":{"surname":"Gulrajani","first_name":"I"},"affiliations":[],"email":null},{"person_name":{"surname":"Liang","first_name":"P"},"affiliations":[],"email":null},{"person_name":{"surname":"Hashimoto","first_name":"T"},"affiliations":[],"email":null}],"date":{"year":"2022","month":null,"day":null},"ids":{"DOI":null,"arXiv":"arXiv:2205.14217"},"target":"http://arxiv.org/abs/2205.14217","publisher":null,"journal":null,"series":null,"scope":null},"b23":{"title":"The Oxford Handbook of Roman Epigraphy","authors":[{"person_name":{"surname":"Bruun","first_name":"C"},"affiliations":[],"email":null},{"person_name":{"surname":"Edmondson","first_name":"J"},"affiliations":[],"email":null}],"date":{"year":"2015","month":null,"day":null},"ids":null,"target":null,"publisher":"Oxford University Press","journal":null,"series":null,"scope":null},"b24":{"title":"LatEpig (version 2.0)","authors":[{"person_name":{"surname":"Ballsun-Stanton","first_name":"B"},"affiliations":[],"email":null},{"person_name":{"surname":"Heřmánková","first_name":"P"},"affiliations":[],"email":null},{"person_name":{"surname":"Laurence","first_name":"R"},"affiliations":[],"email":null}],"date":{"year":"2022","month":null,"day":null},"ids":{"DOI":"10.5281/zenodo.5211341","arXiv":null},"target":"https://github.com/mqAncientHistory/Lat-Epig/.doi:10.5281/zenodo.5211341","publisher":"GitHub","journal":null,"series":null,"scope":null},"b25":{"title":"Big Bird: Transformers for Longer Sequences","authors":[{"person_name":{"surname":"Zaheer","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Guruganesh","first_name":"G"},"affiliations":[],"email":null},{"person_name":{"surname":"Dubey","first_name":"K"},"affiliations":[],"email":null},{"person_name":{"surname":"Ainslie","first_name":"J"},"affiliations":[],"email":null},{"person_name":{"surname":"Alberti","first_name":"C"},"affiliations":[],"email":null},{"person_name":{"surname":"Ontanon","first_name":"S"},"affiliations":[],"email":null},{"person_name":{"surname":"Pham","first_name":"P"},"affiliations":[],"email":null},{"person_name":{"surname":"Ravula","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Wang","first_name":"Q"},"affiliations":[],"email":null},{"person_name":{"surname":"Yang","first_name":"L"},"affiliations":[],"email":null},{"person_name":{"surname":"Ahmed","first_name":"A"},"affiliations":[],"email":null}],"date":{"year":"2020","month":null,"day":null},"ids":null,"target":"https://proceedings.neurips.cc/paper/2020/file/c8512d142a2d849725f31a9a7a361ab9-Paper.pdf","publisher":"Curran Associates, Inc","journal":null,"series":null,"scope":{"volume":33,"pages":{"from_page":17283,"to_page":17297}}}},"sections":[{"title":"Introduction","paragraphs":[{"text":"Epigraphy is the study of inscriptions, which can be described as text engraved on any durable material, such as stone and metals, but also painted text on almost all kind of surfaces [1].","refs":[{"start":184,"end":187,"marker":"bibr","target":"#b0"}]},{"text":"In the ancient Roman society, inscriptions were used for numerous different purposes, such as military records, juridical records and public notices. Their wide use makes inscriptions an invaluable evidence of the past [2]. For instance, honorary inscriptions give us information about the cursus honorum, the sequence of public offices held by aspiring politicians in the Roman Republic [1].","refs":[{"start":219,"end":222,"marker":"bibr","target":"#b1"},{"start":388,"end":391,"marker":"bibr","target":"#b0"}]},{"text":"The material on which the inscriptions were carved upon is subject to deterioration over time. It is estimated that only between 2% and 3% of all Latin inscriptions have survived to this day [1]. For instance, a slab of stone could be missing some parts due to crumbling and thus creating a gap in the text. This newly created gap is commonly referred to as lacuna. The presence of lacunae in an inscription makes it partially or completely illegible (Figure 1). The process of filling these lacunae is time-consuming and requires the involvement of an expert epigraphist, who has to conjecture the size of the gap as well as the content of the missing text.","refs":[{"start":191,"end":194,"marker":"bibr","target":"#b0"},{"start":459,"end":460,"marker":"figure","target":"#fig_0"}]},{"text":"The standard epigraphic convention for reporting these conjectures is to put the presumed text within square brackets [3].","refs":[{"start":118,"end":121,"marker":"bibr","target":"#b2"}]},{"text":"During the years, there have been several attempts to create corpora that collect all available inscriptions for specific languages. Two notable examples for Latin inscriptions are the Corpus Inscriptionum Latinarum (CIL) [4] and L'Année épigraphique (AE) [5]. These corpora also contain, for each inscription, the interpretations made by the epigraphists regarding the resolution of abbreviated texts, and the addition of missing text.","refs":[{"start":222,"end":225,"marker":"bibr","target":"#b3"},{"start":256,"end":259,"marker":"bibr","target":"#b4"}]},{"text":"The objective of this paper is to present our research project for ancient Latin inscriptions restoration. We will describe our action plan to develop a neural network aided companion tool for scholars to speed-up the restoration process, by presenting our proposals of four different deep learning architectures based on previous literature and innovative ideas. Our work focuses on Latin inscriptions, as this ancient language still lacks automatic tools for filling lacunae and it has been investigated less than other ancient languages (e.g., Ancient Greek). This specific type of inscription is written for the most part in the Latin language but may also contain Greek words or transliteration of them, as well as lexical borrowings and hybridisation with foreign languages [1].","refs":[{"start":780,"end":783,"marker":"bibr","target":"#b0"}]},{"text":"The joint research group will be composed of epigraphy experts from the Department of Humanities and Cultural Heritage, as well as deep learning experts form the Department of Mathematics, Computer Science, and Physics of the University of Udine. Thanks to this interdisciplinary expertise we will be able to solve a problem that will benefit both research fields.","refs":[]},{"text":"In fact, aside from the humanistic point of view, the problem of filling lacunae in Latin is nevertheless a challenging problem from the deep learning perspective, since these kinds of methods require to be trained on a large amount of data, which is not available when working with an ancient language such as Latin. ","refs":[]}]},{"title":"Related work","paragraphs":[{"text":"In the recent years, there has been a growing focus on the adoption of Artificial Intelligence (AI) for the analysis of historical documents [6]. For example, AI has been applied to the study of Ancient Christian inscriptions in order to automatically extract new information by analysing their features (e.g., language used, writing style, and material) [7], or to develop tools such as HisDoc [8] to analyse medieval Latin manuscripts from the 9th century.","refs":[{"start":141,"end":144,"marker":"bibr","target":"#b5"},{"start":355,"end":358,"marker":"bibr","target":"#b6"},{"start":395,"end":398,"marker":"bibr","target":"#b7"}]},{"text":"PYTHIA [9] was the first deep learning model capable to perform fully-automated ancient text restoration. It is able to fill the lacunae in damaged ancient Greek inscriptions using a sequence-to-sequence architecture with a bidirectional-LSTM encoder. In order to restore incomplete and missing words, it works at both word and character level, which also allows it to build a better internal word representation [10].","refs":[{"start":7,"end":10,"marker":"bibr","target":"#b8"},{"start":413,"end":417,"marker":"bibr","target":"#b9"}]},{"text":"When it comes to restoring Greek inscriptions, Ithaca [11] is the state of the art. In order to enable large-scale processing, it uses a Transformers-based architecture. Additionally to filling lacunae, Ithaca can also determine the original location of an inscription and place it in time.","refs":[{"start":54,"end":58,"marker":"bibr","target":"#b10"}]},{"text":"PYTHIA and Ithaca have demonstrated that the adoption of this kind of assistive tools can improve both the accuracy and the speed of the epigraphist's restoration activity.","refs":[]},{"text":"The problem of filling lacunae in ancient texts can be seen as a specific case of what in NLP is generally referred to as text infilling [12], which is the task of filling the gaps in a text. This, in turn, is a generalisation of the cloze task. Recently, there have been some advancements in this field thanks to researchers adapting Language Models to perform text infilling [13]. As an example, the Blank Language Model (BlankLM) [14] generates sequences of text by dynamically creating and filling gaps, and it has also been used to perform ancient text restoration, showing an accuracy similar to PYTHIA's.","refs":[{"start":137,"end":141,"marker":"bibr","target":"#b11"},{"start":377,"end":381,"marker":"bibr","target":"#b12"},{"start":433,"end":437,"marker":"bibr","target":"#b13"}]},{"text":"The use of a Masked Language Modeling (MLM) approach has been proven to be effective not only for the restoration of ancient documents, but also for their translation [15]. A recent work [16] proposed a different approach for restoring texts written in the Akkadian language, 1 showing that it is possible to use a pretrained multi-language Language Model such as Multilingual-BERT [17] and fine-tune it on a small dataset, such as the Akkadian language one, to achieve state-of-the-art performances.","refs":[{"start":167,"end":171,"marker":"bibr","target":"#b14"},{"start":187,"end":191,"marker":"bibr","target":"#b15"},{"start":382,"end":386,"marker":"bibr","target":"#b16"}]},{"text":"When it comes to the Latin language, Latin BERT [18] has been proposed, a contextual language model, trained on a corpus of documents spanning from the Classical era to contemporary sources. Due to the expensiveness of training a BERT [17] model, both in terms of computational requirements and data availability, researchers have also proposed an ELECTRA-based model [19] trained on the Latin language.","refs":[{"start":48,"end":52,"marker":"bibr","target":"#b17"},{"start":235,"end":239,"marker":"bibr","target":"#b16"},{"start":368,"end":372,"marker":"bibr","target":"#b18"}]},{"text":"Interestingly, the problem of filling lacunae can also be framed in the context of image processing, as it is akin to the task of completing patterns on ancient pottery [20]. This is a particular case of the most general inpainting task in computer vision for which, recently, methods based on diffusion models such as RePaint [21] have been proposed. Additionally, although diffusion models are mainly used for computer vision tasks, recently they have been also applied to the field of NLP, making them an interesting method to bridge these two fields. 1 Between the Late Bronze and Early Iron Ages, the Akkadian language was the lingua franca used in the Middle East For instance, DiffusER [22] and Diffusion-LM [23] are two generative text models based on denoising diffusion models. The first one is a discrete diffusion model that corrupts the text by applying the four Levenshtein edit operations,2 while the second one is a continuous diffusion model where the diffusion process is continuously applied to word embeddings.","refs":[{"start":169,"end":173,"marker":"bibr","target":"#b19"},{"start":327,"end":331,"marker":"bibr","target":"#b20"},{"start":693,"end":697,"marker":"bibr","target":"#b21"},{"start":715,"end":719,"marker":"bibr","target":"#b22"},{"start":904,"end":905,"marker":null,"target":"#foot_0"}]}]},{"title":"Methodology","paragraphs":[{"text":"Many of the physical epigraphic corpora have been digitised and are available as part of various online corpora. These corpora contain not only the transcription of the text of an inscription, but also the annotations made by expert epigraphists when performing restoration. For example, they correct obvious misspelled words, they estimate the number of missing characters and words, as well as make conjectures on how to fill the lacunae. All this additional information is valuable for the restoration task, but given the large number of different sources, the potential presence of noise, and the heterogeneity of the annotation styles, it becomes necessary to perform some data cleaning and normalisation of the input text to make it machine-readable. In order to do so, a pipeline specific for Latin inscriptions will be created, analogously to what has already been done for Ancient Greek [9] [11].","refs":[{"start":896,"end":899,"marker":"bibr","target":"#b8"},{"start":900,"end":904,"marker":"bibr","target":"#b10"}]},{"text":"The newly acquired data will be used to train a model on Ithaca's architecture, which currently represents the state-of-the-art for the restoration of Greek inscriptions, thus obtaining a baseline for the Latin language. Then, we will develop and analyse three new different approaches to improve on the baseline performance.","refs":[]}]},{"title":"Dataset","paragraphs":[{"text":"One of the main issues when working with ancient languages such as Latin is the scarcity of available data. For historical reasons, the most important corpora of Latin inscription were available only on physical media, namely books. In the recent years, there have been efforts to digitise them all. This research will make use of the Epigraphik-Datenbank Clauss/Slaby (EDCS) 3 , an online database comprehensive of 45 different corpora, including the Corpus Inscriptionum Latinarum, which contains inscriptions until the Fall of the Western Roman Empire, and L'Année épigraphique, a collection of inscriptions, mainly in Latin or Ancient Greek, concerning Ancient Rome. The database is also updated with new findings not available in any printed work and inscriptions originating from numerous online corpora such those part of the EAGLE (Europeana Network for Greek and Latin Epigraphy) 4 project, which gathers the information collected by EDB 5 , EDR 6 , EDH 7 and other European epigraphic database. The database contains the transcription of approximately 532 thousands Greek-Latin inscriptions, and it is the most extensive digital resource of Latin inscriptions [24].","refs":[{"start":376,"end":377,"marker":null,"target":"#foot_1"},{"start":889,"end":890,"marker":null,"target":"#foot_2"},{"start":947,"end":948,"marker":null,"target":"#foot_3"},{"start":955,"end":956,"marker":null,"target":"#foot_4"},{"start":963,"end":964,"marker":null,"target":"#foot_5"},{"start":1170,"end":1174,"marker":"bibr","target":"#b23"}]},{"text":"Each inscription is annotated, when available, with the hypothesis made by expert epigraphist about the number of missing characters that form the lacunae and the eventual conjecture of the missing words, including the reconstruction of abbreviations, and the correction of obvious misspellings by inserting or erasing characters.","refs":[]},{"text":"In addition to the full transcript of the inscription, EDCS makes use of some special characters to report the conjectures made by the epigraphists. For example, Figure 2 reports the transcript of the damaged inscription in Figure 1, taken from EDCS, where the symbol [3] is used to represent a lacuna within the line. To acquire the inscriptions we will make use of the Latin Epigraphy Scraper (LatEpig) [25], a tool able to extract information from EDCS in an easy to read format (e.g. json).","refs":[{"start":169,"end":170,"marker":"figure","target":"#fig_1"},{"start":231,"end":232,"marker":"figure","target":"#fig_0"},{"start":268,"end":271,"marker":"bibr","target":"#b2"},{"start":405,"end":409,"marker":"bibr","target":"#b24"}]}]},{"title":"Models","paragraphs":[{"text":"This research project will study four different approaches (Figure 3) to solve the problem of filling lacunae in Latin inscriptions.","refs":[{"start":67,"end":68,"marker":"figure","target":"#fig_2"}]},{"text":"The first approach (Figure 3a) is to adopt the same Transformer architecture used by Ithaca, inspired by the BigBird [26] model, which is currently the state of the art for restoring ancient Greek inscriptions. The output sequence, generated by Ithaca's torso starting from the text of the inscription where the characters to be restored are marked with the \"?\" symbol, is then given as input to a two-layer feedforward network followed by a softmax function which handles the restoration task, returning the predicted characters. Since Ithaca is the state-ofthe-art for ancient Greek inscriptions, it could also serve as a baseline for Latin inscriptions. Since Transformer models can be expensive to train, in the eventuality that this represent a problem, the Transformer architecture will be replaced with an LSTM-based sequence to sequence architecture, similar to the one proposed by PYTHIA.","refs":[{"start":27,"end":29,"marker":"figure","target":"#fig_2"},{"start":117,"end":121,"marker":"bibr","target":"#b25"}]},{"text":"The second approach (Figure 3b) is based on the one proposed by [16] for the Akkadian language, which identified that the problem of restoring text corresponds to the objective of the Masked Language Modeling task in NLP. Thus, it is possible to restore inscriptions using a fine-tuned pretrained Language Model, such as Multilingual BERT. This approach was proven to be effective in context where the amount of training data is scarce, as in the case of ancient languages. As regards the pretrained model, Multilingual BERT was trained on 104 different languages (including Latin), so it is a suitable candidate. Furthermore, it has also been proposed a BERT-based model pre-trained on a Latin corpus consisting of 642.7 million tokens and containing documents spanning for 22 centuries. This implies that the model has also been trained on documents which are not coeval with the inscriptions contained in EDCS. Despite this, Latin BERT could still be more suitable that Multilingual BERT for fine-tuning thanks to its focus on the Latin language, so it will be taken into considerations in our experiments.","refs":[{"start":28,"end":30,"marker":"figure","target":"#fig_2"},{"start":64,"end":68,"marker":"bibr","target":"#b15"}]},{"text":"The third approach (Figure 3c) will investigate a possible application of diffusion-based models, given their remarkable results in the inpainting task in computer vision, as well as their recent applications to the NLP field for text generation. This approach will consider the advancements in conditional text generation [23], as it is an essential feature in order to perform text infilling and for being able to control the length of the output, which are both desirable features in our scenario. A Diffusion model works by gradually denoising some random Gaussian Noise using a neural network, in order to synthesize new data. To be able to control this generation process, DiffusionLM proposed to use a classifier, which measures how well the generated text satisfies some constraints.","refs":[{"start":27,"end":29,"marker":"figure","target":"#fig_2"},{"start":323,"end":327,"marker":"bibr","target":"#b22"}]},{"text":"The main limitation of the first and second approaches is that they rely heavily on the conjectures made by expert epigraphists regarding the size of the lacunae and the number of missing characters. These conjectures might be erroneous and lead to low-quality model predictions. The fourth approach (Figure 3d) aims to bypass this limitation by using the same strategy adopted by BlankLM, a model capable of generating sequences of text by fillings the gaps, and possibly introducing new ones (given the predicted word, a MLP determines whether to introduce a new blank on the left of the word, on the right, on both, or none), and repeating the process until all blanks are filled. Doing so, it is possible to fill a lacuna without knowing its exact size. In particular, BlankLM has shown great performance for the restoration of Greek inscriptions, therefore the same approach could also be applied to Latin inscriptions.","refs":[{"start":308,"end":310,"marker":"figure","target":"#fig_2"}]}]},{"title":"Conclusions","paragraphs":[{"text":"Despite the presence of encouraging studies that show the effectiveness of automatic methods to fill lacunae in ancient texts, this field is still rather unexplored and leaves great opportunities to develop new technologies and create better tools to aid the experts, especially for the Latin language.","refs":[]},{"text":"This paper describes the foundations and objectives of our research project, which aims to build a deep learning model to restore ancient Latin inscriptions. To this end, first we identified a suitable database which comprises several ancient Greek-Latin inscriptions coming from different renowned corpora. We plan to develop a comprehensive pipeline to pre-process the data, denoise them, normalise them and unify their annotation schema. Finally, we identified four promising deep-learning approaches to fill the lacunae in the Latin texts, based on different techniques. The first one is based on the current state-of-the-art model used to restore ancient Greek inscriptions, the second one relies on pretrained language models, the third one leverages the recent advancement in the field of computer vision and diffusion models, and a final one aims to bypass the limitations of the first and the third proposal, that is the need for epigraphists' conjectures about the dimension of the lacunae.","refs":[]},{"text":"The project will be carried out by a multi-disciplinary team, and it aims to create useful and powerful deep-learning tools to assist expert epigraphists in the task of restoring ancient inscriptions.","refs":[]},{"text":"If successful, the proposed approaches could be easily applied to any other ancient language or, indeed, to any language with limited data availability.","refs":[]}]}],"tables":{},"abstract":{"title":"Abstract","paragraphs":[{"text":"Inscriptions are a testimony to the past but their poor condition, caused by the deterioration of the material on which they are engraved upon, often makes them partially or completely illegible. The process of restoring these inscriptions is time-consuming and requires the involvement of an expert epigraphist. It is possible to speed-up this process by adopting a semi-automatic assisting tool based on deep neural networks. This work describes a methodology, from the acquisition of the inscriptions to the description of four possible approaches, to predict the missing text in a Latin inscription, that our research team plans to implement in the near future as part of an interdisciplinary research project.","refs":[]}]}}