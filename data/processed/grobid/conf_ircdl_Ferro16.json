{"bibliography":{"title":"Proposal for an Evaluation Framework for Compliance Checkers for Long-Term Digital Preservation","authors":[{"person_name":{"surname":"Ferro","first_name":"Nicola"},"affiliations":[{"department":"Department of Information Engineering","institution":"University of Padua","laboratory":null}],"email":"ferro@dei.unipd.it"}],"date":null,"ids":{"DOI":"10.1007/978-3-319-56300-8","arXiv":null},"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"keywords":[],"citations":{"b0":{"title":"Implementing crowdsourcing-based relevance experimentation: an industrial perspective","authors":[{"person_name":{"surname":"Alonso","first_name":"O"},"affiliations":[],"email":null}],"date":{"year":"2013","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"Inf. Retrieval","series":null,"scope":{"volume":16,"pages":{"from_page":101,"to_page":120}}},"b1":{"title":"Introduction to Machine Learning","authors":[{"person_name":{"surname":"Alpaydin","first_name":"E"},"affiliations":[],"email":null}],"date":{"year":"2014","month":null,"day":null},"ids":null,"target":null,"publisher":"The MIT Press","journal":null,"series":null,"scope":null},"b2":{"title":"A comparison of extrinsic clustering evaluation metrics based on formal constraints","authors":[{"person_name":{"surname":"Amigó","first_name":"E"},"affiliations":[],"email":null},{"person_name":{"surname":"Gonzalo","first_name":"J"},"affiliations":[],"email":null},{"person_name":{"surname":"Artiles","first_name":"J"},"affiliations":[],"email":null},{"person_name":{"surname":"Verdejo","first_name":"M"},"affiliations":[],"email":null}],"date":{"year":"2009","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"Inf. Retrieval","series":null,"scope":{"volume":12,"pages":{"from_page":461,"to_page":486}}},"b3":{"title":"A general evaluation measure for document organization tasks","authors":[{"person_name":{"surname":"Amigó","first_name":"E"},"affiliations":[],"email":null},{"person_name":{"surname":"Gonzalo","first_name":"J"},"affiliations":[],"email":null},{"person_name":{"surname":"Verdejo","first_name":"M"},"affiliations":[],"email":null}],"date":{"year":"2013","month":null,"day":null},"ids":null,"target":null,"publisher":"ACM Press","journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":643,"to_page":652}}},"b4":{"title":"Free benchmark corpora for preservation experiments: using model-driven engineering to generate data sets","authors":[{"person_name":{"surname":"Becker","first_name":"C"},"affiliations":[],"email":null},{"person_name":{"surname":"Duretec","first_name":"K"},"affiliations":[],"email":null}],"date":{"year":"2013","month":null,"day":null},"ids":null,"target":null,"publisher":"ACM Press","journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":349,"to_page":358}}},"b5":{"title":"The Challenge of Test Data Quality in Data Processing","authors":[{"person_name":{"surname":"Becker","first_name":"C"},"affiliations":[],"email":null},{"person_name":{"surname":"Duretec","first_name":"K"},"affiliations":[],"email":null},{"person_name":{"surname":"Rauber","first_name":"A"},"affiliations":[],"email":null}],"date":{"year":"2016","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"ACM J. Data Inf. Qual. (JDIQ)","series":null,"scope":{"volume":8,"pages":null}},"b6":{"title":"Decision criteria in digital preservation: what to measure and how","authors":[{"person_name":{"surname":"Becker","first_name":"C"},"affiliations":[],"email":null},{"person_name":{"surname":"Rauber","first_name":"A"},"affiliations":[],"email":null}],"date":{"year":"2011","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"J. Am. Soc. Inform. Sci. Technol. (JASIST)","series":null,"scope":{"volume":62,"pages":{"from_page":1009,"to_page":1028}}},"b7":{"title":"The PREFORMA project: federating memory institutions for better compliance of preservation formats","authors":[{"person_name":{"surname":"Cappellato","first_name":"L"},"affiliations":[],"email":null},{"person_name":{"surname":"Ferro","first_name":"N"},"affiliations":[],"email":null},{"person_name":{"surname":"Fresa","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Geber","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Justrell","first_name":"B"},"affiliations":[],"email":null},{"person_name":{"surname":"Lemmens","first_name":"B"},"affiliations":[],"email":null},{"person_name":{"surname":"Prandoni","first_name":"C"},"affiliations":[],"email":null},{"person_name":{"surname":"Silvello","first_name":"G"},"affiliations":[],"email":null}],"date":{"year":"2016","month":null,"day":null},"ids":{"DOI":"10.1007/978-3-319-41938-1_10","arXiv":null},"target":null,"publisher":"Springer","journal":null,"series":null,"scope":{"volume":612,"pages":{"from_page":86,"to_page":91}}},"b8":{"title":"Issues in digital preservation: towards a new research agenda","authors":[{"person_name":{"surname":"Chanod","first_name":"J"},"affiliations":[],"email":null},{"person_name":{"surname":"Dobreva","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Rauber","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Ross","first_name":"S"},"affiliations":[],"email":null},{"person_name":{"surname":"Casarosa","first_name":"V"},"affiliations":[],"email":null}],"date":{"year":"2010","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":"Dagstuhl Reports","scope":{"volume":null,"pages":{"from_page":1,"to_page":14}}},"b9":{"title":"The Cranfield tests on index languages devices","authors":[{"person_name":{"surname":"Cleverdon","first_name":"C"},"affiliations":[],"email":null}],"date":null,"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":47,"to_page":60}}},"b10":{"title":"TREC 2005 spam track overview","authors":[{"person_name":{"surname":"Cormack","first_name":"G"},"affiliations":[],"email":null},{"person_name":{"surname":"Lynam","first_name":"T"},"affiliations":[],"email":null}],"date":{"year":"2005","month":null,"day":null},"ids":null,"target":null,"publisher":"Special Publication","journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":500,"to_page":266}}},"b11":{"title":"Benchmarks for digital preservation tools","authors":[{"person_name":{"surname":"Duretec","first_name":"K"},"affiliations":[],"email":null},{"person_name":{"surname":"Kulmukhametov","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Rauber","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Becker","first_name":"C"},"affiliations":[],"email":null}],"date":{"year":"2015","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"b12":{"title":"Deliverable D2.1 -Overall Roadmap","authors":[{"person_name":{"surname":"Elfner","first_name":"P"},"affiliations":[],"email":null},{"person_name":{"surname":"Justrell","first_name":"B"},"affiliations":[],"email":null}],"date":{"year":"2014","month":"06","day":null},"ids":null,"target":"http://www.digitalmeetsculture.net/wp-content/uploads/2014/05/PREFORMAD2.1Overall-Roadmapv2.5.pdf","publisher":null,"journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":619568,"to_page":619568}}},"b13":{"title":"An introduction to ROC analysis","authors":[{"person_name":{"surname":"Fawcett","first_name":"T"},"affiliations":[],"email":null}],"date":{"year":"2006","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"Pattern Recogn. Lett","series":null,"scope":{"volume":27,"pages":{"from_page":861,"to_page":874}}},"b14":{"title":"An experimental comparison of performance measures for classification","authors":[{"person_name":{"surname":"Ferri","first_name":"C"},"affiliations":[],"email":null},{"person_name":{"surname":"Hernández-Orallo","first_name":"J"},"affiliations":[],"email":null},{"person_name":{"surname":"Modroiu","first_name":"R"},"affiliations":[],"email":null}],"date":{"year":"2009","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"Pattern Recogn. Lett","series":null,"scope":{"volume":30,"pages":{"from_page":27,"to_page":38}}},"b15":{"title":"Reproducibility challenges in information retrieval evaluation","authors":[{"person_name":{"surname":"Ferro","first_name":"N"},"affiliations":[],"email":null}],"date":{"year":"2017","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"ACM J. Data Inf. Qual. (JDIQ)","series":null,"scope":{"volume":8,"pages":{"from_page":4,"to_page":4}}},"b16":{"title":"Deliverable D8.1R2 -Competitive Evaluation Strategy","authors":[{"person_name":{"surname":"Ferro","first_name":"N"},"affiliations":[],"email":null},{"person_name":{"surname":"Buelinckx","first_name":"E"},"affiliations":[],"email":null},{"person_name":{"surname":"Doubrov","first_name":"B"},"affiliations":[],"email":null},{"person_name":{"surname":"Jadeglans","first_name":"K"},"affiliations":[],"email":null},{"person_name":{"surname":"Lemmens","first_name":"B"},"affiliations":[],"email":null},{"person_name":{"surname":"Martinez","first_name":"J"},"affiliations":[],"email":null},{"person_name":{"surname":"Muñoz","first_name":"V"},"affiliations":[],"email":null},{"person_name":{"surname":"Prandoni","first_name":"C"},"affiliations":[],"email":null},{"person_name":{"surname":"Rice","first_name":"D"},"affiliations":[],"email":null},{"person_name":{"surname":"Rohde-Enslin","first_name":"S"},"affiliations":[],"email":null},{"person_name":{"surname":"Tarres","first_name":"X"},"affiliations":[],"email":null},{"person_name":{"surname":"Verbruggen","first_name":"E"},"affiliations":[],"email":null},{"person_name":{"surname":"Yousefi","first_name":"B"},"affiliations":[],"email":null},{"person_name":{"surname":"Wilson","first_name":"C"},"affiliations":[],"email":null}],"date":{"year":"2016","month":"10","day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":619568,"to_page":619568}}},"b17":{"title":"Increasing reproducibility in IR: findings from the Dagstuhl Seminar on \"Reproducibility of Data-Oriented Experiments in e-Science","authors":[{"person_name":{"surname":"Ferro","first_name":"N"},"affiliations":[],"email":null},{"person_name":{"surname":"Fuhr","first_name":"N"},"affiliations":[],"email":null},{"person_name":{"surname":"Järvelin","first_name":"K"},"affiliations":[],"email":null},{"person_name":{"surname":"Kando","first_name":"N"},"affiliations":[],"email":null},{"person_name":{"surname":"Lippold","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Zobel","first_name":"J"},"affiliations":[],"email":null}],"date":{"year":"2016","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"SIGIR Forum","series":null,"scope":{"volume":50,"pages":{"from_page":68,"to_page":82}}},"b18":{"title":"Digital audio interface -Part 1: General","authors":[],"date":{"year":"2014","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"b19":{"title":"Assessing digital preservation frameworks: the approach of the SHAMAN project","authors":[{"person_name":{"surname":"Innocenti","first_name":"P"},"affiliations":[],"email":null},{"person_name":{"surname":"Ross","first_name":"S"},"affiliations":[],"email":null},{"person_name":{"surname":"Maceviciute","first_name":"E"},"affiliations":[],"email":null},{"person_name":{"surname":"Wilson","first_name":"T"},"affiliations":[],"email":null},{"person_name":{"surname":"Ludwig","first_name":"J"},"affiliations":[],"email":null},{"person_name":{"surname":"Pempe","first_name":"W"},"affiliations":[],"email":null}],"date":{"year":"2009","month":null,"day":null},"ids":null,"target":null,"publisher":"ACM Press","journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":412,"to_page":416}}},"b20":{"title":"Electronic still-picture imaging -Removable memory -Part 2: TIFF/EP image data format","authors":[],"date":{"year":"2001","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"b21":{"title":"Graphic technology -Prepress digital data exchange -Tag image file format for image technology (TIFF/IT)","authors":[],"date":{"year":"2004","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"b22":{"title":"ISO 14721: Space data and information transfer systems -Open archival information system (OAIS) -Reference model","authors":[],"date":{"year":"2012","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"b23":{"title":"Before the repository: defining the preservation threats to research data in the lab","authors":[{"person_name":{"surname":"Kowalczyk","first_name":"S"},"affiliations":[],"email":null}],"date":{"year":"2015","month":null,"day":null},"ids":null,"target":null,"publisher":"ACM Press","journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":215,"to_page":222}}},"b24":{"title":"Crowdsourcing for information retrieval: introduction to the special issue","authors":[{"person_name":{"surname":"Lease","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Yilmaz","first_name":"E"},"affiliations":[],"email":null}],"date":{"year":"2013","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"Inf. Retrieval","series":null,"scope":{"volume":16,"pages":{"from_page":91,"to_page":100}}},"b25":{"title":"Digital preservation, archival science and methodological foundations for digital libraries","authors":[{"person_name":{"surname":"Ross","first_name":"S"},"affiliations":[],"email":null}],"date":{"year":"2012","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"New Rev. Inf. Networking","series":null,"scope":{"volume":17,"pages":{"from_page":43,"to_page":68}}},"b26":{"title":"Test collection based evaluation of information retrieval systems","authors":[{"person_name":{"surname":"Sanderson","first_name":"M"},"affiliations":[],"email":null}],"date":{"year":"2010","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"Found. Trends Inf. Retrieval (FnTIR)","series":null,"scope":{"volume":4,"pages":{"from_page":247,"to_page":375}}},"b27":{"title":"Machine learning in automated text categorization","authors":[{"person_name":{"surname":"Sebastiani","first_name":"F"},"affiliations":[],"email":null}],"date":{"year":"2002","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"ACM Comput. Surv. (CSUR)","series":null,"scope":{"volume":34,"pages":{"from_page":1,"to_page":47}}},"b28":{"title":"Overview of the TREC 2012 crowdsourcing track","authors":[{"person_name":{"surname":"Smucker","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Kazai","first_name":"G"},"affiliations":[],"email":null},{"person_name":{"surname":"Lease","first_name":"M"},"affiliations":[],"email":null}],"date":{"year":"2013","month":null,"day":null},"ids":null,"target":null,"publisher":"Special Publication","journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":500,"to_page":298}}},"b29":{"title":"Ranking retrieval systems without relevance judgments","authors":[{"person_name":{"surname":"Soboroff","first_name":"I"},"affiliations":[],"email":null},{"person_name":{"surname":"Nicholas","first_name":"C"},"affiliations":[],"email":null},{"person_name":{"surname":"Cahan","first_name":"P"},"affiliations":[],"email":null}],"date":{"year":"2001","month":null,"day":null},"ids":null,"target":null,"publisher":"ACM Press","journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":66,"to_page":73}}},"b30":{"title":"A systematic analysis of performance measures for classification tasks","authors":[{"person_name":{"surname":"Sokolova","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Lapalme","first_name":"G"},"affiliations":[],"email":null}],"date":{"year":"2009","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"Inf. Process. Manage","series":null,"scope":{"volume":45,"pages":{"from_page":427,"to_page":437}}},"b31":{"title":"Variations in relevance judgments and the measurement of retrieval effectiveness","authors":[{"person_name":{"surname":"Voorhees","first_name":"E"},"affiliations":[],"email":null}],"date":{"year":"2000","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"Inf. Process. Manage","series":null,"scope":{"volume":36,"pages":{"from_page":697,"to_page":716}}}},"sections":[{"title":"Introduction","paragraphs":[{"text":"The PREservation FORMAts for culture information/e-archives (PREF-ORMA) 1 project is a Pre-Commercial Procurement (PCP) project focused on conformity checking of ingested files for the long-term preservation [8]. The main objective of the project is the development and deployment of an open source software licensed reference implementation for file format standards aimed at any memory institution (or other organisation with a preservation task) wishing to check conformance with a specific standard. This reference implementation, called the conformance checker, will consist of a set of modular tools which will be validated against specific implementations of specifications of standards relevant to the PREFORMA project and used by the European memory institutions for preserving their different kind of data objects.","refs":[{"start":208,"end":211,"marker":"bibr","target":"#b7"}]},{"text":"A conformance checker:","refs":[]},{"text":"-verifies whether a file has been produced according to the specifications of a standard file format, and hence, -verifies whether a file matches the acceptance criteria for long-term preservation by the memory institution, -reports in human and machine readable format which properties deviate from the standard specification and acceptance criteria, and -performs automated fixes for simple deviations in the metadata of the preservation file.","refs":[]},{"text":"The conformance checker software developed by PREFORMA is intended for use within the Open Archival Information System (OAIS) Reference Framework [23] and development is guided by the user requirements provided by the memory institutions that are part of the PREFORMA consortium.","refs":[{"start":146,"end":150,"marker":"bibr","target":"#b22"}]},{"text":"The media types addressed by PREFORMA are: (i) electronic documents for establishing a reference implementation for PDF/A [24-26]; (ii) images for establishing a reference implementation for uncompressed TIFF [21,22]; and, (iii) audio-video for establishing a reference implementation for an audiovisual preservation file, using FFV12 for encoding video or moving images, uncompressed LPCM [19] for encoding sound and MKV3 for wrapping audio-and video-streams in one file.","refs":[{"start":209,"end":213,"marker":"bibr","target":"#b20"},{"start":213,"end":216,"marker":"bibr","target":"#b21"},{"start":333,"end":334,"marker":null,"target":"#foot_0"},{"start":390,"end":394,"marker":"bibr","target":"#b18"},{"start":421,"end":422,"marker":null,"target":"#foot_1"}]},{"text":"Evaluation and validation of the developed conformance checkers is a primary concern in PREFORMA and this paper describes the overall approach and framework we are going to apply to assess the performances of the developed tools.","refs":[]},{"text":"The paper is organized as follows: Section 2 presents some related works in the digital preservation area; Section 3 explains how we frame the conformance checking process as a classification task; Section 4 discusses how we evaluate the performances of the developed conformance checkers; finally, Sect. 5 draws some conclusions and presents an outlook for future work.","refs":[]}]},{"title":"Related Work","paragraphs":[{"text":"\"Digital preservation is about more than keeping the bits [...] It is about maintaining the semantic meaning of the digital object and its content, about maintaining its provenance and authenticity, about retaining its interrelatedness, and about securing information about the context of its creation and use\" [29, p. 45]. Since preservation aims at capturing the very essence of digital objects it is often associated with life cycles [27], preservation actions, and overall preservation frameworks and there is often the need to evaluate them and choose among them [6,7,20].","refs":[{"start":311,"end":321,"marker":"bibr","target":null},{"start":437,"end":441,"marker":"bibr","target":"#b23"},{"start":568,"end":571,"marker":"bibr","target":"#b5"},{"start":571,"end":573,"marker":"bibr","target":"#b6"},{"start":573,"end":576,"marker":"bibr","target":"#b19"}]},{"text":"When it comes to preservation frameworks and their evaluation, this paper focuses on a specific step of a more general preservation framework, namely the checking for conformance of document with respect to their reference standards at ingestion time. In particular, the focus of the paper is on how to evaluate tools for carrying out this step, i.e. conformance checkers, and how to create a benchmark for this purpose.","refs":[]},{"text":"The idea of benchmarking tools for preservation is gaining more and more traction recently [9] and we share a similar approach with [12], who identify the main components of a digital preservation benchmark as:","refs":[{"start":91,"end":94,"marker":"bibr","target":"#b8"},{"start":132,"end":136,"marker":"bibr","target":"#b11"}]},{"text":"motivating comparison defines the comparison to be done and the benefits that comparison will bring in terms of the future research agenda;","refs":[]},{"text":"task sample is a list of tests that the subject, to which a benchmark is applied, is expected to solve; -performance measures are qualitative or quantitative measurements taken by a human or a machine to calculate how fit the subject is for the task.","refs":[]}]},{"title":"Conformance Checking as a Classification Task","paragraphs":[{"text":"The goal of the PREFORMA conformance checkers is to validate documents against their respective standards. This turns into determining, for each document, whether it is compliant, it suffers from issue 1, issue 2, and so on. Therefore, we can model the conformance checking process as a classification task [2], where you label documents according to their characteristics and each label (compliant, issue 1, issue 2, . . .) is a class C i , representing the conformance of or an issue with a document.","refs":[{"start":307,"end":310,"marker":"bibr","target":"#b1"}]},{"text":"In general, classes may intersect, since a document may suffer from multiple issues at the same time, but the compliant class must be a separate one, since you cannot have documents that are compliant and not compliant at the same time, as it is shown in Fig. 1. One of the challenges we have to face is how to determine the list of classes for each the media types targeted by PREFORMA. Domain experts -both from memory institutions and with technical skills on each specific media type -play a central role in this respect, since they can point out known validation issues, potential validation issues, preservation issues also related to policies of memory institutions, and so on.","refs":[{"start":260,"end":261,"marker":"figure","target":"#fig_0"}]},{"text":"One critical aspect in determining such classes is related to their cardinality and granularity. Producing hundreds and hundreds of classes for each media type may be tempting, if you consider this as an indicator of exhaustiveness, but it risks to be harmful in practice, since you may simply ask too much to a conformance checker and you may focus on too tiny or almost irrelevant compliance violations. Therefore, the class creation process must be conducted in an iterative way and domain experts need to work in panels, where they revise and refine each other proposals trying to find the right balance between exhaustiveness and usefulness.","refs":[]},{"text":"In order to provide an additional degree of flexibility to conformance checking, and its evaluation, we plan to also attach a severity to each class since some issues are errors, some others are warnings, some others are mis-conformances to policies and best practices, as it is also shown by the different classes color in Fig. 1. If further analysis and requirements will support it, this could even be turned into a full meta-classification of the identified classes, in order to allow us to group them on the basis of their semantics and relationships and, for example, to express progressive levels of conformance, like core, intermediate and full.","refs":[{"start":329,"end":330,"marker":"figure","target":"#fig_0"}]}]},{"title":"Evaluating Conformance Checkers for Digital Preservation","paragraphs":[{"text":"In order to evaluate conformance checkers, we will rely on the Cranfield paradigm [10], which makes use of experimental collections C = (D, T, GT ), where D is a collection of documents of interest, T is a set of topics and GT is the ground-truth which, for each document d ∈ D and topic t ∈ D, determines the relevance of document d to topic t. In the classification context, this paradigm is instantiated considering the classes C i as topics and the ground-truth is given by the correct labels assigned to each document d [31].","refs":[{"start":82,"end":86,"marker":"bibr","target":"#b9"},{"start":525,"end":529,"marker":"bibr","target":"#b27"}]},{"text":"In terms of the approach proposed by [12], we have that: the motivating comparison is given by the need of assessing conformance checkers; the task sample is defined by the identified classes C i , as discussed in Sect. 3, the gathered documents, as described in Sect. 4.1, and the ground-truth, as presented in Sect. 4.2; the performance measures are described in Sect. 4.3.","refs":[{"start":37,"end":41,"marker":"bibr","target":"#b11"}]},{"text":"The proposed approach also enables a basic level of reproducibility [16,18] of the conducted experiments in the long-term, which we deem essential when it comes to evaluation compliance checkers for long-term preservation.","refs":[{"start":68,"end":72,"marker":"bibr","target":"#b15"},{"start":72,"end":75,"marker":"bibr","target":"#b17"}]}]},{"title":"Document Collections","paragraphs":[{"text":"The preparation of the collection of documents to be used for assessing the performances of a conformance checker is a critical task that needs to be driven by domain experts. We need to gather a huge sample (ten thousands) for each media type (text, image, audio) from the memory institutions participating in PREFORMA, from the suppliers which are developing the conformance checker tools, and from the open source community at large, which is being built around the PREFORMA effort.","refs":[]},{"text":"Documents must be representative of the different classes C i we need to evaluate conformance checkers against. In particular, we cannot have empty classes, i.e. classes for which there is no document in the experimental collection, and the cardinality of each class, i.e. the number of documents in the collection belonging to that class, should make sense from two points of view. Firstly, it should have a size, relative to the other classes, which is proportional to the frequency of the issue represented by the class in real world settings; in other terms, there are issues that happen more frequently and there are issues which are more rare and this should be reflected in the cardinality of the corresponding classes, in order to confront conformance checkers with realistic settings. Secondly, we should pay attention to not introduce any bias in the evaluation measurement and process due to an uncontrolled and excessive discrepancy in the cardinality of the classes.","refs":[]},{"text":"Figure 2 shows the main data set which will be used and made available during the lifetime of the project [13]. The main distinction is between: training dataset: aimed at driving and facilitating the design and development of supplier systems, i.e. conformance checkers, as well as show casing their functionalities; test dataset: aimed at evaluating and testing the supplier systems in order to score and subsequently select the best of them.","refs":[{"start":7,"end":8,"marker":"figure","target":"#fig_1"},{"start":106,"end":110,"marker":"bibr","target":"#b12"}]},{"text":"Test and training datasets are kept as two distinct datasets, i.e. there is no intersection, in order to avoid overfitting supplier system on datasets and to ensure fair and unbiased assessment of them.","refs":[]},{"text":"Both training and test dataset will be associated with ground-truth specifying the correct labels for the documents in the dataset but the ground-truth associated with the test data set will not be shared ahead, because it is needed for carrying out the final testing phase in an unbiased way.","refs":[]},{"text":"More in detail, the test dataset is constituted by representative test data M test j provided by memory institutions that can be either partners of the PREF-ORMA consortium or members of the PREFORMA network of memory institutions. During the execution of the PREFORMA project, this dataset is private and it will be shared only within the consortium to test the supplier systems. After the end of the PREFORMA project, memory institutions may decide to make (part of) it public to favour the PREFORMA ecosystem and open source community.","refs":[]},{"text":"The training dataset is constituted by: (i) representative training data M train k provided by memory institutions that can be either partners of the PREFORMA consortium or members of the PREFORMA network of memory institutions; (ii) representative training data S train k provided by the suppliers participating in the project.","refs":[]},{"text":"The training dataset is constituted by two parts: a demonstration one, which is public and serves the purpose of show casing the suppliers systems both to the other suppliers and to the memory institutions; a private part, which is used internally by each supplier for designing, developing, and testing its own system. Data provided by memory institutions and suppliers which are in the demonstration dataset are accessible and shared also with the other suppliers participating in the project, besides the general public. The purpose of the demonstration dataset is to trigger and facilitate the growth and development of the PREFORMA ecosystem, the open source community, the communication with standardization bodies and, if properly fed, will represent also a strategic asset for suppliers in order to sustain their own business plans.","refs":[]},{"text":"An orthogonal distinction on the datasets is between synthetic and real data. The former are data created with the specific purpose of pinpointing some specific compliance problem or critical issue for a given preservation format, as proposed also by [5]. The latter are data actually managed by memory institutions for their preservation duties. It is intended that both the training and the test datasets will be comprised by both synthetic and real data.","refs":[{"start":251,"end":254,"marker":"bibr","target":"#b4"}]}]},{"title":"Ground-Truth","paragraphs":[{"text":"As it is well known [30], ground-truth creation is an extremely demanding activity since it requires a great amount of human effort to be conducted. For this reason, a lot of research concentrated on how to reduce the burden of groundtruth creation ranging from the utopian attempt to eliminate assessments at all [33] to crowdsourcing [1,28].","refs":[{"start":20,"end":24,"marker":"bibr","target":"#b26"},{"start":314,"end":318,"marker":"bibr","target":"#b29"},{"start":336,"end":339,"marker":"bibr","target":"#b0"},{"start":339,"end":342,"marker":"bibr","target":"#b24"}]},{"text":"Unfortunately, in the context of PREFORMA, crowdsourcing it is not a viable option since real domain experts are needed to carefully judge the compliance of a document to its reference standard.","refs":[]},{"text":"Two interesting questions will arise during ground-truth creation in PREF-ORMA. The first issue is that, to assess the compliance of a document, domain experts will probably also use some of the already existing tools and this may introduce circularity and bias. The second issue is to understand the problem of inter-assessor agreement and see whether on this highly specialised task it will have similar ratios as those for ad-hoc retrieval [35], i.e. in the range 30%-50%, or whether discrepancies from previously known tasks will arise.","refs":[{"start":443,"end":447,"marker":"bibr","target":"#b31"}]},{"text":"The above issues apply in the case of the real data while synthetic data help mitigating the burden of ground-truth creation, because each synthetic document is purposefully created for testing one or more issues in complying to a standard and it is therefore automatically labeled since its creation.","refs":[]}]},{"title":"Measures","paragraphs":[{"text":"Evaluating conformance checkers is not a binary process, i.e. it is not like going through a long check-list and if any of the items in the list is missing or incorrect, the conformance checker is rejected. The evaluation we foresee is more flexible and we aim at quantifying the extent a conformance checker is able to spot deviations from its reference standard.","refs":[]},{"text":"Considering that we frame conformance checking as a classification task, it becomes natural to evaluate it according to the confusion matrix [34] shown in Fig. 3. Recall from Sect. 3 and Fig. 1 that each class C i represents a possible misconformance with respect to a reference standard with the exception of the class C 0 which represents documents fully conforming to the standard.","refs":[{"start":141,"end":145,"marker":"bibr","target":"#b30"},{"start":160,"end":161,"marker":"figure","target":"#fig_2"},{"start":192,"end":193,"marker":"figure","target":"#fig_0"}]},{"text":"In the confusion matrix: True Positve (TP): it is the set of documents that a conformance checker has correctly labeled as belonging to class C i ; True Negative (TN): it is the set of documents that a conformance checker has correctly labeled as not belonging to class C i ; False Positive (FP): it is the set of documents that a conformance checker has incorrectly labeled as belonging to class C i ; False Negative (FN): it is the set of documents that a conformance checker has incorrectly labeled as not belonging to class C i .","refs":[]},{"text":"Note that what we mean by the confusion matrix of Fig. 3 changes if we are considering C 0 , i.e. the class representing a compliant document, or a generic C i , i = 0, i.e. a class representing an issue within a document.","refs":[{"start":55,"end":56,"marker":"figure","target":"#fig_2"}]},{"text":"In the case of C 0 , T P 0 is the set of compliant documents correctly identified as compliant; T N 0 is the set of not compliant documents correctly identified as not compliant; F P 0 is the set of not compliant documents incorrectly identified as compliant; and, F N 0 is the set of compliant documents incorrectly identified as not compliant.","refs":[]},{"text":"In the case of C i , i = 0, T P i is the set of not compliant documents because of issue i correctly identified as suffering from issue i; T N i is the set of documents correctly identified as not suffering from issue i; F P i is the set of documents incorrectly identified as suffering from issue i; F N i is the set of not compliant documents because of issue i but incorrectly identified as not suffering from issue i.","refs":[]},{"text":"Note that the impact of FP and FN is different in the case we are considering C 0 or a generic C i , i = 0. In the case of C 0 , FPs are the worst error for a conformance checker, since they are not conforming documents marked as compliant and thus allowed to proceed in the preservation chain, possibly causing issues in the long term; on the other hand, FNs are a less sever error, since they are compliant documents marked as not compliant which will require some additional work for further checks and fixes (actually not necessary) but, eventually, they will have a chance to go ahead in the preservation chain. In the case of C i , i = 0, FNs are the worst error for a conformance checker, since they are undetected not compliant documents thus allowed to proceed in the preservation chain, possibly causing issues in the long term; on the other hand FPs are just a kind of \"false alarm\", which will require some additional work for further checks and fixes (actually not necessary) but, eventually, they will have a chance to go ahead in the preservation chain.","refs":[]},{"text":"This duality between the harshness of FNs and FPs resembles a similar duality between spam and ham misclassification [11], where spam misclassification annoys the user and may cause the user to overlook important messages while ham misclassification inconveniences the user and risks loss of important messages.","refs":[{"start":117,"end":121,"marker":"bibr","target":"#b10"}]},{"text":"Therefore, we will rely on evaluation measures able both to give a general account of conformance checkers performances and to deal with this duality between FNs and FPs:","refs":[]},{"text":"accuracy: measures the overall effectiveness [34] of a conformance checker as","refs":[{"start":45,"end":49,"marker":"bibr","target":"#b30"}]},{"text":"area under the curve (AUC): measures the ability of a conformance checker to avoid false classification [14,34] as","refs":[{"start":104,"end":108,"marker":"bibr","target":"#b13"},{"start":108,"end":111,"marker":"bibr","target":"#b30"}]},{"text":"logistic average misclassification rate (LAM): is the geometric mean of the odds of compliance and not-compliance misclassification, converted back to a proportion [11,32]. This measure imposes no a priori relative importance on compliance and not-compliance misclassification, and rewards equally a fixed-factor improvement in the odds of either.","refs":[{"start":164,"end":168,"marker":"bibr","target":"#b10"},{"start":168,"end":171,"marker":"bibr","target":"#b28"}]},{"text":"LAM i = logit -1 logit (fpr) + logit (fnr) 2","refs":[]},{"text":"where fpr =","refs":[]}]},{"title":"|F Pi|","paragraphs":[{"text":"|F Pi|+|T Ni| is the false-positive rate, fnr =","refs":[]}]},{"title":"|F Ni|","paragraphs":[{"text":"|F Ni|+|T Pi| is the false-negative rate, and the logit transformations are given by logit(x) = ln x 1-x and logit -1 (x) = e x 1+e x . In order to obtain a single score for each conformance checker across all the categories C i , we will use a macro-averaging approach [31], which computes the arithmetic mean of the above measures over all the categories C i .","refs":[{"start":270,"end":274,"marker":"bibr","target":"#b27"}]},{"text":"Moreover, as explained in Sect. 3, since a document cannot be compliant and not compliant at the same time, the class C 0 of the compliant documents must be separate from any other class C i representing a possible issue of a document, i.e. C 0 ∩ C i = ∅ ∀i, i = 0. As a consequence, assuming perfect classification, i.e. no FP or FN happen, it should be T P 0 ∩ T P i = ∅ ∀i, i = 0, i.e. there must be no intersection between the TP documents attributed to C 0 and those attributed to other classes C i . Since classification is typically not perfect, it should hold that (T P 0 ∪ F P 0 )∩(T P i ∪ F P i ) = ∅ ∀i, i = 0, i.e. the documents that a conformance checker correctly or incorrectly attributes to C 0 should have no intersection with the documents it correctly or incorrectly attributes to other classes C i . Another consequence is that T N 0 ∪F N 0 = N i=1 (T P i ∪ F P i ), i.e. the documents correctly or incorrectly marked as not compliant by a conformance checkers must have been attributed to some other class C i by the same conformance checker.","refs":[]},{"text":"Therefore, we can introduce an additional overall performance measure, called consistency, which assesses the ability of a conformance checker to adhere to the above constraint of separation of C 0 from the other classes:","refs":[]},{"text":"where N is the total number of classes, excluded C 0 . Note that consistency is different from the evaluation measures typically used in classification [15,31,34] or clustering [3,4] and serves the specific purpose of assessing the degree of separation between the compliant and not-compliant classes.","refs":[{"start":152,"end":156,"marker":"bibr","target":"#b14"},{"start":156,"end":159,"marker":"bibr","target":"#b27"},{"start":159,"end":162,"marker":"bibr","target":"#b30"},{"start":177,"end":180,"marker":"bibr","target":"#b2"},{"start":180,"end":182,"marker":"bibr","target":"#b3"}]},{"text":"Figure 4 shows some relevant cases for consistency: when there is no intersection between C 0 and the other classes then Consistency = 1 (Fig. 4a); on the other hand, in the extreme case of complete overall between C 0 and the other classes, i.e. when all the documents are assigned to all the classes, Consistency = 0 (Fig. 4c); in the other cases, when some overlap exists, consistency is in the range (0, 1) (Fig. 4b).","refs":[{"start":7,"end":8,"marker":"figure","target":"#fig_3"},{"start":143,"end":145,"marker":"figure","target":"#fig_3"},{"start":325,"end":327,"marker":"figure","target":"#fig_3"},{"start":417,"end":419,"marker":"figure","target":"#fig_3"}]}]},{"title":"Conclusions and Future Work","paragraphs":[{"text":"In this paper we discussed how to model the process of conformance checking for long-term digital preservation and, consequently how to evaluate it. In particular, we proposed to consider conformance checking as a multi-classification problem, with the constraint that C 0 , the class of compliant documents, is separated from the others. We then discussed how to instantiate the Cranfield paradigm for the specific purpose of evaluating conformance checkers, we selected the existing measures -accuracy, AUC, and LAM -that best fit this peculiar applicative context and we proposed a new measure -consistency -that assess the extent to which conformance checkers are able to keep the C 0 class separated from the other classes.","refs":[]},{"text":"Future work will concern the application of the proposed framework in the context of the PREFORMA project, with real memory institutions, domain experts and the suppliers which are actually developing the conformance checkers for the different media types targeted by PREFORMA. In particular, we see this as an iterative process, where we will go through repeated cycles to collect larger and larger datasets, to train memory institutions and suppliers on this evaluation methodology, and to refine it. An initial account of the defined classes can be found in [17].","refs":[{"start":561,"end":565,"marker":"bibr","target":"#b16"}]}]}],"tables":{},"abstract":{"title":"Abstract","paragraphs":[{"text":"In this paper, we discuss the problem of how to model and evaluate tools that allow memory institutions to check the conformance of documents with respect to their reference standards in order to ensure their appropriateness for long-term preservation. In particular, we propose to model the conformance checking problem as a classification task and to evaluate it as a multi-classification problem using a Cranfield-like approach.","refs":[]}]}}