{"bibliography":{"title":"Connecting Researchers to Data Repositories in the Earth, Space, and Environmental Sciences","authors":[{"person_name":{"surname":"Witt","first_name":"Michael"},"affiliations":[{"department":null,"institution":"Purdue University","laboratory":null}],"email":"mwitt@purdue.edu"},{"person_name":{"surname":"Stall","first_name":"Shelley"},"affiliations":[{"department":null,"institution":"American Geophysical Union","laboratory":null}],"email":"sstall@agu.org"},{"person_name":{"surname":"Duerr","first_name":"Ruth"},"affiliations":[{"department":null,"institution":"Ronin Institute","laboratory":null}],"email":"ruth.duerr@ronininstitute.org"},{"person_name":{"surname":"Plante","first_name":"Raymond"},"affiliations":[{"department":null,"institution":"National Institute of Standards and Technology","laboratory":null}],"email":"raymond.plante@nist.gov"},{"person_name":{"surname":"Fenner","first_name":"Martin"},"affiliations":[{"department":null,"institution":"DataCite","laboratory":null}],"email":"martin.fenner@datacite.org"},{"person_name":{"surname":"Dasler","first_name":"Robin"},"affiliations":[{"department":null,"institution":"DataCite","laboratory":null}],"email":"robin.dasler@datacite.org"},{"person_name":{"surname":"Cruse","first_name":"Patricia"},"affiliations":[{"department":null,"institution":"DataCite","laboratory":null}],"email":"patricia.cruse@datacite.org"},{"person_name":{"surname":"Hou","first_name":"Sophie"},"affiliations":[{"department":"National Center for Atmospheric Research","institution":"University Corporation for Atmospheric Research","laboratory":null}],"email":"hou@ucar.edu"},{"person_name":{"surname":"Ulrich","first_name":"Robert"},"affiliations":[{"department":"Karlsruher Institut für Technologie","institution":null,"laboratory":null}],"email":"robert.ulrich@kit.edu"},{"person_name":{"surname":"Kinkade","first_name":"Danie"},"affiliations":[{"department":null,"institution":"Woods Hole Oceanographic Institution","laboratory":null}],"email":"dkinkade@whoi.edu"}],"date":null,"ids":{"DOI":"10.1007/978-3-030-11226-4_7","arXiv":null},"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"keywords":["Repositories","Fair principles","Recommender systems 1","Data facilities","Research data management","Geosciences"],"citations":{"b0":{"title":"The FAIR guiding principles for scientific data management and stewardship","authors":[{"person_name":{"surname":"Wilkinson","first_name":"M"},"affiliations":[],"email":null}],"date":{"year":"2016","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"Sci. Data","series":null,"scope":{"volume":3,"pages":{"from_page":160018,"to_page":160018}}},"b1":{"title":"Workflow Recommendations for Enabling FAIR Data in the Earth","authors":[{"person_name":{"surname":"Cruse","first_name":"P"},"affiliations":[],"email":null},{"person_name":{"surname":"Servilla","first_name":"M"},"affiliations":[],"email":null}],"date":{"year":"2018","month":null,"day":null},"ids":{"DOI":"10.5281/zenodo.1445839","arXiv":null},"target":"http://doi.org/10.5281/zenodo.1445839","publisher":null,"journal":"Space, and Environmental Sciences","series":null,"scope":null},"b2":{"title":"Open Data in the Humanities Platform: Humanities at Scale: Evolving the DARIAH ERIC","authors":[{"person_name":{"surname":"Buddenbohm","first_name":"S"},"affiliations":[],"email":null},{"person_name":{"surname":"De","first_name":"Jong"},"affiliations":[],"email":null},{"person_name":{"surname":"Priddy","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Moranville","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Ribbe","first_name":"Y"},"affiliations":[],"email":null}],"date":{"year":"2017","month":null,"day":null},"ids":null,"target":"https://hal.archives-ouvertes.fr/hal-01686320","publisher":"DANS-KNAW","journal":null,"series":null,"scope":null},"b3":{"title":"2012 -Space data and information transfer systems -Audit and certification of trustworthy digital repositories","authors":[],"date":{"year":"2012","month":null,"day":null},"ids":null,"target":"https://www.iso.org/standard/56510.html","publisher":null,"journal":null,"series":null,"scope":null},"b4":{"title":"Core Trustworthy Data Repositories Extended Guidance","authors":[],"date":{"year":"2018","month":null,"day":null},"ids":null,"target":"https://www.coretrustseal.org/wp-content/uploads/2017/01/20180629-CTS-Extended-Guidance-v1.1.pdf","publisher":null,"journal":null,"series":null,"scope":null},"b5":{"title":"Co-designing, co-developing, and co-implementing an institutional data repository service","authors":[{"person_name":{"surname":"Witt","first_name":"M"},"affiliations":[],"email":null}],"date":{"year":"2012","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"J. Libr. Adm","series":null,"scope":{"volume":52,"pages":{"from_page":172,"to_page":188}}},"b6":{"title":"Where to Keep Research Data: DCC Checklist for Evaluating Data Repositories Version 1.1, Digital Curation Centre","authors":[{"person_name":{"surname":"Whyte","first_name":"A"},"affiliations":[],"email":null}],"date":{"year":"2016","month":null,"day":null},"ids":null,"target":"http://www.dcc.ac.uk/resources/how-guides-checklists/where-keep-research-data/where-keep-research-data","publisher":null,"journal":null,"series":null,"scope":null},"b7":{"title":"Interview Questions for Determining Data Repository FAIR Compliance","authors":[{"person_name":{"surname":"Plante","first_name":"R"},"affiliations":[],"email":null},{"person_name":{"surname":"Witt","first_name":"M"},"affiliations":[],"email":null}],"date":{"year":"2018","month":null,"day":null},"ids":{"DOI":"10.5281/zenodo.1432515","arXiv":null},"target":"http://doi.org/10.5281/zenodo.1432515","publisher":null,"journal":"Zenodo","series":null,"scope":null},"b8":{"title":"Metadata Schema for the Description of Research Data Repositories: version 3","authors":[{"person_name":{"surname":"Rücknagel","first_name":"J"},"affiliations":[],"email":null}],"date":{"year":"2015","month":null,"day":null},"ids":{"DOI":"10.2312/re3.008","arXiv":null},"target":"http://doi.org/10.2312/re3.008","publisher":null,"journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":29,"to_page":29}}},"b9":{"title":"10 Heuristics for User Interface Design","authors":[{"person_name":{"surname":"Nielsen","first_name":"J"},"affiliations":[],"email":null}],"date":{"year":"1995","month":null,"day":null},"ids":null,"target":"https://www.nngroup.com/articles/ten-usability-heuristics","publisher":"Nielsen Norman Group","journal":null,"series":null,"scope":null}},"sections":[{"title":"Design and Development","paragraphs":[]},{"title":"Decision Tree","paragraphs":[{"text":"The starting place for the group was to imagine a researcher who is producing data and to diagram at a high level what decisions that researcher would make as they select a repository to deposit their data. Researchers could be writing proposals, for example, to funding agencies that require data management plans in which repositories must be specified; or, they could be further along in performing their research at a point when they are submitting papers for publication with journals that require supporting data be shared and archived in a repository (Fig. 1).","refs":[{"start":564,"end":565,"marker":"figure","target":"#fig_0"}]},{"text":"In all cases, researchers will be compelled to follow any mandates or recommendations of specific repositories that are made by their funder, publisher, journal, or institution. If this is not the case, researchers should consider what domain-specific repositories are commonly used in their area of research or for the type of data they are producing. They should contact the repository or otherwise confirm whether they can deposit their data and what the parameters for using the service are, e.g., what metadata and formats do they require, do they charge a fee, file size limits, etc. A repository that is certified is preferable to one that is not because it has demonstrated through a formal process such as the CoreTrustSeal or ISO 16363 [4] that it has an adequate and sustainable organizational infrastructure, digital object management, and technology to provide the services that it advertises. Furthermore, repositories that provide higher levels of curation are preferable to repositories that provide lower levels of curation. In the context of CoreTrustSeal, four levels of curation are defined [5]. The lowest level of curation is to simply accept and distribute content as-is deposited. Basic curation may involve a simple check of the data before it is accepted and the addition of some basic metadata or documentation. Enhanced curation may additionally include format conversion and more detailed metadata or documentation. The highest level, or data-level, curation includes enhanced curation with editing and quality assurance of the data or other, additional services. If a domain repository is not available or is unable to accept the researcher's data, they may use a data repository that is offered by their institution or a general-purpose data repository such as Dryad8 , figshare9 , Harvard Dataverse10 , Mendeley Data11 , Open Science Framework12 , and Zenodo13 . Likewise for institutional or general-purpose data repositories, certification and higher levels of curation are preferred. In many research organizations, researchers can consult librarians for assistance in navigating these options and for help in selecting an appropriate repository for their data [6], and further guidance is offered by resources such as the Digital Curation Centre's Checklist for Evaluating Data Repositories [7].","refs":[{"start":746,"end":749,"marker":"bibr","target":"#b3"},{"start":1111,"end":1114,"marker":"bibr","target":"#b4"},{"start":1797,"end":1798,"marker":null,"target":"#foot_2"},{"start":1809,"end":1810,"marker":null,"target":"#foot_3"},{"start":1830,"end":1832,"marker":null,"target":"#foot_4"},{"start":1848,"end":1850,"marker":null,"target":"#foot_5"},{"start":1875,"end":1877,"marker":null,"target":"#foot_6"},{"start":1890,"end":1892,"marker":null,"target":"#foot_7"},{"start":2196,"end":2199,"marker":"bibr","target":"#b5"},{"start":2327,"end":2330,"marker":"bibr","target":"#b6"}]}]},{"title":"Interviews with Data Facilities","paragraphs":[{"text":"Initiated by the Lorentz Workshop14 in 2014, members of the broader research community collaborated to develop and publish the FAIR Principles in 2016 [1], and work has continued through the GO FAIR initiative15 towards defining metrics for evaluating and measuring implementation of the Principles or the \"FAIRness\" of data and metadata. To get a better, practical sense of FAIR adoption among data repositories in the Earth, space, and environmental sciences, the TAG designed an interview guide [8] and conducted one-hour interviews with domain repository managers who were engaged in the Enabling FAIR Data initiative. These included the Ag Data Commons (United States Department of Agriculture), Alabama Geological Survey, Biological and Chemical Oceanography Data Management Office (Woods Hole Oceanographic Institution), Dash (California Digital Library), Deep Carbon Observatory, Interdisciplinary Earth Data Alliance (Columbia University), Helmholtz Centre Potsdam GFZ German Research Centre for Geosciences, PANGAEA, Socioeconomic Data and Applications Center (NASA), Research Data Archive (National Center for Atmospheric Research), and VTechData (Virginia Polytechnic Institute and State University).","refs":[{"start":33,"end":35,"marker":null,"target":"#foot_8"},{"start":151,"end":154,"marker":"bibr","target":"#b0"},{"start":209,"end":211,"marker":null,"target":"#foot_9"},{"start":498,"end":501,"marker":"bibr","target":"#b7"}]},{"text":"The questions were developed from discussions within the TAG (including those who would be interviewed) and reflect what they considered FAIR implementation to resemble in current repository practice that are salient within the domain. For each practice, repositories were asked if they had implemented the practice, had plans to implement it, or did not have plans for implementation. Common practices among repositories in the domain included providing a search/browse user interface; provisioning landing pages for datasets; minting Digital Object Identifiers (DOIs) for datasets and/or data collections; providing human-readable and machine-actionable metadata describing datasets; linking datasets to related, published literature; supporting interfaces for metadata export and harvesting; identifying authors using ORCID identifiers; describing datasets with temporal, geospatial, and other domain-specific metadata; suggesting citations to encourage users to cite data; providing support services around data (e.g., help desk); enabling direct machine access to data (e.g., ftp, THREDDS, OPeNDAP, SPARQL, OGC); ascribing open access licenses for data reuse; registering their repositories with re3data; and supporting functionality to include data housed by the repository in peer review workflows. All repositories recognized the importance of certification: approximately half were already certified (primarily through the World Data System 16 or CoreTrustSeal) or were actively pursuing certification, with the other half either planning to or interested in pursuing certification in the near future. Only some repositories embed machine-actionable metadata in landing pages (e.g., JSON-LD, HTML meta tags); linked or otherwise referenced datasets in their repositories to related data elsewhere; captured provenance of data in their custody; or furnished citations to related literature in their DOI metadata, e.g., such that could be used by Scholix 17 or other services that relate data and literature, quantify impact measures of data, etc. Interestingly, while most repositories responded that they do not provide machine-actionable citations for their data, these were effectively provided by the DOI for many applications such as citation management software clients.","refs":[{"start":1962,"end":1964,"marker":null,"target":"#foot_11"}]}]},{"title":"re3data Schema Mapping and Tool Design","paragraphs":[{"text":"The primary purpose of the decision tree and interview exercises were to inform the design and development of the Repository Finder: to make it easy for a researcher to identify an appropriate domain repository to deposit their data and, in the process, to tacitly promote the FAIR Principles both in terms of awareness for the researcher and to begin to recognize emerging \"FAIR\" practices by data repositories (Fig. 2).","refs":[{"start":418,"end":419,"marker":"figure","target":"#fig_1"}]},{"text":"The re3data registry currently manages metadata records describing 2,200 data repositories across all domains of research and around the world. Each repository is cataloged using forty-one descriptive attributes that are explained and can be validated in XML18 using version 3.0 of the Metadata Schema for the Description of Research Data Repositories [9]. A subset of records pertaining to the Earth, space, and environmental sciences was established by limiting to relevant subjectID attributes based on the Classification of Subject Area, Review Board, Research Area and Scientific Discipline (2016-2019) from the Deutsche Forschungsgemeinschaft (DFG) 19 , which is used by re3data. SubjectID is a required attribute in the schema. In addition, results are implicitly limited to only repositories that accept data for deposit (dataUploadType is \"open\" or \"restricted\") and those that are domain repositories (type is \"disciplinary\"). Guided by the interview and user test results, repositories that provide open access to their data (dataAccessType is \"open\") and persistent identifiers (pidSystem is true) were included in the criteria for inclusion to recognize practices that are working towards FAIR that are currently and widely adopted (Fig. 3). Initial design documents and discussions were incorporated into a wireframe using Balsmiq20 that was iterated through biweekly online meetings of the project team. The software was developed as two separate applications: an API integrated with the re3data Elasticsearch index using the Ruby on Rails21 framework, and a frontend for this API using the EmberJS22 framework. The work was done over the course of four monthly development sprints, and the tool is hosted by DataCite with its source code openly accessible on github 23,24 . The application queries re3data using Elasticsearch match phrase prefix queries25 on the repositoryName, description, and keyword fields. Repository Finder begins with a short explanation of the tool and then presents two options: the user can (1) initiate a search by entering keywords that are auto-completed and receive results ranked by relevance of all repositories that accept deposit of data, provide open access, and use persistent identifiers. Alternatively, the user can (2) click a link to see repositories that meet the criteria of the Enabling FAIR Data community. These results are ordered alphabetically and include only repositories in the domain of Earth, space, and environmental sciences that meet the above criteria, highlighting repositories that have achieved certification with a \"seal\" icon. After results are displayed, the user has the ability to narrow the results by keyword; subsequent results are ranked by relevance. Each individual result displays the name of the repository; its description, subjects, and keywords; and a switch to display more details about the repository, including links to the repository, contact information, and its full registry entry in the native re3data interface. At the end of the result list, institutional and general-purpose repositories are suggested to be used for cases where a domain repository is not available or will not accept the researcher's data (Fig. 4).","refs":[{"start":258,"end":260,"marker":null,"target":"#foot_12"},{"start":352,"end":355,"marker":"bibr","target":"#b8"},{"start":655,"end":657,"marker":null,"target":"#foot_13"},{"start":1251,"end":1252,"marker":"figure","target":"#fig_2"},{"start":1344,"end":1346,"marker":null,"target":"#foot_15"},{"start":1554,"end":1556,"marker":null,"target":"#foot_16"},{"start":1613,"end":1615,"marker":null,"target":"#foot_17"},{"start":1869,"end":1871,"marker":null,"target":"#foot_20"},{"start":3218,"end":3219,"marker":"figure","target":"#fig_3"}]}]},{"title":"User Testing","paragraphs":[{"text":"In between the third and fourth development sprints, a prototype of the tool was made available for the purpose of user testing, which occurred in three, separate studies. The first two studies were held at the 2018 ESIP Summer Meeting to leverage the diversity of the attendees' data roles and responsibilities. The first study that was conducted by Connecting Researchers to Data Repositories the ESIP Usability Cluster26 engaged fifteen users in a session with a focus on usability that combined the focus group and user study techniques so that the users could provide feedback regarding specific, task-based interactions with the tool in a moderated fashion. The second study was conducted by the ESIP Usability Cluster Chair and Fellow using the one-on-one, in-person user study technique with a total of five users who fit the general \"researcher\" persona. During the user study session, each subject was first asked to tell a \"user story\" and describe a goal they would like to accomplish when looking for a repository. The subject was then asked to use the tool to perform specific, defined tasks based on the \"user story\" scenario and the goal. The subject was asked to think aloud while performing the tasks, so that the subject could share the thought process as they determine how to use the tool to accomplish the tasks. Feedback from users identified several concerns that aligned with usability issues that are outlined and discussed in Jakob Nielsen's 10 Usability Heuristics for User Interface Design [10]. In particular, users indicated that improvement in the following areas could have significant impact on the user interface and experience of the tool: the identity and messaging of the tool (e.g. what can the tool do, and why would I use it?), the authenticity and understandability of the content (e.g., institutional repositories not included in results, too many filters that only repository managers would understand, and lack of information regarding how the repositories' records are curated and can be updated in re3data); and the overall design approach (e.g. be more user-centric by providing visibility of system status, minimizing use of jargons, adding support documentation such as an FAQ, and implementing user friendly aesthetics for the user interface).","refs":[{"start":421,"end":423,"marker":null,"target":"#foot_21"},{"start":1519,"end":1523,"marker":"bibr","target":"#b9"}]},{"text":"In the third study, a commercial firm was hired to interview users while guiding them through use of the tool. Subjects were recruited by project team members and included twenty-four individuals who identified themselves as either domain researchers or repository \"champions\" such as librarians, curators, data facility staff, or other data professionals. Test subjects described their backgrounds coming from Astronomy, Astrophysics, Atmospheric Sciences, Ecology, Environmental Science, Geodesy, Geography, Geoinformatics, Geology, Geomorphology, Geophysics, Hydrogeology, Hydrology, Oceanography, Paleoceanography, Palaeontology, and Polar Science. All subject classifications from the selected DFG subject areas were represented by at least one user with the exception of 316-01 Geochemistry, Mineralogy, and Crystallography. Online web sessions were conducted and recorded using Zoom with each session lasting between twenty and thirty minutes each. An interviewer gave a brief introduction to the tool and its purpose before guiding the user through the task of searching for a repository to deposit their data. Users were asked if the terminology and prompts were clearly understood as well as to evaluate the results for accuracy and relevance. Were there any repositories that were not relevant in the result list, and were the top results the most relevant? Were there any repositories they would expect to see in the results that were not there? Lastly, interviewers asked if the user's expectations were met by the tool and to share any additional input, ideas, or improvements that could be incorporated in the final development cycle of the tool or potential future development. Recordings of the sessions and interview notes were analyzed and a summary report reaffirmed users' perception of the need for such a tool and suggested improvements needed to the utilization of space and level of detail presented in the user interface, the mechanism for searching, and the metadata quality and completeness of the information about repositories in re3data. The user interface was refined to give collapsed results that can be expanded to show more detail, and the original hierarchical drop-down list of subjects was replaced with an auto-completing keyword search and a simple link to display a list of repositories that meet the criteria of the Enabling FAIR Data community initiative. The quality of the results given by the tool are impacted directly by the quality and completeness of metadata describing each repository in the re3data registry. To begin to address concerns with metadata, the re3data editorial board met for a two-day workshop hosted by the Karlsruhe Institute of Technology to focus on enhancing and bringing more consistency to the records for repositories in the Earth, space, and environmental sciences. They collectively edited a representative sample of records and compared notes to discuss issues and build consensus around editorial practices, in particular, for the repository attributes that impact Repository Finder and other tools like it in the future that may be built using re3data's API. The most accurate information about a repository can be provided to re3data by the repository managers themselves; to encourage their participation, a onepage guidance document was prepared and disseminated to the community by AGU. Users of Repository Finder and re3data continue to submit enhancements and corrections that refine and improve the quality of the registry and the results provided by the tool.","refs":[]}]},{"title":"Challenges and Future Work","paragraphs":[{"text":"The project faced familiar constraints of a short timeline and limited resources; while we were able to engage a significant cross-section of stakeholders who work with data in the context of scholarship in Earth, space, and environmental sciences, it was not representative of the domain as a whole. Input was not statistically significant and relied on convenience samples of parties engaged in the initiative with a strong representation bias from North America and Europe. More time and broader engagement would result in a more robust consensus. The decision tree, interviews, and user tests were intended to inform the development of the tool in a practical and direct manner; they were not designed to stand alone as formal research studies. Problems related to metadata extended beyond the completeness of records in re3data: differences in terminology and the lack of widely adopted controlled vocabularies for the domain and subdomains as well as data types raised concerns in user testing and limited the potential functionality of the tool, e.g., the ability to search repositories by the type of data they accept. In particular, the DFG subject classification was limiting, for example, by not including commonly used subject terms such as \"environmental science\". Within the re3data schema, the most flexibility to overcome this limit exists in adding a variety of different keywords that represent the same subjects with different names and in the description, in particular, to add very specific subdomain terminology, instrumentation, and data formats. There is an inverse relationship between the number of attributes that are used to filter searches and the quantity of results those searches will produce. In terms of promoting FAIR, many of the practices that were reported by repositories were either not widely adopted, or in some cases, not cataloged in the registry. For example, an early iteration of the tool limited results to only certified repositories, but this excluded too many repositories that researchers recognized as being relevant to their research, and in some cases, yielded no results at all. There is also an important role for repositories and data facilities that are provided locally by institutions; however, the tool does not know the affiliation of the user, so it was not possible to include relevant institutional repositories in the results. The current version of Repository Finder was limited in scope to the use case of a researcher selecting a repository to deposit their data, but discussions with other TAGs and from user testing suggested many other use cases that could be motivated by publishers, journals, funders, societies, and other drivers that could be explored. Other potential future work includes updating the criteria to reflect the metrics coming out of GO FAIR and other, related initiatives as well as extending this approach to other domains outside of the Earth, space, and environmental sciences and to other lists of recommendations that may exist or emerge in the future.","refs":[]}]}],"tables":{},"abstract":{"title":"Abstract","paragraphs":[{"text":"The Repository Finder tool was developed to help researchers in the domain of Earth, space, and environmental sciences to identify appropriate repositories where they can deposit their research data and to promote practices that implement the FAIR Principles, encouraging progress toward sharing data that are findable, accessible, interoperable, and reusable. Requirements for the design of the tool were gathered through a series of workshops and working groups as a part of the Enabling FAIR Data initiative led by the American Geophysical Union that included the development of a decision tree that researchers may follow in selecting a data repository, interviews with domain repository managers, and usability testing. The tool is hosted on the web by DataCite and enables a researcher to query all data repositories by keyword or to view a list of domain repositories that accept data for deposit, support open access, and provide persistent identifiers. Metadata records from the re3data.org registry of research data repositories and the returned results highlight repositories that have achieved trustworthy digital repository certification through a formal procedure such as the CoreTrust Seal.","refs":[]}]}}