{"bibliography":{"title":"Merging Structural and Taxonomic Similarity for Text Retrieval Using Relational Descriptions","authors":[{"person_name":{"surname":"Ferilli","first_name":"Stefano"},"affiliations":[{"department":"Dipartimento di Informatica","institution":"Università di Bari via E","laboratory":null},{"department":"Centro Interdipartimentale per la Logica e sue Applicazioni","institution":"Università di Bari via","laboratory":null}],"email":"ferilli@di.uniba.it"},{"person_name":{"surname":"Biba","first_name":"Marenglen"},"affiliations":[{"department":"Computer Science Department","institution":"Tirana Rr. \"Komuna e Parisit\"","laboratory":null}],"email":"marenglenbiba@unyt.edu.al"},{"person_name":{"surname":"Mauro","first_name":"Nicola"},"affiliations":[{"department":"Dipartimento di Informatica","institution":"Università di Bari via E","laboratory":null},{"department":"Centro Interdipartimentale per la Logica e sue Applicazioni","institution":"Università di Bari via","laboratory":null}],"email":null},{"person_name":{"surname":"Basile","first_name":"Teresa"},"affiliations":[{"department":"Dipartimento di Informatica","institution":"Università di Bari via E","laboratory":null}],"email":"basile@di.uniba.it"},{"person_name":{"surname":"Esposito","first_name":"Floriana"},"affiliations":[{"department":"Dipartimento di Informatica","institution":"Università di Bari via E","laboratory":null},{"department":"Centro Interdipartimentale per la Logica e sue Applicazioni","institution":"Università di Bari via","laboratory":null}],"email":"esposito@di.uniba.it"}],"date":null,"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"keywords":[],"citations":{"b0":{"title":"Combining lexical, syntactic, and semantic evidence for textual entailment classification","authors":[{"person_name":{"surname":"Agichtein","first_name":"E"},"affiliations":[],"email":null},{"person_name":{"surname":"Askew","first_name":"W"},"affiliations":[],"email":null},{"person_name":{"surname":"Liu","first_name":"Y"},"affiliations":[],"email":null}],"date":{"year":"2008","month":null,"day":null},"ids":null,"target":null,"publisher":"TAC","journal":null,"series":null,"scope":null},"b1":{"title":"Semantic distance in wordnet: An experimental, application-oriented evaluation of five measures","authors":[{"person_name":{"surname":"Budanitsky","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Hirst","first_name":"G"},"affiliations":[],"email":null}],"date":{"year":"2001","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"b2":{"title":"Logic Programming and Databases","authors":[{"person_name":{"surname":"Ceri","first_name":"S"},"affiliations":[],"email":null},{"person_name":{"surname":"Gottlöb","first_name":"G"},"affiliations":[],"email":null},{"person_name":{"surname":"Tanca","first_name":"L"},"affiliations":[],"email":null}],"date":{"year":"1990","month":null,"day":null},"ids":null,"target":null,"publisher":"Springer","journal":null,"series":null,"scope":null},"b3":{"title":"Recognizing textual entailment with logical inference","authors":[{"person_name":{"surname":"Clark","first_name":"P"},"affiliations":[],"email":null},{"person_name":{"surname":"Harrison","first_name":"P"},"affiliations":[],"email":null}],"date":{"year":"2008","month":null,"day":null},"ids":null,"target":null,"publisher":"TAC","journal":null,"series":null,"scope":null},"b4":{"title":"A generalization model based on oi-implication for ideal theory refinement","authors":[{"person_name":{"surname":"Esposito","first_name":"F"},"affiliations":[],"email":null},{"person_name":{"surname":"Fanizzi","first_name":"N"},"affiliations":[],"email":null},{"person_name":{"surname":"Ferilli","first_name":"S"},"affiliations":[],"email":null},{"person_name":{"surname":"Semeraro","first_name":"G"},"affiliations":[],"email":null}],"date":{"year":"2001","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"Fundamenta Informaticae","series":null,"scope":{"volume":47,"pages":{"from_page":15,"to_page":33}}},"b5":{"title":"A general similarity framework for horn clause logic","authors":[{"person_name":{"surname":"Ferilli","first_name":"S"},"affiliations":[],"email":null},{"person_name":{"surname":"Basile","first_name":"T"},"affiliations":[],"email":null},{"person_name":{"surname":"Biba","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Di Mauro","first_name":"N"},"affiliations":[],"email":null},{"person_name":{"surname":"Esposito","first_name":"F"},"affiliations":[],"email":null}],"date":{"year":"2009","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"Fundamenta Informaticae","series":null,"scope":{"volume":90,"pages":{"from_page":43,"to_page":46}}},"b6":{"title":"Learning logic models for automated text categorization","authors":[{"person_name":{"surname":"Ferilli","first_name":"S"},"affiliations":[],"email":null},{"person_name":{"surname":"Fanizzi","first_name":"N"},"affiliations":[],"email":null},{"person_name":{"surname":"Semeraro","first_name":"G"},"affiliations":[],"email":null}],"date":{"year":"2001","month":null,"day":null},"ids":null,"target":null,"publisher":"Springer","journal":null,"series":null,"scope":null},"b7":{"title":"Word sense disambiguation: The state of the art","authors":[{"person_name":{"surname":"Ide","first_name":"N"},"affiliations":[],"email":null},{"person_name":{"surname":"Véronis","first_name":"J"},"affiliations":[],"email":null}],"date":{"year":"1998","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"Computational Linguistics","series":null,"scope":{"volume":24,"pages":{"from_page":1,"to_page":40}}},"b8":{"title":"Machine learning experiments for textual entailment","authors":[{"person_name":{"surname":"Inkpen","first_name":"D"},"affiliations":[],"email":null},{"person_name":{"surname":"Kipp","first_name":"D"},"affiliations":[],"email":null},{"person_name":{"surname":"Nastase","first_name":"V"},"affiliations":[],"email":null}],"date":{"year":"2006","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"b9":{"title":"More than one sense per discourse","authors":[{"person_name":{"surname":"Krovetz","first_name":"R"},"affiliations":[],"email":null}],"date":{"year":"1998","month":null,"day":null},"ids":null,"target":null,"publisher":"Research Memorandum","journal":null,"series":null,"scope":null},"b10":{"title":"An information-theoretic definition of similarity","authors":[{"person_name":{"surname":"Lin","first_name":"D"},"affiliations":[],"email":null}],"date":null,"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":296,"to_page":304}}},"b11":{"title":"","authors":[{"person_name":{"surname":"Kaufmann","first_name":"Morgan"},"affiliations":[],"email":null}],"date":{"year":"1998","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"b12":{"title":"Foundations of Logic Programming","authors":[{"person_name":{"surname":"Lloyd","first_name":"J"},"affiliations":[],"email":null}],"date":{"year":"1987","month":null,"day":null},"ids":null,"target":null,"publisher":"Springer","journal":null,"series":null,"scope":null},"b13":{"title":"Wordnet: A lexical database for English","authors":[{"person_name":{"surname":"Miller","first_name":"G"},"affiliations":[],"email":null}],"date":{"year":"1995","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"Communications of the ACM","series":null,"scope":{"volume":38,"pages":{"from_page":39,"to_page":41}}},"b14":{"title":"Inductive logic programming","authors":[{"person_name":{"surname":"Muggleton","first_name":"S"},"affiliations":[],"email":null}],"date":{"year":"1991","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"New Generation Computing","series":null,"scope":{"volume":8,"pages":{"from_page":295,"to_page":318}}},"b15":{"title":"Learning shallow semantic rules for textual entailment","authors":[{"person_name":{"surname":"Pennacchiotti","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Zanzotto","first_name":"F"},"affiliations":[],"email":null}],"date":{"year":"2007","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"b16":{"title":"Extensions of inversion of resolution applied to theory completion","authors":[{"person_name":{"surname":"Rouveirol","first_name":"C"},"affiliations":[],"email":null}],"date":{"year":"1992","month":null,"day":null},"ids":null,"target":null,"publisher":"Academic Press","journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":64,"to_page":90}}},"b17":{"title":"An ontology-driven similarity algorithm","authors":[{"person_name":{"surname":"Vargas-Vera","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Motta","first_name":"E"},"affiliations":[],"email":null}],"date":{"year":"2004","month":"07","day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":null}},"sections":[{"title":"Introduction","paragraphs":[{"text":"The spread of digital technologies has caused a dramatic growth in the availability of documents in digital format, due to the easy creation and transmission thereof using networked computer systems. Hence, the birth of several repositories, aimed at storing and providing such documents to interested final users. The shortcoming of this scenario is in the problem of finding useful documents that can satisfy an information need (the so-called information overload problem). Indeed, in legacy environments, few selected publications were available, and librarians could properly assess their content and consequently tag them for subsequent retrieval. Now, the amount of available documents is so huge that manual evaluation and tagging is infeasible. This represented a significant motivation for the invention of proper Information Retrieval techniques, that could rely on automatic techniques for document indexing and retrieval. More precisely, documents are almost always indexed based on their textual content, and are searched for by expressing textual queries. Due to the inborn complexity of Natural Language, information retrieval techniques have typically focussed their attention on the lexical level, that seemed a good tradeoff between computational requirements and outcome effectiveness. The text is seen as a sequence of un-related words (bag-of-words) and the query is expressed as a set of terms that are to be found in the documents. The weakness of such approaches, however, is that the syntactic and logical structure underlying the sentences is completely lost. Unfortunately, the real meaning of a sentence is mostly determined just by that level, and hence the quality of the term-based retrieval outcomes can be significantly affected by such a lack. Indeed, although much more computationally demanding than simple bag-of-word approaches traditionally exploited in the literature, techniques that take into account the syntactic structure of sentences are very important to fully capture the information they convey. Reporters know very well that, swapping the subject and the object in a sentence like \"The dog bit the man\", results in very different interest of the underlying news.","refs":[]},{"text":"The landscape has slightly changed recently, due to the improved computational capabilities of current computer machines. Thus, considering the structural level of natural language sentences in text processing is no more technically infeasible, although still hard. However, handling the structural aspects in Natural Language Processing (NLP for short) cannot be reduced to just building syntactic parsers for the various languages. Sophisticated techniques for representing and handling this kind of information are needed, as well. First-Order Logic (or FOL) is a powerful representation language that allows to express relationships among objects, which is often an unnegligible requirement in real-world and complex domains. Logic Programming [12] is a computer programming framework based on a FOL sub-language, which allows to perform reasoning on knowledge expressed in the form of Horn clauses. Inductive Logic Programming (ILP) [14] aims at learning automatically logic programs from known examples of behaviour, and has proven to be a successful Machine Learning approach in domains where relations among objects must be expressed to fully capture the relevant information. One of the main reasons why FOL is a particularly complex framework compared to simple propositional or attribute-value ones relates to the problem of indeterminacy, meaning that different portions of one formula can be mapped in (often many) different ways onto portions of another.","refs":[{"start":748,"end":752,"marker":"bibr","target":"#b12"},{"start":938,"end":942,"marker":"bibr","target":"#b14"}]},{"text":"An obstacle towards fruitful application of FOL to NLP is the fact that, in the traditional FOL approach, predicates that make up the description language are defined by the knowledge engineer that is in charge of setting up the reasoning or learning problem, and are uninterpreted by the systems. Conversely, some kinds of information need to be interpreted in order to be fully exploited, which requires a proper background knowledge to be set up. For instance, numeric information must be exploited referring to mathematical concepts such as number ordering relationships and arithmetic operations. Analogously, descriptions of natural language sentences obviously include words of the vocabulary, that are the expression of underlying concepts among which many implicit relationships exist that can be captured by a taxonomy. Being able to properly consider and handle such an information is crucial for any successful application of pure FOL techniques to NLP [7].","refs":[{"start":965,"end":968,"marker":"bibr","target":"#b6"}]},{"text":"An advantage of the logic framework is that a background knowledge can be defined and provided to help improving performance or effectiveness of the results. In the above case, a taxonomic background knowledge is needed. Unfortunately, unless the problem domain is very limited, natural language typically requires huge taxonomic information, and the problems of synonimy and polisemy introduce further complexity. In these cases, the use of existing stateof-the-art taxonomies can be a definite advantage. This work proposes the use of a framework for similarity assessment between FOL Horn clauses, enhanced to properly take into account also a taxonomic background knowledge, in order to find documents whose textual content is similar to a prototype sentence representing the query of the user. The basic similarity framework is borrowed from [6], while the taxonomic information is provided by WordNet.","refs":[{"start":847,"end":850,"marker":"bibr","target":"#b5"}]},{"text":"The next section shows how natural language can be described in FOL, and how the introduction of taxonomic background knowledge can support the exploitation of implicit relationships between the concepts underlying the descriptions. Then, Section 3 describes the similarity formula and framework for structural and taxonomic similarity assessment. Section 4 shows experiments that suggest the effectiveness of the proposed approach. Lastly, Section 5 concludes the paper and outlines future work directions.","refs":[]}]},{"title":"NLP = FOL + Taxonomies","paragraphs":[{"text":"The considerations reported in the previous section motivate the adoption of both FOL and taxonomic information for the description of natural language sentences. To give an idea, consider the following sentences:","refs":[]},{"text":"1 -\"The boy wants a small dog\" 2 -\"The girl desires a yellow canary\" 3 -\"The hammer hits a small nail\" They structurally exhibit the same grammatical pattern, thus no hint is available to assess which is more similar to which. Going more in depth, at the lexical level, the only common word ('small') appears in sentences 1 and 3, which would suggest they are closer to each other than to sentence 2. However, it becomes clear that the first two are conceptually the most similar to each other as long as one knows and considers that 'boy' and 'girl' are two young persons, 'to want' and the number of noun X is plural past(X) the tense of verb X is past pres(X) the tense of verb X is present fut(X) the tense of verb X is future 'to desire' are synonyms and 'dog' and 'canary' are two pets. In an information retrieval perspective, if 1 represents the user query, and {2,3} are the documents in the repository, we would like 2 to be returned first, while pure syntactic or lexical techniques would return 3 as the best matching solution. Note that the interesting case is that of sentences that are very close or identical grammatically, but very different in meaning; indeed, for sentences that differ already at the grammatical level the basic structural similarity framework described in [6] would be enough for assessing their degree of distance.","refs":[{"start":1293,"end":1296,"marker":"bibr","target":"#b5"}]},{"text":"There are several levels of the grammatical structure that can be exploited to describe natural language sentences at different levels of abstraction. Of course, the deeper the level, the more complex the description and the more computational demanding its processing. The best grain-size to be exploited depends on the particular situation, and should represent a suitable tradeoff between expressive power and complexity. For demonstration purposes, in the following let us consider the very simple sentence structural description language reported in Table 1. Additionally, each noun, verb, adjective or adverb is described by the corresponding concept (or word) in the sentence, that is to be interpreted according to the taxonomy. To specify which literals are to be interpreted, suppose that they are enclosed as arguments of a tax/1 predicate. This yields, for the previous three sentences, the following descriptions: s1 = sentence(s1) :-subj(s1,ss1), pred(s1,ps1), dir obj(s1,ds1), noun(ss1,nss1), sing(nss1), tax(boy(nss1)), verb(ps1,vps1), pres(ps1), tax(want(vps1)), adj(ds1,ads1), tax(small(ads1)), noun(ds1,nds1), sing(nds1), tax(dog(nds1)). s2 = sentence(s2) :-subj(s2,ss2), pred(s2,ps2), dir obj(s2,ds2), noun(ss2,nss2), sing(nss2), tax(girl(nss2)), verb(ps2,vps2), pres(ps2), tax(desire(vps2)), adj(ds2,ads2), tax(yellow(ads2)), noun(ds2,nds2), sing(nds2), tax(canary(nds2)).","refs":[{"start":561,"end":562,"marker":"table","target":"#tab_0"}]},{"text":"s3 = sentence(s3) :-subj(s3,ss3), pred(s3,ps3), dir obj(s3,ds3), noun(ss3,nss3), sing(nss3), tax(hammer(nss3)), verb(ps3,vps3), pres(ps3), tax(hit(vps3)), adj(ds3,ads3), tax(small(ads3)), noun(ds3,nds3), sing(nds3), tax(nail(nds3)).","refs":[]},{"text":"As already pointed out, setting up a general taxonomy is a hard work, for which reason the availability of an already existing resource can be a valuable help in carrying out the task. In this example we will refer to the most famous taxonomy available nowadays, WordNet (WN) [13], that provides both the conceptual and the lexical level. Note that, if the concepts are not explicitly referenced in the description, but common words in natural language are used instead, due to the problem of polysemy (a word may correspond to many concepts), their similarity must somehow combine the similarities between each pair of concepts underlying the words. Such a combination can consist, for instance, in the average or maximum similarity among such pairs, or more sensibly can exploit the domain of discourse. A distance between groups of words (if necessary) can be obtained by couplewise working on the closest (i.e., taxonomically most similar) words in each group.","refs":[{"start":276,"end":280,"marker":"bibr","target":"#b13"}]}]},{"title":"Similarity Framework","paragraphs":[{"text":"Many AI tasks can take advantage from techniques for descriptions comparison: subsumption procedures (to converge more quickly), flexible matching, instancebased classification techniques or clustering, generalization procedures (to focus on the components that are more likely to correspond to each other). Here, we are interested in the assessment of similarity between two natural language texts described by both lexical/syntactic features and by taxonomic references. Due to its complexity, few works exist on FOL descriptions comparison. In [6], a framework for computing the similarity between two Datalog Horn clauses has been provided, which is summarized in the following. Let us preliminary recall some basic notions involved in Logic Programming. The arity of a predicate is the number of arguments it takes. A literal is an n-ary predicate, applied to n terms, possibly negated. Horn clauses are logical formulae usually represented in Prolog style as l 0 :-l 1 , . . . , l n where the l i 's are literals. It corresponds to an implication l 1 ∧ • • • ∧ l n ⇒ l 0 to be interpreted as \"l 0 (called head of the clause) is true, provided that l 1 and ... and l n (called body of the clause) are all true\". Datalog [3] is, at least syntactically, a restriction of Prolog in which, without loss of generality [16], only variables and constants (i.e., no functions) are allowed as terms. A set of literals is linked if and only if each literal in the set has at least one term in common with another literal in the set. We will deal with the case of linked Datalog clauses. In the following, we will call compatible two sets or sequences of literals that can be mapped onto each other without yielding inconsistent term associations (i.e., a term in one formula cannot correspond to different terms in the other formula).","refs":[{"start":547,"end":550,"marker":"bibr","target":"#b5"},{"start":1225,"end":1228,"marker":"bibr","target":"#b2"},{"start":1318,"end":1322,"marker":"bibr","target":"#b16"}]},{"text":"Intuitively, the evaluation of similarity between two items i and i might be based both on parameters expressing the amounts of common features, which should concur in a positive way to the similarity evaluation, and of the features of each item that are not owned by the other (defined as the residual of the former with respect to the latter), which should concur negatively to the whole similarity value assigned to them [11]:","refs":[{"start":424,"end":428,"marker":"bibr","target":"#b10"}]},{"text":"n , the number of features owned by i but not by i (residual of i wrt i ); l , the number of features owned both by i and by i ; m , the number of features owned by i but not by i (residual of i wrt i ).","refs":[]},{"text":"A similarity function that expresses the degree of similarity between i and i based on the above parameters, and that has a better behaviour than other formulae in the literature in cases in which any of the parameters is 0, is [6]:","refs":[{"start":228,"end":231,"marker":"bibr","target":"#b5"}]},{"text":"It takes values in ]0, 1[, which resembles the theory of probability and hence can help human interpretation of the resulting value. When n = m = 0 it tends to the limit of 1 as long as the number of common features grows. The fullsimilarity value 1 is never reached, being reserved to two items that are exactly the same (i = i ), which can be checked in advance. Consistently with the intuition that there is no limit to the number of different features owned by the two descriptions, which contribute to make them ever different, it is also always strictly greater than 0, and will tend to such a value as long as the number of nonshared features grows. Moreover, for n = l = m = 0 the function evaluates to 0.5, which can be considered intuitively correct for a case of maximum uncertainty. Note that each of the two terms refers specifically to one of the two items under comparison, and hence they could be weighted to reflect their importance.","refs":[]},{"text":"In FOL representations, usually terms denote objects, unary predicates represent object properties and n-ary predicates express relationships between objects; hence, the overall similarity must consider and properly mix all such components. The similarity between two clauses C and C is guided by the similarity between their structural parts, expressed by the n-ary literals in their bodies, and is a function of the number of common and different objects and relationships between them, as provided by their least general generalization C = l 0 :-l 1 , . . . , l k . Specifically, we refer to the θ OI generalization model [5]. The resulting formula is the following:","refs":[{"start":625,"end":628,"marker":"bibr","target":"#b4"}]},{"text":"where k is the number of literals and o the number of terms in C , k is the number of literals and o the number of terms in C , o is the number of terms in C and l i ∈ C and l i ∈ C are generalized by l i for i = 1, . . . , k. The similarity of the literals is smoothed by adding the overall similarity in the number of overlapping and different literals and terms.","refs":[]},{"text":"The similarity between two compatible n-ary literals l and l , in turn, depends on the multisets of n-ary predicates corresponding to the literals directly linked to them (a predicate can appear in multiple instantiations among these literals), called star, and on the similarity of their arguments: sf s (l , l ) = sf(n s , l s , m s ) + avg{sf o (t , t )} t /t ∈θ where θ is the set of term associations that map l onto l and S and S are the stars of l and l , respectively:","refs":[]},{"text":"Lastly, the similarity between two terms t and t is computed as follows:","refs":[]},{"text":"where the former component takes into account the sets of properties (unary predicates) P and P referred to t and t , respectively:","refs":[]},{"text":"and the latter component takes into account how many times the two objects play the same or different roles in the n-ary predicates; in this case, since an object might play the same role in many instances of the same relation, the multisets R and R of roles played by t and t , respectively, are to be considered:","refs":[]},{"text":"since the taxonomic predicates represent further information about the objects involved in a description, in addition to their properties and roles, term similarity is the component where the corresponding similarity can be introduced in the overall framework. Hence, the similarity between two terms becomes:","refs":[]},{"text":"where the additional component refers to the similarity between the taxonomic information associated to the two terms t and t . In particular, it suffices providing a way to assess the similarity between two concepts. Then, in case the taxonomic information is expressed in the form of words instead of concepts, either a Word Sense Disambiguation [8] technique is exploited to identify the single intended concept for polysemous words, or, according to the one-domainper-discourse assumption, the similarity between two words can be referred to the closest pair of concepts associated to those words. In principle, in case of synonymy or polysemy, assuming consistency of domain among the words used in a same context [10], the similarity measure, by couplewise comparing all concepts underlying two words, can also suggest a ranking of which are the most probable senses for each, this way serving as a simple Word Sense Disambiguation procedure, or as a support to a more elaborate one.","refs":[{"start":348,"end":351,"marker":"bibr","target":"#b7"},{"start":719,"end":723,"marker":"bibr","target":"#b9"}]},{"text":"To assess the similarity between concepts in a given taxonomy, and indirectly the similarity between the words that express those concepts, (1) can be applied directly on the taxonomic relations. The most important and significant relationship among concepts expressed in any taxonomy is the generalization/specialization one, relating concepts or classes to their super-and sub-concepts or classes, respectively. According to the definition in [2], this yields a similarity measure rather than a full semantic relatedness measure, but we are currently working to extend it by taking into account relations other than hyponimy as well. Intuitively, the closer a common ancestor of two concepts c and c , the more they can be considered as similar to each other, and various distance measure proposed in the literature are based on the length of the paths that link the concepts to be compared to their closest common ancestor. In our case, (1) requires three parameters: one expressing the common information between the two objects to be compared, and the others expressing the information carried by each of the two but not by the other.","refs":[{"start":445,"end":448,"marker":"bibr","target":"#b1"}]},{"text":"If the taxonomy is a hierarchy, and hence can be represented as a tree, this ensures that the path connecting each node (concept) to the root (the most general concept) is unique: let us call < p 1 , . . . , p n > the path related to c , and < p 1 , . . . , p n > the path related to c . Thus, given any two concepts, their closest common ancestor is uniquely identified, as the last element in common in the two paths: suppose this is the k-th element (i.e., ∀i = 1, . . . , k :","refs":[]},{"text":"Consequently, three sub-paths are induced: the sub-path in common, going from the root to such a common ancestor (< p 1 , . . . , p k >), and the two trailing sub-paths (< p k+1 , . . . , p n > and < p k+1 , . . . , p n >). Now, the former can be interpreted as the common information, and the latter as the residuals, and hence their lengths (n -k, k, n -k) can serve as arguments (n, l, m) to apply the similarity formula. This represents a novelty with respect to other approaches in the literature, where only one or both of the trailing parts are typically exploited, and is also very intuitive, since the longest the path from the top concept to the common ancestor, the more they have in common, and the higher the returned similarity value.","refs":[]},{"text":"Actually, in real-world domains the taxonomy is not just a hierarchy, but rather it is a heterarchy, meaning that multiple inheritance must be taken into account and hence a concept can specialize many other concepts. This is very relevant as regards the similarity criterion above stated, since in a heterarchy the closest common ancestor and the paths linking two nodes are not unique, hence many incomparable common ancestors and paths between concepts can be found, and going to the single common one would very often result in overgeneralization. Our solution to this problem is computing the whole set of ancestors of either concept, and then considering as common information the intersection of such sets, and as residuals the two symmetric differences. Again this is fairly intuitive, since the number of common ancestors can be considered a good indicator of the common information and features between the two concepts, just as the number of different ancestors can provide a reasonable estimation of the different information and features they own.","refs":[]}]},{"title":"Evaluation","paragraphs":[{"text":"To assess the effectiveness of the proposed technique, two separate evaluations must be carried out. First of all, the taxonomic similarity measure alone must be proved effective in returning sensible similarity values for couples of concepts. Then, the overall similarity framework integrating both structural and taxonomic similarity assessment must be proved effective in evaluating the similarity between complex description. In the case of NLP, the latter must additionally show its ability in overcoming problems of interpretation due to the presence of polysemous words. We will show with some examples that both these requirements can be satisfied by the proposed approach.","refs":[]},{"text":"As to the taxonomic similarity assessment alone, consider the following words and concepts, and some of the corresponding similarity values reported in Table 2:","refs":[{"start":158,"end":159,"marker":"table","target":"#tab_1"}]},{"text":"102330245 mouse (animal) : 'any of numerous small rodents typically resembling diminutive rats having pointed snouts and small ears on elongated bodies with slender usually hairless tails' 103793489 mouse (device) : 'a hand-operated electronic device that controls the coordinates of a cursor on your computer screen as you move it around on a pad; on the bottom of the device is a ball that rolls on the surface of the pad' 103082979 computer (device) : 'a machine for performing calculations automatically' calculating machines)' 102121620 cat (pet) : 'feline mammal usually having thick soft fur and no ability to roar: domestic cats; wildcats' 102127808 cat (wild) : 'any of several large cats typically able to roar and living in the wild' 102129604 tiger (animal) : 'large feline of forests in most of Asia having a tawny coat with black stripes; endangered' 102084071 dog (pet) : 'a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds' 102374451 horse (animal) : 'solid-hoofed herbivorous quadruped domesticated since prehistoric times' 103624767 horse (chess) : 'a chessman shaped to resemble the head of a horse; can move two squares horizontally and one vertically (or vice versa)'","refs":[]},{"text":"At the level of concepts, it is possible to note that the similarity ranking is quite intuitive, in that less related concepts receive a lower value. The closest pairs are 'wild cat'-'tiger' and 'pet cat'-'tiger', followed by 'mouse (animal)'-'cat (pet)', then by 'mouse (device)'-'computer (device)', by 'cat (pet)'-'dog (pet)' and by 'dog (pet)'-'horse (animal)', all with similarity values above 0.5. Conversely, all odd pairs, mixing animals and devices or objects (including polysemic words), get very low values, below 0.4. Then, for checking the overall structural and taxonomic similarity assessment capability, let us go back to the sample sentences in the Introduction for an application of the proposed taxonomically-enhanced similarity framework to descriptions of sentences written in natural language.","refs":[]},{"text":"As a first step, the similarity between single words must be assessed. Applying the proposed procedure, the similarity values are as follows:","refs":[]},{"text":"boy-girl = 0.75 boy-hammer = 0.435 girl-hammer = 0.435 want-desire = 0.826 want-hit = 0.361 desire-hit = 0.375 yellow-small = 0.562 small-small = 1 dog-canary = 0.667 dog-nail = 0.75 canary-nail = 0.386 It is possible to note that all similarities agree with the intuition, except the pair dog-nail that gets a higher similarity value than dog-canary, due to the interpretations of 'dog' as 'a hinged catch that fits into a notch of a ratchet to move a wheel forward or prevent it from moving backward' and 'nail' as 'a thin pointed piece of metal that is hammered into materials as a fastener'.","refs":[]},{"text":"Without considering taxonomic information, the generalization between s1 and s2 and between s2 and s3 is: sentence(X) :-subj(X,Y), pred(X,W), dir obj(X,Z), noun(Y,Y1), sing(Y1), verb(W,W1), prest(W1), adj(Z,Z1), noun(Z,Z2), sing(Z2).","refs":[]},{"text":"while the generalization between s1 and s3 is:","refs":[]},{"text":"sentence(X) :-subj(X,Y), pred(X,W), dir obj(X,Z), noun(Y,Y1), sing(Y1), verb(W,W1), pres(W1), adj(Z,Z1), tax(small(Z1)), noun(Z,Z2), sing(Z2).","refs":[]},{"text":"so that the latter, having an additional literal with respect to the former, will take a greater similarity value due to just the structural similarity of the two sentences, in spite of the very different content. Conversely, by considering the taxonomic similarity among words, the comparisons become: fs(s1,s2) = 2.444 fs(s1,s3) = 2.420 fs(s2,s3) = 2.318","refs":[]},{"text":"where, indeed, the first two sentences neatly get the largest similarity value with respect to the other combinations. Notwithstanding the 'dog-nail' ambiguity, the overall correct similarity ranking between sentences is correct.","refs":[]},{"text":"In order to better understand the effect of the approach on the similarity values, other tests were performed on the following sample sentences:","refs":[]},{"text":"1-\"the boy buys a jewel for a girl\" 2-\"the girl receives a jewel from a boy\" 3-\"a young man purchases a gem for a woman\" 4-\"a young man purchases a precious stone for a woman\" having a different structure (e.g., transitive vs intransitive in 1-2), containing synonyms that could belong to different synsets (boy vs 'young man' in 1-3), or made up of multiple words instead of a single one (e.g., gem vs precious stone in 1-4). For these sentences the similarity values obtained were: fs(1,2) = 2.383 fs(1,3) = 2.484 fs(1,4) = 2.511","refs":[]}]},{"title":"Conclusions","paragraphs":[{"text":"Information retrieval effectiveness has become a crucial issue with the enormous growth of available digital documents and the spread of Digital Libraries. Search and retrieval are mostly carried out on the textual content of documents, and traditionally only at the lexical level. However, pure term-based queries are very limited because most of the information in natural language is carried by the syntactic and logic structure of sentences. To take into account such a structure, powerful relational languages, such as first-order logic, must be exploited. However, logic formulae constituents are typically uninterpreted (they are considered as purely syntactic entities), whereas words in natural language express underlying concepts that involve several implicit relationships, as those expressed in a taxonomy. This problem can be tackled by providing the logic interpreter with suitable taxonomic background knowledge. This work proposed the exploitation of a similarity framework that includes both structural and taxonomic features to assess the similarity between First-Order Logic (Horn clause) descriptions of texts in natural language, in order to support more sophisticated information retrieval approaches than simple termbased queries. Although the proposed framework applies to any kind of structural description and taxonomy, being able to reuse an already existing taxonomy would be of great help. For this reason, the examples reported in this paper exploited the WordNet (WN) database, that can be naturally embedded in the proposed framework. Other works exist in the literature that combine in various shapes and for different purposes structural (and possibly logical) descriptions of sentences, some kind of similarity and WN. Some concern Question Answering [17], others Textual Entailment [9,4,1,15]. However, the taxonomy relationships exploited in these works, or the way in which the structure of sentences is handled, makes them useless to our purpose.","refs":[{"start":1787,"end":1791,"marker":"bibr","target":"#b17"},{"start":1819,"end":1822,"marker":"bibr","target":"#b8"},{"start":1822,"end":1824,"marker":"bibr","target":"#b3"},{"start":1824,"end":1826,"marker":"bibr","target":"#b0"},{"start":1826,"end":1829,"marker":"bibr","target":"#b15"}]},{"text":"Evaluation on a sample case shows the viability of the solution, and its robustness with respect to problems due to lexical ambiguity and polysemy. Several nonorganized small experiments on tens of sentences having different length have been carried out so far, confirming the sample results, but revealing large computational times (1-2 min for long sentences). Thus, a first direction for future work will concern efficiency improvement in order to make it scalable. After that, more thorough experimentation and fine-tuning of the taxonomic similarity computation methodology by exploiting other relationships represented in WordNet will make sense. Also application of the proposed similarity framework to other problems, such as Word Sense Disambiguation in phrase structure analysis would be interesting directions deserving further investigation.","refs":[]}]}],"tables":{"tab_0":{"heading":"Table 1 .","description":"First-order logic language for structural description of sentences","rows":[["subj(X,Y) Y is the subject of sentence X"],["pred(X,Y) Y is the predicate of sentence X"],["dir obj(X,Y) Y is the direct object of sentence X"],["ind obj(X,Y) Y is the in direct object of sentence X"],["noun(X,Y) Y is a noun appearing in component X of the sentence"],["verb(X,Y) Y is a verb appearing in component X of the sentence"],["adj(X,Y) Y is an adjective appearing in component X of the sentence"],["adv(X,Y) Y is an adverb appearing in component X of the sentence"],["prep(X,Y) Y is a preposition appearing in component X of the sentence"],["sing(X)","the number of noun X is singular"],["pl(X)",""]]},"tab_1":{"heading":"Table 2 .","description":"Sample similarity values between WordNet words/concepts","rows":[["Concept","Concept","Similarity"],["cat (wild) [102127808]","tiger (animal) [102129604]","0.910"],["cat (pet) [102121620]","tiger (animal) [102129604]","0.849"],["mouse (animal) [102330245] cat (pet) [102121620]","0.775"],["mouse (device) [103793489] computer (device) [103082979]","0.727"],["cat (pet) [102121620]","dog (pet) [102084071]","0.627"],["cat (wild) [102127808]","dog (pet) [102084071]","0.627"],["dog (pet) [102084071]","horse (domestic) [102374451]","0.542"],["mouse (animal) [102330245] computer (device) [103082979]","0.394"],["mouse (animal) [102330245] mouse (device) [103793489]","0.394"],["mouse (device) [103793489] cat (pet) [102121620]","0.384"],["cat (domestic) [102121620] computer (device) [103082979]","0.384"],["horse (domestic) [102374451] horse (chess) [103624767]","0.339"]]}},"abstract":{"title":"Abstract","paragraphs":[{"text":"Information retrieval effectiveness has become a crucial issue with the enormous growth of available digital documents and the spread of Digital Libraries. Search and retrieval are mostly carried out on the textual content of documents, and traditionally only at the lexical level. However, pure term-based queries are very limited because most of the information in natural language is carried by the syntactic and logic structure of sentences. To take into account such a structure, powerful relational languages, such as first-order logic, must be exploited. However, logic formulae constituents are typically uninterpreted (they are considered as purely syntactic entities), whereas words in natural language express underlying concepts that involve several implicit relationships, as those expressed in a taxonomy. This problem can be tackled by providing the logic interpreter with suitable taxonomic knowledge.","refs":[]},{"text":"This work proposes the exploitation of a similarity framework that includes both structural and taxonomic features to assess the similarity between First-Order Logic (Horn clause) descriptions of texts in natural language, in order to support more sophisticated information retrieval approaches than simple term-based queries. Evaluation on a sample case shows the viability of the solution, although further work is still needed to study the framework more deeply and to further refine it.","refs":[]}]}}