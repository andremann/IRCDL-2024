{"bibliography":{"title":"Data Interoperability and Curation: The European Film Gateway Experience","authors":[{"person_name":{"surname":"Artini","first_name":"Michele"},"affiliations":[{"department":"Istituto di Scienza e Tecnologie dell'Informazione \"A. Faedo","institution":"Consiglio Nazionale delle Ricerche","laboratory":null}],"email":null},{"person_name":{"surname":"Bardi","first_name":"Alessia"},"affiliations":[{"department":"Istituto di Scienza e Tecnologie dell'Informazione \"A. Faedo","institution":"Consiglio Nazionale delle Ricerche","laboratory":null}],"email":null},{"person_name":{"surname":"Biagini","first_name":"Federico"},"affiliations":[{"department":"Istituto di Scienza e Tecnologie dell'Informazione \"A. Faedo","institution":"Consiglio Nazionale delle Ricerche","laboratory":null}],"email":null},{"person_name":{"surname":"Debole","first_name":"Franca"},"affiliations":[{"department":"Istituto di Scienza e Tecnologie dell'Informazione \"A. Faedo","institution":"Consiglio Nazionale delle Ricerche","laboratory":null}],"email":null},{"person_name":{"surname":"Bruzzo","first_name":"Sandro"},"affiliations":[{"department":"Istituto di Scienza e Tecnologie dell'Informazione \"A. Faedo","institution":"Consiglio Nazionale delle Ricerche","laboratory":null}],"email":null},{"person_name":{"surname":"Manghi","first_name":"Paolo"},"affiliations":[{"department":"Istituto di Scienza e Tecnologie dell'Informazione \"A. Faedo","institution":"Consiglio Nazionale delle Ricerche","laboratory":null}],"email":null},{"person_name":{"surname":"Mikulicic","first_name":"Marko"},"affiliations":[{"department":"Istituto di Scienza e Tecnologie dell'Informazione \"A. Faedo","institution":"Consiglio Nazionale delle Ricerche","laboratory":null}],"email":null},{"person_name":{"surname":"Savino","first_name":"Pasquale"},"affiliations":[{"department":"Istituto di Scienza e Tecnologie dell'Informazione \"A. Faedo","institution":"Consiglio Nazionale delle Ricerche","laboratory":null}],"email":null},{"person_name":{"surname":"Zoppi","first_name":"Franco"},"affiliations":[{"department":"Istituto di Scienza e Tecnologie dell'Informazione \"A. Faedo","institution":"Consiglio Nazionale delle Ricerche","laboratory":null}],"email":null}],"date":null,"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"keywords":["Data cleansing","Data curation","Data infrastructure","D-net","Data interoperability","Aggregation system","Metadata formats","Audio video"],"citations":{"b0":{"title":"European Film Gateway project","authors":[],"date":null,"ids":null,"target":"http://www.europeanfilmgateway.eu","publisher":null,"journal":null,"series":null,"scope":null},"b1":{"title":"eContentPlus framework","authors":[],"date":null,"ids":null,"target":"http://ec.europa.eu/information_society/activities/econtentplus/index_en.html","publisher":null,"journal":null,"series":null,"scope":null},"b2":{"title":"Functional requirements for bibliographic records","authors":[],"date":{"year":"1998","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":"UBCIM Publications; New Series","scope":{"volume":19,"pages":null}},"b3":{"title":"Metadata: The Foundations of Resource Description","authors":[{"person_name":{"surname":"Weibel","first_name":"S"},"affiliations":[],"email":null}],"date":{"year":"1995","month":null,"day":null},"ids":null,"target":"http://www.dlib.org/dlib/July95/07weibel.html","publisher":null,"journal":"D-Lib Magazine","series":null,"scope":null},"b4":{"title":"Cinematographic Works Standard. Committee","authors":[],"date":{"year":"2005","month":null,"day":null},"ids":null,"target":null,"publisher":"Technical","journal":null,"series":null,"scope":null},"b5":{"title":"BASE: Bielefeld Academic Search Engine","authors":[],"date":null,"ids":null,"target":"http://www.base-search.net","publisher":null,"journal":null,"series":null,"scope":null},"b6":{"title":"DAREnet: Digital Academic Repositories","authors":[],"date":null,"ids":null,"target":"http://www.darenet.nl/","publisher":null,"journal":null,"series":null,"scope":null},"b7":{"title":"OAIster Official Site","authors":[],"date":null,"ids":null,"target":"http://www.oaister.org","publisher":null,"journal":null,"series":null,"scope":null},"b8":{"title":"Bricks Project","authors":[],"date":null,"ids":null,"target":"http://www.brickscommunity.org/","publisher":null,"journal":null,"series":null,"scope":null},"b9":{"title":"DILIGENT Project","authors":[],"date":null,"ids":null,"target":"http://diligent.ercim.eu/","publisher":null,"journal":null,"series":null,"scope":null},"b10":{"title":"D4Science Project","authors":[],"date":null,"ids":null,"target":"http://www.d4science.eu/","publisher":null,"journal":null,"series":null,"scope":null},"b11":{"title":"CLARIN Project","authors":[],"date":null,"ids":null,"target":"http://www.clarin.eu/14","publisher":null,"journal":null,"series":null,"scope":null},"b12":{"title":"ScholNet Project","authors":[],"date":null,"ids":null,"target":"ftp://ftp.cordis.europa.eu/pub/ist/docs/rn/scholnet.pdf","publisher":null,"journal":null,"series":null,"scope":null},"b13":{"title":"D-NET Software Toolkit","authors":[],"date":null,"ids":null,"target":"http://www.d-net.research-infrastructures.eu","publisher":null,"journal":null,"series":null,"scope":null},"b14":{"title":"DRIVER Project","authors":[],"date":null,"ids":null,"target":"http://www.driver-community.eu/","publisher":null,"journal":null,"series":null,"scope":null},"b15":{"title":"OpenAIRE Project","authors":[],"date":null,"ids":null,"target":"http://www.openaire.eu/","publisher":null,"journal":null,"series":null,"scope":null},"b16":{"title":"HOPE Project","authors":[],"date":null,"ids":null,"target":"http://www.peoplesheritage.eu","publisher":null,"journal":null,"series":null,"scope":null},"b17":{"title":"Common interoperability schema for archival resources and filmographic descriptions","authors":[{"person_name":{"surname":"Balzer","first_name":"D"},"affiliations":[],"email":null},{"person_name":{"surname":"Debole","first_name":"F"},"affiliations":[],"email":null},{"person_name":{"surname":"Savino","first_name":"P"},"affiliations":[],"email":null}],"date":null,"ids":null,"target":null,"publisher":null,"journal":"EFG Project","series":null,"scope":{"volume":null,"pages":{"from_page":20,"to_page":20}}},"b18":{"title":"General-Purpose Digital Library Content Laboratory Systems","authors":[{"person_name":{"surname":"Manghi","first_name":"P"},"affiliations":[],"email":null},{"person_name":{"surname":"Mikulicic","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Candela","first_name":"L"},"affiliations":[],"email":null},{"person_name":{"surname":"Artini","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Bardi","first_name":"A"},"affiliations":[],"email":null}],"date":{"year":"2010","month":null,"day":null},"ids":null,"target":null,"publisher":"Springer","journal":null,"series":null,"scope":{"volume":6273,"pages":{"from_page":14,"to_page":21}}},"b19":{"title":"Realizing and Maintaining Aggregative Digital Library Systems: D-NET Software Toolkit and OaIster System","authors":[{"person_name":{"surname":"Manghi","first_name":"P"},"affiliations":[],"email":null},{"person_name":{"surname":"Mikulicic","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Candela","first_name":"L"},"affiliations":[],"email":null},{"person_name":{"surname":"Castelli","first_name":"D"},"affiliations":[],"email":null},{"person_name":{"surname":"Pagano","first_name":"P"},"affiliations":[],"email":null}],"date":{"year":"2010","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"D-Lib Magazine","series":null,"scope":{"volume":16,"pages":null}},"b20":{"title":"The making of the open archives initiative protocol for metadata harvesting","authors":[{"person_name":{"surname":"Lagoze","first_name":"C"},"affiliations":[],"email":null},{"person_name":{"surname":"Van De Sompel","first_name":"H"},"affiliations":[],"email":null}],"date":{"year":"2003","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"Library Hi Tech","series":null,"scope":{"volume":21,"pages":{"from_page":118,"to_page":128}}},"b21":{"title":"PACE: A General-Purpose Tool for Authority Control","authors":[{"person_name":{"surname":"Manghi","first_name":"P"},"affiliations":[],"email":null},{"person_name":{"surname":"Mikulicic","first_name":"M"},"affiliations":[],"email":null}],"date":{"year":"2011","month":null,"day":null},"ids":null,"target":null,"publisher":"Springer","journal":null,"series":null,"scope":{"volume":240,"pages":{"from_page":80,"to_page":92}}},"b22":{"title":"Searching and browsing film archives. The European Film Gateway Approach","authors":[{"person_name":{"surname":"Savino","first_name":"P"},"affiliations":[],"email":null},{"person_name":{"surname":"Debole","first_name":"F"},"affiliations":[],"email":null},{"person_name":{"surname":"Eckes","first_name":"G"},"affiliations":[],"email":null}],"date":{"year":"2009","month":"08","day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"b23":{"title":"Encoded Archival Description","authors":[],"date":null,"ids":null,"target":"http://www.loc.gov/ead","publisher":null,"journal":null,"series":null,"scope":null},"b24":{"title":"Encoded Archival Context Corporate Bodies, Persons, and Families","authors":[],"date":null,"ids":null,"target":"http://www.viaf.org","publisher":null,"journal":null,"series":null,"scope":null}},"sections":[{"title":"Introduction","paragraphs":[{"text":"Nowadays, many digital film archives are available in Europe, thanks to a significant effort performed in digitizing existing collections of images, videos, and cinemarelated material (e.g., audio documents, photographs, posters, drawings, text documents). These archives make their collections available to the community through repository platforms or similar technologies, which support web portals to search, browse, and visualize cinema-related metadata and relative digital objects. Although the information dissemination service they offer is extremely useful, their autonomy still represents a limit to the urgent demand of immediate and global access to information required by today's communities.","refs":[]},{"text":"The EFG (European Film Gateway) Best Practice Network [1], funded by the European Commission under the eContentplus programme [2], provides community users with a single entry point from which content of several archives can be searched in a uniform fashion, abstracting over their differences and peculiarities. Specifically, EFG delivers a data infrastructure whose aim is to aggregate content from the most prominent European film archives and cinematheques in order to make it available to end users and authorized third-party consumers, including Europeana (European Digital Library) [3]. The project started in September 2008 and was completed in October 2011 and its two-year continuation will kick-off on February 2012. It includes 20 partner institutions from 14 European countries, and today provides direct access to about 640,000 digital objects including films, photos, posters, drawings, and text documents, plus authority files for film works, persons and corporate bodies.","refs":[{"start":54,"end":57,"marker":"bibr","target":"#b0"},{"start":126,"end":129,"marker":"bibr","target":"#b1"},{"start":589,"end":592,"marker":"bibr","target":null}]},{"text":"Although film archives contain similar digital movie-related objects, their data models (and relative metadata schemas) may be very different in structure and semantics, as well as their content be subject to errors or be duplicated. In this paper, we describe the solutions to the data interoperability and data curation challenges faced in EFG in order to deliver a unified, homogeneous, high-quality, and unambiguous European information space of movie metadata.","refs":[]},{"text":"Data interoperability. The EFG infrastructure has adopted a bottom-up approach to data aggregation where interoperability is achieved by (i) defining a common data model and relative metadata schema together with domain specific vocabularies, and (ii) implementing the technology to collect, transform onto the common schema, and harmonize metadata records collected from the archives. The EFG data infrastructure technology is powered by the D-NET [15] software toolkit, which provides a rich and customizable set of data management services capable of coping with issues such as metadata collection, storage, indexing, transformation, and cleaning. D-NET also offers services for the deployment of portals that can be configured according to the target community requirements, hence enabling end-users to search/browse the information space. Moreover, the D-NET toolkit includes mediation services for systems to access the space through standard protocols, such as OAI-PMH [22] and SRW/CQL, and several exchange formats.","refs":[{"start":449,"end":453,"marker":"bibr","target":"#b13"},{"start":976,"end":980,"marker":"bibr","target":"#b20"}]},{"text":"Data curation. Once metadata records are aggregated into a structurally and semantically homogenous information space, the EFG infrastructure enables archive experts to perform data curation actions by delivering easy-to-use tools for metadata validation, editing, de-duplication (e.g. the same persons and movies entities collected from different repositories). To this aim, the authors extended D-NET with services implementing the data curation functionalities for content and vocabulary checking, metadata editing, and authority file management (i.e., record de-duplication).","refs":[]},{"text":"Paper Outline: Section 2 gives an overview of the problem and introduces the adopted solution. Section 3 describes the main characteristics of the EFG common metadata schema. Section 4 describes the D-NET software toolkit. Section 5 presents the EFG D-NET-based infrastructure and its extension with D-NET data curation services. Finally, Section 6 concludes the paper.","refs":[]}]},{"title":"Overview of the Problem and Adopted Solution","paragraphs":[{"text":"The EFG data infrastructure delivers two main requirements as identified by the user community:","refs":[]},{"text":"• Single access point to the European movie archives: it supports advanced search and browse over all different types of collections (videos, images, textual documents), visualization of detailed metadata descriptions, and metadata export to third-party services, including Europeana. • High-quality metadata descriptions: the EFG information space does not contain documents with poor descriptions and avoids duplication of information.","refs":[]},{"text":"As mentioned in the introduction, these requisites are hindered by the highly heterogeneous nature of the archives. In fact, content of different archives generally conforms to different metadata models and XML schemas, whose structure may vary from complex element trees to simple flat sets of elements. Moreover, such content may describe different entities or the same entities, but with distinct semantics; e.g., different vocabularies of terms and format representation standards for dates, names, time durations.","refs":[]},{"text":"To tackle such heterogeneity, EFG delivered two main outcomes: the EFG common data model and relative XML schema, onto which archive metadata records can be mapped; the EFG data infrastructure, whose services offer functionality for (i) collecting XML records from the archives and transforming them onto records matching the common XML metadata schema, and (ii) curating the resulting records by identifying and fixing semantic errors and duplicates. The data infrastructure was realized adopting the D-NET Software Toolkit [15] and extending it with new services for data curation.","refs":[{"start":525,"end":529,"marker":"bibr","target":"#b13"}]},{"text":"The data ingestion workflow (sketched in Fig. 1.) consists of four phases and requires an interaction between domain experts and infrastructure administrators, adequately supported by the infrastructure services. These actors are driven by a detailed methodology, whose aim is to enable a controlled data ingestion life-cycle which will incrementally lead to the publication in production of a high-quality information space. Such workflow consists of four phases: Phase 1: Metadata Mapping Definition. Domain experts from the archives analyze the metadata they provide to determine how such information may structurally and semantically map onto the EFG metadata schema. The relative structural and semantic mapping rules are handed over to infrastructure administrators, who encode them in the form of D-NET scripts.","refs":[{"start":46,"end":47,"marker":"figure","target":null}]},{"text":"Phase 2: Metadata Transformation and Cleaning. Archive metadata records are collected via OAI-PMH or FTP protocols to be processed through the mapping scripts produced in phase 1 and generate corresponding EFG records. The resulting records are not immediately available for access, but stored in a \"pre-production\" information space, where the Phase 3 of the workflow can take place. As we shall see, the Phase 1 and Phase 2 may be fired several times to refine the mapping rules and achieve the best metadata quality.","refs":[]},{"text":"Phase 3: Metadata Quality Control and Enrichment. Records in the pre-production Information Space can be validated and inspected to identify mapping errors, mistakes (e.g., typos), and duplicates. Specifically, the Content Checker Tool can be used to verify that structural mapping was properly performed, the Vocabulary Checker Tool notifies data providers about EFG records not yet complying with the common vocabularies, and the Authority File Manager (AFM) identifies possible record duplicates. This quality control process may lead to the redefinition of the mapping rules (Phase 1), the adjustments of the mapping scripts (Phase 2), or to a subsequent data enrichment process. The Metadata Editor Tool enables curators to edit EFG records, while the AFM can fire record merge actions and effectively remove the duplicates.","refs":[]},{"text":"Phase 4: Metadata Publishing. EFG records which passed Phase 3 are moved to the production Information Space, where they become visible from the EFG portal and can also be exported to third-party providers, such as Europeana.","refs":[]}]},{"title":"Fig. 1. Phases of the EFG data ingestion workflow","paragraphs":[]},{"title":"EFG Common Metadata Model and XML Schema","paragraphs":[{"text":"The EFG Common Metadata Model was designed after the analysis of the metadata models and schemas adopted within various organisations operating in the audio/video domain, starting from the data providers of the EFG consortium. This study took into consideration standards such as EAD [25], FRBR [4] and Dublin Core [5], as well as more film-specific standards such as the Cinematographic Works Standards EN 15907 [6]. As a result, eight interrelated entities have been defined in the EFG Common Metadata Model [19][24]:","refs":[{"start":284,"end":288,"marker":"bibr","target":"#b23"},{"start":295,"end":298,"marker":"bibr","target":"#b2"},{"start":315,"end":318,"marker":"bibr","target":"#b3"},{"start":413,"end":416,"marker":"bibr","target":"#b4"},{"start":510,"end":514,"marker":"bibr","target":"#b17"}]},{"text":"• The AVCreation contains the properties of a cinematographic work: the film title, the record source (archive), the country of reference, the publication year, etc. • The AVManifestation contains the information about the physical embodiment of an audiovisual creation. Examples are archival copies (analogue or digital) and database files. Properties of an AVManifestion include language, dimension, duration, coverage, format, rights holder, and provenance. Furthermore we may hav these entities are connected associated to each entity w tionships will be used to su all movies directed by Stan biographies of actors, etc.  2). The metadata rec will be used to retrieve the archived object, while the re upport browsing. As an example, it is possible to search nley Kubrick in the '50s and browse all received awar metadata associated for the film \"2001: A Space Odyssey\" tadata XML Schema [19] implements the common mo XML element types and attributes for all the eight enti es. The common schema is conceived as the type union for each entity) in such a way that one EFG XML rec her with its relationships to other entities. ","refs":[{"start":627,"end":628,"marker":"figure","target":"#fig_0"},{"start":893,"end":897,"marker":"bibr","target":"#b17"}]}]},{"title":"Enabling Data I","paragraphs":[{"text":"In the last decade, as witne net [8], OAIster [9]) and EC DILIGENT [11], D4Scien HOPE [18]), the diffusion o years in several communitie aggregating content from su In the last three Framewor called knowledge infrastru resources of all kinds avail structures, which are envir process, aggregate their da Several technological soluti ity for collecting data from chives, databases), curating offering customized portal of references between publi y and Curation: The European Film Gateway Experience led \"controlled elements\", which are the XML eleme with a given vocabulary of terms.","refs":[{"start":33,"end":36,"marker":"bibr","target":"#b6"},{"start":46,"end":49,"marker":"bibr","target":"#b7"},{"start":67,"end":71,"marker":"bibr","target":"#b9"},{"start":86,"end":90,"marker":"bibr","target":"#b16"}]}]},{"title":"Infrastructures: The D-NET Software Toolk","paragraphs":[{"text":"essed by several national initiatives (e.g., BASE 7, DAR C projects (e.g., Europeana [3], Bricks [10], ScholNet [1 ce [12], DRIVER [16], OpenAIRE [17], CLARIN [1 of Digital Libraries which took place in the last ten-twe es, has been followed by an urgent need for integrating uch DLs to make it available through a single access po rk Programme calls, the European Union initiated the ucture vision, inspired by the same goal of unifying d lable in Europe. The idea was that of devising data inf ronments through which several organizations can sh ata resources by adopting an economy of scale approa ions [20] were devised in such projects, to offer function m heterogeneous data sources (e.g. repository systems, g such data to form a homogeneous information space, services to operate over such space; e.g. search, infere ications, citation calculation, etc. Of particular interest to Digital Libraries is the D-NET software toolkit, resulting from the experience of DRIVER, DRIVER-II, and OpenAIRE EC projects. D-NET is an open source solution specifically devised for the construction and operation of customized data infrastructures. D-NET provides a service-oriented framework where data infrastructures can be constructed in a LEGO-like approach, by selecting and properly combining the required D-NET services (such architectural concept was devised at CNR-ISTI by some of the authors of this paper). The resulting infrastructures are customizable (e.g., transformation into common metadata formats can be configured to match community preferences), extensible (e.g. new services can be integrated, to offer functionality not yet supported by D-NET), and scalable (e.g., storage and index replicas can be maintained and deployed on remote nodes to tackle multiple concurrent accesses or very-large data size). D-NET offers a rich set of services (see Fig. 3) targeting aspects such as data collection (mediation area), data mappings from formats to formats (mapping area), and data access (provision area). Services can be customized and combined to meet the data workflow requirements of a target user community. As proven by the several installations [15] and adoption in a number of European projects (DRIVER, DRIVER II, OpenAIRE, HOPE), D-NET represents an optimal and sustainable solution [21] for the realization of the EFG infrastructure. In the context of the EFG project, D-NET has been successfully extended with further generic and configurable services (curation area) for advanced curation and validation of XML metadata records.","refs":[{"start":97,"end":101,"marker":"bibr","target":"#b8"},{"start":118,"end":122,"marker":"bibr","target":"#b10"},{"start":131,"end":135,"marker":"bibr","target":"#b14"},{"start":146,"end":150,"marker":"bibr","target":"#b15"},{"start":606,"end":610,"marker":"bibr","target":null},{"start":1865,"end":1866,"marker":"figure","target":"#fig_1"},{"start":2162,"end":2166,"marker":"bibr","target":"#b13"},{"start":2303,"end":2307,"marker":"bibr","target":"#b19"}]}]},{"title":"EFG Data Infrastructure","paragraphs":[{"text":"The EFG data infrastructure consists of the D-NET services shown in Fig. 3, appropriately combined to support the data ingestion workflow presented in Section 2. In particular, the services in the Data Curation are resulted from the project activities.","refs":[{"start":73,"end":74,"marker":"figure","target":"#fig_1"}]},{"text":"They were devised in order to meet the requirements of EFG archive partners, but engineered to support their functionalities when operating over arbitrary XML schemas.","refs":[]}]},{"title":"Metadata Mapping Definition, Transformation, and Cleaning","paragraphs":[{"text":"Archives and their experts joining the EFG data infrastructure are supported with a methodology that facilitates the definition of structural mappings from their archive schema onto the EFG common metadata schema and semantic mappings from their vocabularies onto the common vocabularies. A mapping consists in a set of rules, which serve as input to the infrastructure administrators to configure the services in the Data Mapping Area. Here, the Transformator Service and the Cleaner Service run PERL scripts which parse, validate and transform the source records into EFG records according to the defined rules. The Transformator Service is responsible for the application of structural rules. Such rules define the correspondence among elements and attributes of the archive schema and elements and attributes of the EFG schema. Structural mapping is not as trivial as it may seem, due onto several interrelated EF More in detail, a structural m dentifying the schema element relative to the input value identifying the schema elements (and the sub-entity) o hould be mapped; tes if the source element is mandatory (if not, the recor tes if the source element is repeatable; f the mapping rule.","refs":[]},{"text":"ead responsible for the application of semantic rules. S f the archive schema and the corresponding element of element and target element of structural rules), and def n the terms of the respective vocabularies.","refs":[]}]},{"title":"Control and Enrichment","paragraphs":[{"text":"FG data infrastructure the D-NET software toolkit has b g services, constituting the D-NET Data Curation Area.","refs":[]},{"text":"ntent Checker (see Fig. 4) is a validation tool that allo rowsing the pre-production Information Space in order have been correctly harvested and mapped. Vocabulary Checker. The Vocabulary Checker gives access to the metadata records that do not satisfy the constraints imposed by the common metadata schema and vocabularies after the transformation and cleaning phases. The Vocabulary Checker displays the number, the types and the positions of errors in the records of the Information Space. Thanks to the browse by error typology functionality, curators can decide if an error can be solved directly in the Information Space via the Metadata Editor Tool or in the original source archive.","refs":[{"start":24,"end":25,"marker":"figure","target":"#fig_2"}]},{"text":"Metadata Editor Tool. The Metadata Editor Tool (MET) is a cataloguing tool for the enrichment of the Information Space. It allows data curators to add, edit and delete metadata records in the Information Space, as well as to establish relationships between existing (authority) records, even if coming from different sources. The MET is aware of controlled vocabularies, hence supports data curators while editing controlled elements by proposing a drop down list with all and only the terms defined by the associated controlled vocabulary. For example, let us suppose the Det Danske Filminstitut (DFI) EFG data provider provides a metadata record relative to the movie \"Olsen Banden over alle bjerge\", which features the actor Ove Sprogøe, but the actor is not mentioned in the metadata record. In order to make the record retrievable through the EFG portal to end users searching for \"Ove Sprogøe\", the movie record must be enriched with such information. The MET allows data curators to construct a relationship between the DFI movie metadata record and the person record, be the latter provided by harvesting other archives or created by data curators themselves.","refs":[]},{"text":"Authority File Manager. The Authority File Manager (PACE [23]) is an advanced tool that curators can use to merge duplicate records and disambiguate the information space. The tool is capable of automatically identifying the pairs of records candidate for merging based on a multi-sort version of the sorted neighbourhood algorithm and a record similarity function that is customizable by data curators (they can chose between a range of similarity functions and assign different weights to the record fields). After one run of the candidate identification process, record pairs are displayed in descending order with respect to a 0…1 similarity distance. The curator has the responsibility of merging the two records (i.e., deciding if the two records are indeed representing the same entity). In the EFG scenario, the AFM has been configured to merge metadata records relative to persons and film works (AVCreation). Once the information space is disambiguated, authoritative records can also be linked to international ontologies such as VIAF [27] or transformed according to standard encodings, such as EAC-CPF [26], for external re-use.","refs":[{"start":57,"end":61,"marker":"bibr","target":"#b21"},{"start":1046,"end":1050,"marker":"bibr","target":null},{"start":1115,"end":1119,"marker":"bibr","target":"#b24"}]}]},{"title":"Metadata Publishing","paragraphs":[{"text":"The EFG Portal is available at [1]. Facilities like advanced metadata search and browse (by collection, provider, date, language and media type), search results filtering, video streaming, photo gallery and news highlights enhance the user experience in the phases of search and access. Moreover, D-NET offers services to export metadata records through OAI-PMH, OAI-ORE, and SRW/CQL protocols. EFG operate such services to automatically serve its information space to third-party consumers, above all the Europeana project [3], of which EFG is a direct feeder.","refs":[{"start":31,"end":34,"marker":"bibr","target":"#b0"}]}]},{"title":"Conclusions and Future Work","paragraphs":[{"text":"We described the solutions adopted in the EFG Best Practice Network to achieve a complete integration of different national audio/video archives. The solution is based on the creation of a metadata schema that is an expressive interoperability metadata schema integrating well-known standards with peculiarities of data providers' idiosyncratic schemas. The schema has therefore both the power to preserve the input metadata quality and the simplicity to enable simple mappings from all different archives. Metadata aggregation is based on the use of the D-NET software toolkit, a data infrastructure enabling software. D-NET offers services for metadata collection, transformation, and provision. Its service-oriented framework allows for the addition of new services, to add domain specific missing functionalities. In EFG this resulted in the realization and integration of advanced curation and validation services: the Content Checker, the Vocabulary Checker, the Metadata Editor Tool and the Authority File Manager. The current limitations of the EFG data infrastructure relate to the manual effort required in the phases of mapping rule definition and implementation and of metadata quality control and enrichment. Whilst some of the operations cannot be fully automatized, because archive administrators want to have control on data manipulation processes, we foresee some enhancements to (i) facilitate domain experts in the definition of mappings, (ii) (partly) automate the script-implementation of those mappings, and (iii) support experts and system administrator to ensure better metadata quality. Data provider experts currently define mappings by filling prefabricated Excel worksheets. Such files are then manually processed by infrastructure administrators to generate the corresponding transformation scripts. We could simplify this workflow by supporting data providers with a mapping definition tool, equipped with a GUI that shows a visual representation of their metadata schema and the common schema, and allows them to draw mappings by \"dragging and dropping\" elements of the first to elements of the second. The same tool could \"generate\" transformation scripts, at least when mappings can be reduced to a sequence of rule templates. Finally, we believe that the number of iterations of the transformation/cleaning and validation workflow could be reduced by providing a mapping test environment, where domain experts and infrastructure admins can verify the result of their mappings over a set of sample records.","refs":[]}]}],"tables":{},"abstract":{"title":"Abstract","paragraphs":[{"text":"Film archives, containing collections of cinema-related digital material, have been created in many European countries. Today, the EC Best Practice Network Project EFG (European Film Gateway) provides a single access point to 59 collections from 19 archives and across 14 European countries, for a total of 640,000 digital objects. This paper illustrates challenges and solutions in the realization of the EFG data infrastructure. These mainly concerned the curation and interoperability issues derived by the need of aggregating metadata from heterogeneous archives (different data models, hence metadata schemas, and exchange formats). EFG designed a common data model for movie information, onto which archives data models can be optimally mapped. It realizes a data infrastructure based on the D-NET software toolkit, capable of dealing with data collection, mapping, cleaning, indexing, and access provision through web portals or standard access protocols. To achieve its objectives EFG has extended D-NET with advanced tools for data curation.","refs":[]}]}}