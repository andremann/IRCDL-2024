{"bibliography":{"title":"Negation Detection for Robust Adverse Drug Event Extraction From Social Media Texts*","authors":[{"person_name":{"surname":"Scaboro","first_name":"Simone"},"affiliations":[{"department":null,"institution":"University of Udine","laboratory":null}],"email":"scaboro.simone@spes.uniud.it"},{"person_name":{"surname":"Portelli","first_name":"Beatrice"},"affiliations":[{"department":null,"institution":"University of Udine","laboratory":null}],"email":"portelli.beatrice@spes.uniud.it"},{"person_name":{"surname":"Chersoni","first_name":"Emmanuele"},"affiliations":[{"department":null,"institution":"The Hong Kong Polytechnic University","laboratory":null}],"email":"emmanuele.chersoni@polyu.edu.hk"},{"person_name":{"surname":"Santus","first_name":"Enrico"},"affiliations":[{"department":null,"institution":"CSAIL MIT","laboratory":null}],"email":"esantus@gmail.com"},{"person_name":{"surname":"Serra","first_name":"Giuseppe"},"affiliations":[{"department":null,"institution":"University of Udine","laboratory":null}],"email":"giuseppe.serra@uniud.it"}],"date":null,"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"keywords":["Social media","Negation detection","Adverse drug events","Annotated corpora creation","Bio-medical data"],"citations":{"b0":{"title":"NADE: A benchmark for robust adverse drug events extraction in face of negations","authors":[{"person_name":{"surname":"Scaboro","first_name":"S"},"affiliations":[],"email":null},{"person_name":{"surname":"Portelli","first_name":"B"},"affiliations":[],"email":null},{"person_name":{"surname":"Chersoni","first_name":"E"},"affiliations":[],"email":null},{"person_name":{"surname":"Santus","first_name":"E"},"affiliations":[],"email":null},{"person_name":{"surname":"Serra","first_name":"G"},"affiliations":[],"email":null}],"date":{"year":"2021","month":null,"day":null},"ids":null,"target":"https://aclanthology.org/2021.wnut-1.26","publisher":"Association for Computational Linguistics","journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":230,"to_page":237}}},"b1":{"title":"Text and Data Mining Techniques in Adverse Drug Reaction Detection","authors":[{"person_name":{"surname":"Karimi","first_name":"S"},"affiliations":[],"email":null},{"person_name":{"surname":"Wang","first_name":"C"},"affiliations":[],"email":null},{"person_name":{"surname":"Metke-Jimenez","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Gaire","first_name":"R"},"affiliations":[],"email":null},{"person_name":{"surname":"Paris","first_name":"C"},"affiliations":[],"email":null}],"date":{"year":"2015","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"ACM Computing Surveys (CSUR)","series":null,"scope":{"volume":47,"pages":{"from_page":1,"to_page":39}}},"b2":{"title":"Portable Automatic Text Classification for Adverse Drug Reaction Detection via Multi-corpus Training","authors":[{"person_name":{"surname":"Sarker","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Gonzalez","first_name":"G"},"affiliations":[],"email":null}],"date":{"year":"2015","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"Journal of Biomedical Informatics","series":null,"scope":{"volume":53,"pages":{"from_page":196,"to_page":207}}},"b3":{"title":"Social Media Mining for Public Health Monitoring and Surveillance","authors":[{"person_name":{"surname":"Paul","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Sarker","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Brownstein","first_name":"J"},"affiliations":[],"email":null},{"person_name":{"surname":"Nikfarjam","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Scotch","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Smith","first_name":"K"},"affiliations":[],"email":null},{"person_name":{"surname":"Gonzalez","first_name":"G"},"affiliations":[],"email":null}],"date":{"year":"2016","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":468,"to_page":479}}},"b4":{"title":"Overview of the Second Social Media Mining for Health (SMM4H) Shared Tasks at AMIA 2017","authors":[{"person_name":{"surname":"Sarker","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Gonzalez-Hernandez","first_name":"G"},"affiliations":[],"email":null}],"date":{"year":"2017","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"Training","series":null,"scope":{"volume":1,"pages":{"from_page":1239,"to_page":1239}}},"b5":{"title":"Overview of the Social Media Mining for Health (SMM4H) Shared Tasks at EMNLP 2018","authors":[{"person_name":{"surname":"Weissenbacher","first_name":"D"},"affiliations":[],"email":null},{"person_name":{"surname":"Sarker","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Paul","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Gonzalez","first_name":"G"},"affiliations":[],"email":null}],"date":{"year":"2018","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"b6":{"title":"Overview of the Fourth Social Media Mining for Health (SMM4H) Shared Tasks at ACL 2019","authors":[{"person_name":{"surname":"Weissenbacher","first_name":"D"},"affiliations":[],"email":null},{"person_name":{"surname":"Sarker","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Magge","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Daughton","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"O'connor","first_name":"K"},"affiliations":[],"email":null},{"person_name":{"surname":"Paul","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Gonzalez","first_name":"G"},"affiliations":[],"email":null}],"date":{"year":"2019","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"b7":{"title":"Overview of the Fifth Social Media Mining for Health Applications Shared Tasks at Coling 2020","authors":[{"person_name":{"surname":"Klein","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Alimova","first_name":"I"},"affiliations":[],"email":null},{"person_name":{"surname":"Flores","first_name":"I"},"affiliations":[],"email":null},{"person_name":{"surname":"Magge","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Miftahutdinov","first_name":"Z"},"affiliations":[],"email":null},{"person_name":{"surname":"Minard","first_name":"A.-L"},"affiliations":[],"email":null},{"person_name":{"surname":"O'connor","first_name":"K"},"affiliations":[],"email":null},{"person_name":{"surname":"Sarker","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Tutubalina","first_name":"E"},"affiliations":[],"email":null},{"person_name":{"surname":"Weissenbacher","first_name":"D"},"affiliations":[],"email":null}],"date":{"year":"2020","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"b8":{"title":"Beyond Accuracy: Behavioral Testing of NLP Models with CheckList","authors":[{"person_name":{"surname":"Ribeiro","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Wu","first_name":"T"},"affiliations":[],"email":null},{"person_name":{"surname":"Guestrin","first_name":"C"},"affiliations":[],"email":null},{"person_name":{"surname":"Singh","first_name":"S"},"affiliations":[],"email":null}],"date":{"year":"2020","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"b9":{"title":"Speculation and Negation: Rules, Rankers, and the Role of Syntax","authors":[{"person_name":{"surname":"Velldal","first_name":"E"},"affiliations":[],"email":null},{"person_name":{"surname":"Øvrelid","first_name":"L"},"affiliations":[],"email":null},{"person_name":{"surname":"Read","first_name":"J"},"affiliations":[],"email":null},{"person_name":{"surname":"Oepen","first_name":"S"},"affiliations":[],"email":null}],"date":{"year":"2012","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"Computational Linguistics","series":null,"scope":{"volume":38,"pages":{"from_page":369,"to_page":410}}},"b10":{"title":"Detecting Negated and Uncertain Information in Biomedical and Review Texts","authors":[{"person_name":{"surname":"Cruz Díaz","first_name":"N"},"affiliations":[],"email":null}],"date":{"year":"2013","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"b11":{"title":"A Simple Algorithm for Identifying Negated Findings and Diseases in Discharge Summaries","authors":[{"person_name":{"surname":"Chapman","first_name":"W"},"affiliations":[],"email":null},{"person_name":{"surname":"Bridewell","first_name":"W"},"affiliations":[],"email":null},{"person_name":{"surname":"Hanbury","first_name":"P"},"affiliations":[],"email":null},{"person_name":{"surname":"Cooper","first_name":"G"},"affiliations":[],"email":null},{"person_name":{"surname":"Buchanan","first_name":"B"},"affiliations":[],"email":null}],"date":{"year":"2001","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"Journal of Biomedical Informatics","series":null,"scope":{"volume":34,"pages":{"from_page":301,"to_page":310}}},"b12":{"title":"Negbert: A Transfer Learning Approach for Negation Detection and Scope Resolution","authors":[{"person_name":{"surname":"Khandelwal","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Sawant","first_name":"S"},"affiliations":[],"email":null}],"date":{"year":"2020","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"b13":{"title":"Resolving the Scope of Speculation and Negation using Transformer-Based Architectures","authors":[{"person_name":{"surname":"Britto","first_name":"B"},"affiliations":[],"email":null},{"person_name":{"surname":"Khandelwal","first_name":"A"},"affiliations":[],"email":null}],"date":{"year":"2020","month":null,"day":null},"ids":{"DOI":null,"arXiv":"arXiv:2001.02885"},"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"b14":{"title":"Multitask Learning of Negation and Speculation using Transformers","authors":[{"person_name":{"surname":"Khandelwal","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Britto","first_name":"B"},"affiliations":[],"email":null}],"date":{"year":"2020","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"b15":{"title":"BERT Prescriptions to Avoid Unwanted Headaches: A Comparison of Transformer Architectures for Adverse Drug Event Detection","authors":[{"person_name":{"surname":"Portelli","first_name":"B"},"affiliations":[],"email":null},{"person_name":{"surname":"Lenzi","first_name":"E"},"affiliations":[],"email":null},{"person_name":{"surname":"Chersoni","first_name":"E"},"affiliations":[],"email":null},{"person_name":{"surname":"Serra","first_name":"G"},"affiliations":[],"email":null},{"person_name":{"surname":"Santus","first_name":"E"},"affiliations":[],"email":null}],"date":{"year":"2021","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"b16":{"title":"Improving Adverse Drug Event Extraction with SpanBERT on Different Text Typologies","authors":[{"person_name":{"surname":"Portelli","first_name":"B"},"affiliations":[],"email":null},{"person_name":{"surname":"Passabì","first_name":"D"},"affiliations":[],"email":null},{"person_name":{"surname":"Lenzi","first_name":"E"},"affiliations":[],"email":null},{"person_name":{"surname":"Serra","first_name":"G"},"affiliations":[],"email":null},{"person_name":{"surname":"Santus","first_name":"E"},"affiliations":[],"email":null},{"person_name":{"surname":"Chersoni","first_name":"E"},"affiliations":[],"email":null}],"date":{"year":"2021","month":null,"day":null},"ids":{"DOI":null,"arXiv":"arXiv:2105.08882"},"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"b17":{"title":"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding","authors":[{"person_name":{"surname":"Devlin","first_name":"J"},"affiliations":[],"email":null},{"person_name":{"surname":"Chang","first_name":"M.-W"},"affiliations":[],"email":null},{"person_name":{"surname":"Lee","first_name":"K"},"affiliations":[],"email":null},{"person_name":{"surname":"Toutanova","first_name":"K"},"affiliations":[],"email":null}],"date":{"year":"2019","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"b18":{"title":"SpanBERT: Improving Pre-training by Representing and Predicting Spans","authors":[{"person_name":{"surname":"Joshi","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Chen","first_name":"D"},"affiliations":[],"email":null},{"person_name":{"surname":"Liu","first_name":"Y"},"affiliations":[],"email":null},{"person_name":{"surname":"Weld","first_name":"D"},"affiliations":[],"email":null},{"person_name":{"surname":"Zettlemoyer","first_name":"L"},"affiliations":[],"email":null},{"person_name":{"surname":"Levy","first_name":"O"},"affiliations":[],"email":null}],"date":{"year":"2019","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"Transactions of the Association for Computational Linguistics","series":null,"scope":{"volume":8,"pages":{"from_page":64,"to_page":77}}},"b19":{"title":"Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing","authors":[{"person_name":{"surname":"Gu","first_name":"Y"},"affiliations":[],"email":null},{"person_name":{"surname":"Tinn","first_name":"R"},"affiliations":[],"email":null},{"person_name":{"surname":"Cheng","first_name":"H"},"affiliations":[],"email":null},{"person_name":{"surname":"Lucas","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Usuyama","first_name":"N"},"affiliations":[],"email":null},{"person_name":{"surname":"Liu","first_name":"X"},"affiliations":[],"email":null},{"person_name":{"surname":"Naumann","first_name":"T"},"affiliations":[],"email":null},{"person_name":{"surname":"Gao","first_name":"J"},"affiliations":[],"email":null},{"person_name":{"surname":"Poon","first_name":"H"},"affiliations":[],"email":null}],"date":{"year":"2020","month":null,"day":null},"ids":{"DOI":null,"arXiv":"arXiv:2007.15779"},"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"b20":{"title":"jenojp/negspacy: Minor Bug Fix, Improve Chunk Prefix Functionality","authors":[{"person_name":{"surname":"Pizarro","first_name":"J"},"affiliations":[],"email":null},{"person_name":{"surname":"Reteig","first_name":"L"},"affiliations":[],"email":null},{"person_name":{"surname":"Murray","first_name":"L"},"affiliations":[],"email":null}],"date":{"year":"2020","month":null,"day":null},"ids":{"DOI":"10.5281/zenodo.3702544","arXiv":null},"target":"https://doi.org/10.5281/zenodo.3702544.doi:10.5281/zenodo.3702544","publisher":null,"journal":null,"series":null,"scope":null},"b21":{"title":"The BioScope Corpus: Biomedical Texts Annotated for Uncertainty, Negation and their Scopes","authors":[{"person_name":{"surname":"Vincze","first_name":"V"},"affiliations":[],"email":null},{"person_name":{"surname":"Szarvas","first_name":"G"},"affiliations":[],"email":null},{"person_name":{"surname":"Farkas","first_name":"R"},"affiliations":[],"email":null},{"person_name":{"surname":"Móra","first_name":"G"},"affiliations":[],"email":null},{"person_name":{"surname":"Csirik","first_name":"J"},"affiliations":[],"email":null}],"date":{"year":"2008","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"BMC Bioinformatics","series":null,"scope":{"volume":9,"pages":{"from_page":1,"to_page":9}}},"b22":{"title":"Cadec: A Corpus of Adverse Drug Event Annotations","authors":[{"person_name":{"surname":"Karimi","first_name":"S"},"affiliations":[],"email":null},{"person_name":{"surname":"Metke-Jimenez","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Kemp","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Wang","first_name":"C"},"affiliations":[],"email":null}],"date":{"year":"2015","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"Journal of Biomedical Informatics","series":null,"scope":{"volume":55,"pages":{"from_page":73,"to_page":81}}},"b23":{"title":"TwiMed: Twitter and PubMed Comparable Corpus of Drugs, Diseases, Symptoms, and Their Relations","authors":[{"person_name":{"surname":"Alvaro","first_name":"N"},"affiliations":[],"email":null},{"person_name":{"surname":"Miyao","first_name":"Y"},"affiliations":[],"email":null},{"person_name":{"surname":"Collier","first_name":"N"},"affiliations":[],"email":null}],"date":{"year":"2017","month":null,"day":null},"ids":{"DOI":"10.2196/publichealth.6396","arXiv":null},"target":"https://doi.org/10.2196/publichealth.6396.doi:10.2196/publichealth.6396","publisher":null,"journal":"JMIR Public Health Surveillance","series":null,"scope":{"volume":3,"pages":{"from_page":24,"to_page":24}}}},"sections":[{"title":"Introduction","paragraphs":[{"text":"As more users keep reporting their personal experience with drugs on social media, blogs and health forums, automatic Adverse Drug Event (ADE) detection in social media texts is becoming a fundamental tool in the field of pharmacovigilance [2,3]. It is common for Internet users to report their personal experiences with drugs on forums and microblogging platforms, but also messaging pharmaceutical companies directly on social media, via chatbots or emails. This is why both researchers and the industry are looking for ways to make use of this great amount of unprocessed and potentially informative data. User-generated texts, and social media texts in particular, are inherently noisy (containing colloquial language, slang and metaphors, non-standard syntactic constructions etc.) and require specialized data cleaning and handling techniques. The task becomes even more complicated if the final objective is to map them to a formal medical dictionary or ontology.","refs":[{"start":240,"end":243,"marker":"bibr","target":"#b1"},{"start":243,"end":245,"marker":"bibr","target":"#b2"}]},{"text":"In the last decade, the Natural Language Processing (NLP) community dedicated a consistent effort in developing robust methods for mining biomedical information from user-generated texts, also leading to the creation of several dedicated shared tasks series on ADE detection (SMM4H -Social Media Mining for Health) [4,5,6,7,8]. Although these models have seen great advancements in the last years, it is still unknown how robust they are in face of some pervasive linguistic phenomena such as negation and speculation. However, general investigations on machine comprehension and question answering tasks confirmed that such phenomena often pose a serious challenge [9]. The distinction between certain, hypothesized and negated and speculated events is of key importance in biomedical NLP tasks [10,11]. In the same way, it is essential to know whether the causal link between a drug and an ADE is being stated or negated in pharmacovigilance.","refs":[{"start":315,"end":318,"marker":"bibr","target":"#b3"},{"start":318,"end":320,"marker":"bibr","target":"#b4"},{"start":320,"end":322,"marker":"bibr","target":"#b5"},{"start":322,"end":324,"marker":"bibr","target":"#b6"},{"start":324,"end":326,"marker":"bibr","target":"#b7"},{"start":666,"end":669,"marker":"bibr","target":"#b8"},{"start":796,"end":800,"marker":"bibr","target":"#b9"},{"start":800,"end":803,"marker":"bibr","target":"#b10"}]},{"text":"Detecting the scope of negation and speculation has been object of NLP research for at least one decade, via both rule-based and machine learning approaches. An early, popular system was introduced by Chapman et al. [12], whose NegEx algorithm exploited regular expressions to identify negations in clinical documents in English. The latest advancements are represented by BERT-based models [13,14], also with the aid of multitask learning architectures [15].","refs":[{"start":216,"end":220,"marker":"bibr","target":"#b11"},{"start":391,"end":395,"marker":"bibr","target":"#b12"},{"start":395,"end":398,"marker":"bibr","target":"#b13"},{"start":454,"end":458,"marker":"bibr","target":"#b14"}]},{"text":"As of today, the research in biomedical NLP mostly focused on scope detection of negations and speculations per se and on more formal types of texts (e.g. clinical notes, articles). Given the growing demand to process and analyze large collections of user-generated content from social media, we choose to focus on ADE detection on Twitter posts. They are characterized by a noisier and more informal writing style. The goal is to enable to systems to be more successful at distinguishing between factual and non-factual information.","refs":[]},{"text":"In this paper, introduce an extended dataset to analyze the performance of ADE extraction in presence of asserted and negated Adverse Events. We show that the latest state-of-the-art ADE detection systems cannot recognize and handle negations correctly and introduce two strategies to increase the robustness of existing systems: (i) adding a negation detection module in a pipeline fashion to exclude the negated ADEs predicted by the models; (ii) augmenting the training set with artificially negated samples.","refs":[]}]},{"title":"Proposed Strategies","paragraphs":[{"text":"Following the latest advancements in the SMM4H Shared Tasks, we choose three Transformerbased models that showed high performance on the ADE extraction dataset of SMM4H [16,17]  and are currently at the top of the corresponding leaderboard: BERT [18], SpanBERT [19] and PubMedBERT [20]. The models are fine-tuned for token classification, predicting an IOB label for each token in the sentence to detect the boundaries of ADE mentions.","refs":[{"start":169,"end":173,"marker":"bibr","target":"#b15"},{"start":173,"end":176,"marker":"bibr","target":"#b16"},{"start":246,"end":250,"marker":"bibr","target":"#b17"},{"start":261,"end":265,"marker":"bibr","target":"#b18"},{"start":281,"end":285,"marker":"bibr","target":"#b19"}]},{"text":"We analyze two possible strategies to increase the robustness of the baseline models: (i) adding a negation (or speculation) detection module in a pipeline fashion to exclude some incorrect adverse events predicted by the models; (ii) augmenting the training set with artificially created samples. Figure 2 illustrates the two approaches.","refs":[{"start":305,"end":306,"marker":"figure","target":"#fig_1"}]}]},{"title":"Specialized negation detection modules","paragraphs":[{"text":"We propose a simple pipeline to enhance the robustness of the base models against negation by combining them with a negation detection module. Let us consider a text 𝑡, a ADE extraction base model ℬ and a negation detection module 𝒩 . Given 𝑡, ℬ outputs a set of substrings of 𝑡 that are labeled as ADE mentions: ℬ(𝑡) = {𝑏 1 , . . . , 𝑏 𝑚 }. Similarly, 𝒩 takes a text and outputs a set of substrings, which are considered to be entities within a negation scope: 𝒩 (𝑡) = {𝑛 1 , . . . , 𝑛 𝑡 }.","refs":[]},{"text":"A combined pipeline model is obtained by discarding all ADE spans 𝑏 𝑖 ∈ ℬ(𝑡) that overlap one of the negation spans 𝑛 𝑗 ∈ 𝒩 (𝑡): ℬ𝒩 (𝑡) = {𝑏 𝑖 ∈ ℬ(𝑡) | ∀𝑗(𝑛 𝑗 ∈ 𝒩 (𝑡) ∧ 𝑏 𝑖 ∩ 𝑛 𝑗 = ∅)} Modules used We introduce two negation detection modules: NegEx, a Python implementation [21] of the NegEx algorithm, based on simple regular expressions, which evaluates whether named entities are negated; BERTneg, a BERT model (bert-base-uncased) that we finetuned for token classification. We trained BERTneg on BioScope [22], which contains medical texts annotated for the presence of negation and speculation cues and their related scopes. We selected 3190 sentences (2801 with a negation scope) and finetuned the model for scope detection (10 epochs, learning rate 1𝑒 -4).","refs":[{"start":274,"end":278,"marker":"bibr","target":"#b20"},{"start":509,"end":513,"marker":"bibr","target":"#b21"}]}]},{"title":"Data Augmentation","paragraphs":[{"text":"While there are several datasets for ADE detection on social media texts [23,24], the largest collection is the one released yearly for the SMM4H Workshop and Shared Task.","refs":[{"start":73,"end":77,"marker":"bibr","target":"#b22"},{"start":77,"end":80,"marker":"bibr","target":"#b23"}]},{"text":"However, most datasets are made of samples that either do or do not contain an ADE (useful to train the Classification module in Figure 1). Because of this, they include a small number of negated ADEs by construction: no particular attention is given to these samples when curating the data and, even when they are present, they are labelled as noADE samples. This makes it harder to study this phenomenon.","refs":[{"start":136,"end":137,"marker":"figure","target":"#fig_0"}]},{"text":"We augment the SMM4H19 𝐸 dataset (the training set for the ADE extraction Task of SMM4H19 [7]) in two ways: (i) recovery of real samples; (ii) generating negated versions of real samples. Both activities were carried out by four volunteer annotators with a high level of proficiency in English.","refs":[{"start":90,"end":93,"marker":"bibr","target":"#b6"}]}]},{"title":"Recovery of real samples","paragraphs":[{"text":"We look for real samples that negate the presence of an ADE using SMM4H19 𝐶 and SMM4H20 𝐶 , the datasets for the binary classification tasks in [7] and [8]. These are meant to be used as test samples, to check the robustness of the model. Generation of negated samples We manually create negated versions for the ADE tweets in the test split of SMM4H19 𝐸 . These are meant to be used as additional training samples, to teach the model how to distinguish asserted and negated adverse events. The result of this procedure is a new set of tweets denying the presence of an ADE. As an example, the original tweet \"fluoxetine, got me going crazy\" was transformed into \"fluoxetine, didn't get me going crazy\".","refs":[{"start":144,"end":147,"marker":"bibr","target":"#b6"},{"start":152,"end":155,"marker":"bibr","target":"#b7"}]}]},{"title":"Data Partitioning","paragraphs":[{"text":"We split the available data in a train and a test set, both containing the three categories of tweets: ADE, noADE and negADE. Given the small amount of real negADE tweets, we use all of them in the test set to evaluate the performance only on real tweets. Conversely, the training set only contains the manually generated negADE samples.","refs":[]}]},{"title":"Experiments","paragraphs":[{"text":"All the reported results are the average over 5 runs. For the Transformer models we used the same hyperparameters reported by Portelli et al. [16]. As metrics, we consider the number of false positive predictions (FP) and the relaxed precision (P), recall (R) and F1 score as defined in the SMM4H shared tasks [7]: the scores take into account \"partial\" matches, in which it is sufficient for a prediction to partially overlap with the gold annotation. We report the number of FP both on the whole test set and on individual partitions (ADE, noADE and negADE samples). For brevity, here we report the results for just one of the baseline models (PubMedBERT, Table 1). Results for the other baseline models behave similarly and can be found in [1].","refs":[{"start":142,"end":146,"marker":"bibr","target":"#b15"},{"start":310,"end":313,"marker":"bibr","target":"#b6"},{"start":664,"end":665,"marker":"table","target":"#tab_1"},{"start":743,"end":746,"marker":"bibr","target":"#b0"}]},{"text":"As a preliminary step for all experiments, the two negation detection models are trained and used to predict the negation scopes for all the test samples once. This allows us to compute the predictions of any pipeline model. Exp 0 (row 1) To provide a measure of the initial robustness of the base models and their general performance, we train them on the ADE and noADE samples only. The base models have a high number of FP, especially in the negADE category. This strongly suggests that they are not robust against this phenomenon. Exp 1 (rows 2-3) We test the efficacy of the pipeline negation detection method, applying NegEx and BERTneg to the base models. When combined with NegEx (row 2), the FP decreases by almost 50 points, showing that the regular expression module removes a great number of unwanted predictions. BERTneg decreases the number of FP too, but only by 38 points, being less aggressive than NegEx. However, if we look at P and R in the first three rows, we see that the negation detection modules increase P at the cost of large drops in R: some correct predictions of the base models get discarded (i.e., ADEs that contain a negation such as \"After taking this drug I cannot sleep anymore\"). Exp 2 (row 4) We add to the training set all negADE generated samples and train the base models on them to test the effect of augmenting the dataset. This lowers the number of FP predictions for all models as much as using NegEx (compare row 2 and 4), especially on the negADE set. We still observe a drop in R, but less severe than in Exp 1 (less true positives are being discarded). The increase in P is also more noticeable, leading to an overall increase in F1. Exp 3 (rows 5-6) To investigate whether the two methods are complementary in their action, we combine the two strategies, applying the pipeline architecture to the models trained on the augmented dataset. They are in some way complementary, as shown by the further decrease in FP in all categories. However, combining the two approaches might not be the best strategy, as it leads to a further decrease in R.","refs":[]}]},{"title":"Observations","paragraphs":[{"text":"The results show that introducing a small number of new samples (even if artificial) is the best way to directly increase the model knowledge about the phenomenon. However, this solution could be expensive in absence of annotated data. For this reason, the pipeline models might be a viable alternative, as they maintain the F1 score while still decreasing the number of FP.","refs":[]}]}],"tables":{"tab_1":{"heading":"Table 1 P","description":", R, F1 score and number of False Positives (FP) for all the tested models.","rows":[["","","P","R","F1","FP","ADE noADE negADE"],["1","ℬ (base model)","53.24 67.41 59.47","144.2 37.0 40.4","67.4","1"],["2","ℬ+NegEx","59.21 59.76 59.47","93.4 32.0 37.6","23.8","2"],["3","ℬ+BERTneg","57.69 62.64 60.04","106.2 30.6 39.0","36.6","3"],["4","ℬ+negSamp","63.28 63.33 63.20","84.2 30.6 34.6","19.0","4"],["5","ℬ+NegEx +negSamp","63.24 58.29 60.58","76.6 29.4 34.6","12.6","5"],["6 ℬ+BERTneg +negSamp","64.74 60.98 62.72","74.2 27.2 34.2","12.8","6"]]}},"abstract":{"title":"Abstract","paragraphs":[{"text":"Adverse Drug Event (ADE) extraction from user-generated content has gained popularity as a tool to aid researchers and pharmaceutical companies to monitor side effect of drugs in the wild. Automatic models can rapidly examine large collections of social media texts. However it is currently unknown if such models are robust in face of linguistic phenomena such as negation and speculation, which are pervasive across language varieties. We evaluate three state-of-the-art systems, showing their fragility against negation, and then we introduce two possible strategies to increase the robustness of these models: (i) a pipeline approach, using a specific component for negation detection; (ii) an augmentation of the dataset with artificially negated samples to further train the models. We show that both strategies bring significant increases in performance.","refs":[]}]}}