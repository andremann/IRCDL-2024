{"bibliography":{"title":"A Streamlined Pipeline to Enable the Semantic Exploration of a Bookstore","authors":[{"person_name":{"surname":"Ceriani","first_name":"Miguel"},"affiliations":[{"department":null,"institution":"Sapienza Università di Roma","laboratory":null}],"email":"ceriani@diag.uniroma1.it"},{"person_name":{"surname":"Bernasconi","first_name":"Eleonora"},"affiliations":[{"department":null,"institution":"Sapienza Università di Roma","laboratory":null}],"email":"bernasconi@diag.uniroma1.it"},{"person_name":{"surname":"Mecella","first_name":"Massimo"},"affiliations":[{"department":null,"institution":"Sapienza Università di Roma","laboratory":null}],"email":"mecella@diag.uniroma1.it"}],"date":null,"ids":{"DOI":"10.1007/978-3-030-39905-4_8","arXiv":null},"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"keywords":["Semantic web","Pipeline","Semantic enrichment","Knowledge graph","Linked data","Book catalog"],"citations":{"b0":{"title":"An extension of SPARQL designed to map JSON or XML content to RDF","authors":[],"date":null,"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"b1":{"title":"Exploration and visualization in the web of big linked data: a survey of the state of the art","authors":[{"person_name":{"surname":"Bikakis","first_name":"N"},"affiliations":[],"email":null},{"person_name":{"surname":"Sellis","first_name":"T"},"affiliations":[],"email":null}],"date":{"year":"2016","month":null,"day":null},"ids":{"DOI":null,"arXiv":"arXiv:1601.08059"},"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"b2":{"title":"Yewno discover","authors":[{"person_name":{"surname":"Bolina","first_name":"M"},"affiliations":[],"email":null}],"date":{"year":"2019","month":null,"day":null},"ids":{"DOI":"10.15845/noril.v11i1.2772","arXiv":null},"target":"https://doi.org/10.15845/noril.v11i1.2772","publisher":null,"journal":"Nord. J. Inf. Lit. High. Educ","series":null,"scope":{"volume":11,"pages":null}},"b3":{"title":"RDF 1.1 concepts and abstract syntax","authors":[{"person_name":{"surname":"Cyganiak","first_name":"R"},"affiliations":[],"email":null},{"person_name":{"surname":"Wood","first_name":"D"},"affiliations":[],"email":null},{"person_name":{"surname":"Lanthaler","first_name":"M"},"affiliations":[],"email":null}],"date":{"year":"2014","month":"02","day":null},"ids":null,"target":"http://www.w3.org/TR/2014/REC-rdf11-concepts-20140225/","publisher":null,"journal":null,"series":null,"scope":null},"b4":{"title":"Approaches to visualising linked data: a survey","authors":[{"person_name":{"surname":"Dadzie","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Rowe","first_name":"M"},"affiliations":[],"email":null}],"date":{"year":"2011","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"Semant. Web","series":null,"scope":{"volume":2,"pages":{"from_page":89,"to_page":124}}},"b5":{"title":"SPARQL 1.1 query language","authors":[{"person_name":{"surname":"Harris","first_name":"S"},"affiliations":[],"email":null}],"date":{"year":"2013","month":"03","day":null},"ids":null,"target":"http://www.w3.org/TR/2013/REC-sparql11-query-20130321/","publisher":null,"journal":null,"series":null,"scope":null},"b6":{"title":"Information visualization and visual data mining","authors":[{"person_name":{"surname":"Keim","first_name":"D"},"affiliations":[],"email":null}],"date":{"year":"2002","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"IEEE Trans. Visual. Comput. Graph","series":null,"scope":{"volume":8,"pages":{"from_page":1,"to_page":8}}},"b7":{"title":"A SPARQL extension for generating RDF from heterogeneous formats","authors":[{"person_name":{"surname":"Lefrançois","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Zimmermann","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Bakerally","first_name":"N"},"affiliations":[],"email":null}],"date":{"year":"2017","month":null,"day":null},"ids":{"DOI":"10.1007/978-3-319-58068-5_3","arXiv":null},"target":"https://doi.org/10.1007/978-3-319-58068-5","publisher":"Springer","journal":null,"series":null,"scope":{"volume":10249,"pages":{"from_page":35,"to_page":50}}},"b8":{"title":"Survey of linked data based exploration systems","authors":[{"person_name":{"surname":"Marie","first_name":"N"},"affiliations":[],"email":null},{"person_name":{"surname":"Gandon","first_name":"F"},"affiliations":[],"email":null}],"date":{"year":"2014","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"b9":{"title":"A survey of named entity recognition and classification","authors":[{"person_name":{"surname":"Nadeau","first_name":"D"},"affiliations":[],"email":null},{"person_name":{"surname":"Sekine","first_name":"S"},"affiliations":[],"email":null}],"date":{"year":"2007","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"Lingvisticae Investigationes","series":null,"scope":{"volume":30,"pages":{"from_page":3,"to_page":26}}},"b10":{"title":"GLOBDEF: a framework for dynamic pipelines of semantic data enrichment tools","authors":[{"person_name":{"surname":"Nisheva-Pavlova","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Alexandrov","first_name":"A"},"affiliations":[],"email":null}],"date":{"year":"2019","month":null,"day":null},"ids":{"DOI":"10.1007/978-3-030-14401-2_15","arXiv":null},"target":"https://doi.org/10.1007/978-3-030-14401-215","publisher":"Springer","journal":null,"series":null,"scope":{"volume":846,"pages":{"from_page":159,"to_page":168}}},"b11":{"title":"Semantic web in data mining and knowledge discovery: a comprehensive survey","authors":[{"person_name":{"surname":"Ristoski","first_name":"P"},"affiliations":[],"email":null},{"person_name":{"surname":"Paulheim","first_name":"H"},"affiliations":[],"email":null}],"date":{"year":"2016","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"J. Web Semant","series":null,"scope":{"volume":36,"pages":{"from_page":1,"to_page":22}}},"b12":{"title":"Entity linking with a knowledge base: issues, techniques, and solutions","authors":[{"person_name":{"surname":"Shen","first_name":"W"},"affiliations":[],"email":null},{"person_name":{"surname":"Wang","first_name":"J"},"affiliations":[],"email":null},{"person_name":{"surname":"Han","first_name":"J"},"affiliations":[],"email":null}],"date":{"year":"2014","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"IEEE Trans. Knowl. Data Eng","series":null,"scope":{"volume":27,"pages":{"from_page":443,"to_page":460}}},"b13":{"title":"The eyes have it: a task by data type taxonomy for information visualizations","authors":[{"person_name":{"surname":"Shneiderman","first_name":"B"},"affiliations":[],"email":null}],"date":{"year":"1996","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":336,"to_page":343}}},"b14":{"title":"Machine readable web APIs with schema.org action annotations","authors":[{"person_name":{"surname":"Kärle","first_name":"U"},"affiliations":[],"email":null},{"person_name":{"surname":"Fensel","first_name":"E"},"affiliations":[],"email":null}],"date":{"year":"2018","month":null,"day":null},"ids":null,"target":null,"publisher":"Elsevier","journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":255,"to_page":261}}},"b15":{"title":"Linked data platform 1.0. W3C Recommendation 26","authors":[{"person_name":{"surname":"Speicher","first_name":"S"},"affiliations":[],"email":null},{"person_name":{"surname":"Arwe","first_name":"J"},"affiliations":[],"email":null},{"person_name":{"surname":"Malhotra","first_name":"A"},"affiliations":[],"email":null}],"date":{"year":"2015","month":"02","day":null},"ids":null,"target":"http://www.w3.org/TR/2015/REC-ldp-20150226/","publisher":null,"journal":null,"series":null,"scope":null}},"sections":[{"title":"Introduction","paragraphs":[{"text":"Searching in a library or book catalog is a recurrent task for researchers and common users alike. The search tools, once cumbersome physical file cabinets organized by author, topic, etc., are now usually web-based interfaces that allow more search flexibility and are globally accessible from any web-connected device. Nevertheless, the adopted search paradigm is still mainly the same one, albeit with the important addition of free-text search.","refs":[]},{"text":"In the last years, knowledge graphs gained broad adoption as a way of organizing and exploring a domain of knowledge. They organize information around concepts, which are connected to each other through semantic relationships. If these concepts are interpreted as topics, a knowledge graph is a rich way to organize a set of texts (or other media) by topic. The relationships between concepts (topics) are preserved and can be used to explore/search the corpus in ways that can go beyond the simple classification of media by topics.","refs":[]},{"text":"We propose a lightweight system that takes advantage of existing technologies to organize a library or book catalog through a knowledge graph with little upfront effort. A visual user interface allows the user to search and explore the graph as a way to access the book corpus. The pipeline is being experimented on the book catalog of an editor specialized in ancient Rome history.","refs":[]},{"text":"The rest of the paper is organized as follows. Section 2 analyses the related work, while Sects. 3 and 4 describe respectively the proposed system and used data models. Section 5 describes the implementation details and the concrete use case. Finally, Sect. 6 concludes and anticipates future work.","refs":[]}]},{"title":"Related Work","paragraphs":[{"text":"There has been a large amount of work in literature about visual information seeking [6,13]. Nevertheless, most of the work focus on how to explore and filter items classified by a homogeneous set of properties. For unstructured information like books, exploring and filtering by basic metadata (i.e., author, title, etc.) can be useful but it is often not sufficient. There has hence been recently a lot of research on how to attach semantics to unstructured data [11], through processes like named-entity recognition and linking (NERL) [9,12].","refs":[{"start":85,"end":88,"marker":"bibr","target":"#b6"},{"start":88,"end":91,"marker":"bibr","target":"#b13"},{"start":465,"end":469,"marker":"bibr","target":"#b11"},{"start":538,"end":541,"marker":"bibr","target":"#b9"},{"start":541,"end":544,"marker":"bibr","target":"#b12"}]},{"text":"Several software tools and research works deal with the issue of such semantic enrichments. Yewno Discover [2] is an integrated system that addresses similar challenges but does not offer flexibility, requiring the development of ad-hoc adjustments to build a specific pipeline. The GLOBDEF system [10] works with pluggable enhancement modules, which are dynamically activated to create onthe-fly pipelines for data enhancement, but it does not provide the management, integration, and visualization of the generated metadata. Apache Stanbol1 is a set of components able to offer various services for semantic enrichment, visualization of knowledge graph and the management of metadata. It is extremely useful and can be integrated with our system, but on itself, it does not offer a ready to use pipeline. Multiple user interfaces for visualization and exploration of knowledge graphs have been researched [1,4,8], but the question on how to effectively use these extracted semantics is still open.","refs":[{"start":107,"end":110,"marker":"bibr","target":"#b2"},{"start":298,"end":302,"marker":"bibr","target":"#b10"},{"start":541,"end":542,"marker":null,"target":"#foot_0"},{"start":907,"end":910,"marker":"bibr","target":"#b1"},{"start":910,"end":912,"marker":"bibr","target":null},{"start":912,"end":914,"marker":"bibr","target":null}]},{"text":"Although existing work deals with aspects of the pipeline proposed here, our system is novel in being designed from the ground up to offer knowledge graphbased access to an arbitrary corpus of texts. The mechanism of integration of semantic enrichment services, crucial for the adaptivity of the pipeline, is also novel, by being based on simple, actionable, semantic descriptions of the services. Finally, the user interface is novel in adopting visual linked data exploration as a means to search in a corpus of content, rather than just as an end in itself.","refs":[]}]},{"title":"Scenario and System","paragraphs":[{"text":"In the considered scenario, the responsible of a catalog of books (e.g., an editor or a library) wants to facilitate the search and exploration of its corpus through a specialized knowledge graph. The knowledge graph needs to integrate existing metadata, concepts associated with texts through semantic enriching processes, and relationships between the concepts. Both generic users and domain experts will be able to interact with the knowledge graph via a visual user interface or via programmatic interfaces which will enable advanced queries, transformations, and integration with further data sources.","refs":[]},{"text":"The proposed pipeline is shown in Fig. 1. In case of having access only to printed versions of some texts, those are first scanned and go through an OCR. The content of all the books is then stored in electronic form (e.g., PDFs), along with the relevant metadata, in a repository that supports the linked data container API, a standard RDF-based REST API [15]. This repository can be maintained by the catalog maintainers (e.g., editors or librarians) through a dedicated frontend application. It can also be directly connected with existing databases/systems for automatic content/metadata insertion/update. ","refs":[{"start":39,"end":40,"marker":"figure","target":null},{"start":356,"end":360,"marker":"bibr","target":"#b15"}]}]},{"title":"Fig. 1. The proposed pipeline","paragraphs":[{"text":"The content stored in that repository is analysed by some, possibly remote, semantic enrichment services (as NERL) that give as output some knowledge extracted from the content, possibly represented using existing models and knowledge graphs. To allow plugging diverse services, a component called service integration engine manages calling and integrating the desired web services based on a global integration configuration, which describes which services need to be called, and for each service a specific service description, which describes how to adapt it. While the integration configuration is maintained by experts for the specific pipeline, service descriptions are adapters of existing web services that could be developed by the maintainers of this pipeline as well as the service providers or third parties, favouring scalability of the system.","refs":[]},{"text":"Both the metadata coming from the repository (linked data container) and the extracted knowledge coming from the service integration engine are stored in a triple store, where they can be accessed either through the front end or directly through a SPARQL endpoint. The front end offers a multi-paradigm user interface, in which the knowledge graph visual exploration is coupled with a tabular exposition of the metadata of texts in the corpus (Fig. 2 shows a mockup). Offering the data in RDF format through SPARQL, enables advanced and unanticipated use of the data, through semantic web standards and tools.","refs":[{"start":449,"end":450,"marker":"figure","target":null}]}]},{"title":"Fig. 2. A mockup of the user interface 4 Data Models","paragraphs":[{"text":"RDF [3], the basic data model for linked data, is used to represent all the data items in the pipeline, adopting specific vocabularies or ontologies for each type of managed data. The standard query language for RDF, SPARQL [5], is used as a basis to define views and mappings. The structure of the PDF repository is represented thanks to the linked data platform vocabulary [15]. Basic metadata about the books are represented through the Dublin Core Metadata Element Set 2 .","refs":[{"start":4,"end":7,"marker":"bibr","target":"#b3"},{"start":224,"end":227,"marker":"bibr","target":"#b5"},{"start":375,"end":379,"marker":"bibr","target":"#b15"}]},{"text":"For the description of external services and basic mapping of the inputs/outputs, the actions descriptors from the schema.org 3 vocabulary are used, as proposed in [14], augmented by the use of the SPARQL Generate language 4 [7] to define non trivial mappings of the output. The semantic annotations (output of the semantic enrichment services) are represented using the Web Annotations Vocabulary 5 , which allows to associate properties to the annotation itself (e.g., reliability score) and to identify the exact portion(s) of text an annotation refers to. The annotations associate the text to concepts in some knowledge graph which may be topics (after named entity recognition and linking), moods (after sentiment analysis), etc. The knowledge graphs may adopt different data models.","refs":[{"start":164,"end":168,"marker":"bibr","target":"#b14"},{"start":225,"end":228,"marker":"bibr","target":"#b7"}]}]},{"title":"Implementation and Case Study","paragraphs":[{"text":"We are in the phase of implementing the whole pipeline. For each step, there are existing solutions we adopted or new components that we are developing. For the triple store we are using Blazegraph 6 , while for the content repository supporting LDP containers we use Fedora Commons 7 . The service integration engine is based on the SPARQL Generate engine 8 , which maps the JSON output of each web service to RDF. The web front end is developed using the React framework 9 for modularity, using the JS library Ontodia 10 for the knowledge graph visual user interface. For books that do no exist natively in electronic format, the scanned pages go through the OCR of the software ABBYY FineReader Pro 15 11 . For semantic enrichment, we are using the external entity extraction (NERL) web service offered by the Dandelion API 12 , which relates segments of the input text to resources in DBpedia, along with a confidence value. Nevertheless, given the flexibility of the service integration mechanism, the system is not tied to this specific service.","refs":[]},{"text":"The practical case study considered is to implement the idea for \"L'Erma di Bretschneider\", an Italian editor with around two thousands publications. \"L'Erma\" specializes in ancient history, especially ancient Rome history, and it is well-known in the field. The system is being tested on a selected catalog of 198 books, each of them containing from around two hundreds to seven hundreds pages and measuring from around one megabyte to 180 megabytes as PDFs. The user interface to the knowledge graph will be publicly available, in order to support the exploration of the catalog of books. The expected users falls in two main categories: casual users willing to explore the catalogue and knowledge on ancient Rome history; expert users that do research in the field and need support to explore and find books relevant to their research topic.","refs":[]}]},{"title":"Conclusions","paragraphs":[{"text":"This paper presented a concrete lightweight pipeline for enhancing access to a catalog of books through knowledge graph based exploration. The system is based on free software components and meant to be easily deployable for small-medium sized organizations that may not have the technical know-how and resources needed to build and maintain a specifically designed knowledge graph and software system. The development is still in progress but the design analysis and tests carried on so far indicate that the pipeline works without the need for custom coding and it appears useful to the target users. The presented case study will offer a context to thoroughly and formally evaluate the software. The evaluation will include a task oriented analysis as well as a holistic analysis of the impact of the tool on creative processes of research and personal enrichment.","refs":[]}]}],"tables":{},"abstract":{"title":"Abstract","paragraphs":[{"text":"Searching in a library or book catalog is a recurrent task for researchers and common users alike. Thanks to semantic enrichment techniques, such as named-entity recognition and linking, texts may be automatically associated with entities in some reference knowledge graph(s). The association of a corpus of texts with a knowledge graph opens up the way to searching/exploring using novel paradigms. We present a pipeline that uses semantic enrichment and knowledge graph visualization techniques to enable the semantic exploration of an existing text corpus. The pipeline is meant to be ready for use and consists of existing free software tools and free software code contributed by us. We are developing and testing the pipeline on the field, by using it to access the catalog of a bookstore specialized in ancient Rome history.","refs":[]}]}}