{"bibliography":{"title":"A Preliminary Assessment of the Article Deduplication Algorithm Used for the OpenAIRE Research Graph","authors":[{"person_name":{"surname":"Vichos","first_name":"Kleanthis"},"affiliations":[{"department":null,"institution":"ATHENA RC","laboratory":null}],"email":null},{"person_name":{"surname":"De Bonis","first_name":"Michele"},"affiliations":[{"department":"Istituto di Scienza e Tecnologie dell'Informazione","institution":"National Research Council","laboratory":null}],"email":null},{"person_name":{"surname":"Kanellos","first_name":"Ilias"},"affiliations":[{"department":null,"institution":"ATHENA RC","laboratory":null}],"email":null},{"person_name":{"surname":"Chatzopoulos","first_name":"Serafeim"},"affiliations":[{"department":null,"institution":"ATHENA RC","laboratory":null}],"email":null},{"person_name":{"surname":"Atzori","first_name":"Claudio"},"affiliations":[{"department":"Istituto di Scienza e Tecnologie dell'Informazione","institution":"National Research Council","laboratory":null}],"email":null},{"person_name":{"surname":"Manola","first_name":"Natalia"},"affiliations":[{"department":null,"institution":"OpenAIRE","laboratory":null}],"email":null},{"person_name":{"surname":"Manghi","first_name":"Paolo"},"affiliations":[{"department":"Istituto di Scienza e Tecnologie dell'Informazione","institution":"National Research Council","laboratory":null},{"department":null,"institution":"OpenAIRE","laboratory":null}],"email":null},{"person_name":{"surname":"Vergoulis","first_name":"Thanasis"},"affiliations":[{"department":null,"institution":"ATHENA RC","laboratory":null}],"email":null}],"date":null,"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":null},"keywords":["Scholarly data","Open science","Deduplication","Knowledge graphs"],"citations":{"b0":{"title":"Open science: one term, five schools of thought","authors":[{"person_name":{"surname":"Fecher","first_name":"B"},"affiliations":[],"email":null},{"person_name":{"surname":"Friesike","first_name":"S"},"affiliations":[],"email":null}],"date":{"year":"2014","month":null,"day":null},"ids":null,"target":null,"publisher":"Springer","journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":17,"to_page":47}}},"b1":{"title":"The data model of the openaire scientific communication e-infrastructure","authors":[{"person_name":{"surname":"Manghi","first_name":"P"},"affiliations":[],"email":null},{"person_name":{"surname":"Houssos","first_name":"N"},"affiliations":[],"email":null},{"person_name":{"surname":"Mikulicic","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Jörg","first_name":"B"},"affiliations":[],"email":null}],"date":{"year":"2012","month":null,"day":null},"ids":null,"target":null,"publisher":"Springer","journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":168,"to_page":180}}},"b2":{"title":"Open research knowledge graph: next generation infrastructure for semantic scholarly knowledge","authors":[{"person_name":{"surname":"Jaradeh","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Oelen","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Farfar","first_name":"K"},"affiliations":[],"email":null},{"person_name":{"surname":"Prinz","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Souza","first_name":"J"},"affiliations":[],"email":null},{"person_name":{"surname":"Kismihók","first_name":"G"},"affiliations":[],"email":null},{"person_name":{"surname":"Stocker","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Auer","first_name":"S"},"affiliations":[],"email":null}],"date":{"year":"2019","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":243,"to_page":246}}},"b3":{"title":"Microsoft Academic Graph: When experts are not enough","authors":[{"person_name":{"surname":"Wang","first_name":"K"},"affiliations":[],"email":null},{"person_name":{"surname":"Shen","first_name":"Z"},"affiliations":[],"email":null},{"person_name":{"surname":"Huang","first_name":"C"},"affiliations":[],"email":null},{"person_name":{"surname":"Wu","first_name":"C.-H"},"affiliations":[],"email":null},{"person_name":{"surname":"Dong","first_name":"Y"},"affiliations":[],"email":null},{"person_name":{"surname":"Kanakia","first_name":"A"},"affiliations":[],"email":null}],"date":{"year":"2020","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"QSS","series":null,"scope":{"volume":1,"pages":{"from_page":396,"to_page":413}}},"b4":{"title":"Entity deduplication in big data graphs for scholarly communication","authors":[{"person_name":{"surname":"Manghi","first_name":"P"},"affiliations":[],"email":null},{"person_name":{"surname":"Atzori","first_name":"C"},"affiliations":[],"email":null},{"person_name":{"surname":"Bonis","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Bardi","first_name":"A"},"affiliations":[],"email":null}],"date":{"year":"2020","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"Data Technologies and Applications","series":null,"scope":null},"b5":{"title":"The journal coverage of web of science and scopus: a comparative analysis","authors":[{"person_name":{"surname":"Mongeon","first_name":"P"},"affiliations":[],"email":null},{"person_name":{"surname":"Paul-Hus","first_name":"A"},"affiliations":[],"email":null}],"date":{"year":"2016","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"Scientometrics","series":null,"scope":{"volume":106,"pages":{"from_page":213,"to_page":228}}},"b6":{"title":"Dimensions: building context for search and evaluation","authors":[{"person_name":{"surname":"Hook","first_name":"D"},"affiliations":[],"email":null},{"person_name":{"surname":"Porter","first_name":"S"},"affiliations":[],"email":null},{"person_name":{"surname":"Herzog","first_name":"C"},"affiliations":[],"email":null}],"date":{"year":"2018","month":null,"day":null},"ids":null,"target":null,"publisher":null,"journal":"Frontiers in Research Metrics and Analytics","series":null,"scope":{"volume":3,"pages":{"from_page":23,"to_page":23}}},"b7":{"title":"Crossref: The sustainable source of communityowned scholarly metadata","authors":[{"person_name":{"surname":"Hendricks","first_name":"G"},"affiliations":[],"email":null},{"person_name":{"surname":"Tkaczyk","first_name":"D"},"affiliations":[],"email":null},{"person_name":{"surname":"Lin","first_name":"J"},"affiliations":[],"email":null},{"person_name":{"surname":"Feeney","first_name":"P"},"affiliations":[],"email":null}],"date":{"year":"2020","month":null,"day":null},"ids":{"DOI":"10.1162/qss_a_00022","arXiv":null},"target":null,"publisher":null,"journal":null,"series":null,"scope":{"volume":1,"pages":{"from_page":414,"to_page":427}}},"b8":{"title":"The openaire research community dashboard: on blending scientific workflows and scientific publishing","authors":[{"person_name":{"surname":"Baglioni","first_name":"M"},"affiliations":[],"email":null},{"person_name":{"surname":"Bardi","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Kokogiannaki","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Manghi","first_name":"P"},"affiliations":[],"email":null},{"person_name":{"surname":"Iatropoulou","first_name":"K"},"affiliations":[],"email":null},{"person_name":{"surname":"Principe","first_name":"P"},"affiliations":[],"email":null},{"person_name":{"surname":"Vieira","first_name":"A"},"affiliations":[],"email":null},{"person_name":{"surname":"Nielsen","first_name":"L"},"affiliations":[],"email":null},{"person_name":{"surname":"Dimitropoulos","first_name":"H"},"affiliations":[],"email":null},{"person_name":{"surname":"Foufoulas","first_name":"I"},"affiliations":[],"email":null}],"date":{"year":"2019","month":null,"day":null},"ids":null,"target":null,"publisher":"Springer","journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":56,"to_page":69}}},"b9":{"title":"Gdup: De-duplication of scholarly communication big graphs","authors":[{"person_name":{"surname":"Atzori","first_name":"C"},"affiliations":[],"email":null},{"person_name":{"surname":"Manghi","first_name":"P"},"affiliations":[],"email":null},{"person_name":{"surname":"Bardi","first_name":"A"},"affiliations":[],"email":null}],"date":{"year":"2018","month":null,"day":null},"ids":null,"target":null,"publisher":"IEEE","journal":null,"series":null,"scope":{"volume":null,"pages":{"from_page":142,"to_page":151}}}},"sections":[{"title":"Introduction","paragraphs":[{"text":"In recent years, large amounts of scholarly data have become openly available due to the increased popularity of the Open Science [1] initiatives. This abundance of scholarly content is really important since it catalyzes the creation and provision of several added value services that can facilitate scientific knowledge discovery, as well as research assessment and monitoring. In most cases, the scholarly content is published in the form of Scholarly Knowledge Graphs (SKGs). Knowledge graphs are heterogeneous graphs (i.e., having multiple node and edge types) capable of representing the semantics of complex knowledge spaces; this makes them attractive for the case of scholarly data, since this domain consists of many entities (e.g., articles, researchers, venues, software, datasets) which are highly interconnected with different types of relationships.","refs":[{"start":130,"end":133,"marker":"bibr","target":"#b0"}]},{"text":"Several SKGs have been produced in recent years either from the academic community (e.g., the OpenAIRE Research Graph [2], the Open Research Knowledge Graph [3]) or industry-driven IRCDL 2022: 18th Italian Research Conference on Digital Libraries, February 24-25, 2022, Padova, Italy kvichos@athenarc.gr (K. Vichos); michele.debonis@isti.cnr.it (M. De Bonis); ilias.kanellos@athenarc.gr (I. Kanellos); schatz@athenarc.gr (S. Chatzopoulos); claudio.atzori@isti.cnr.it (C. Atzori); natalia.manola@openaire.eu (N. Manola); paolo.manghi@openaire.eu (P. Manghi); vergoulis@athenarc.gr (T. Vergoulis) https://schatzopoulos.github.io/ (S. Chatzopoulos); http://thanasis-vergoulis.com/ (T. Vergoulis) 0000-0002-8955-9489 (K. Vichos); 0000-0003-2347-6012 (M. De Bonis); 0000-0003-1714-5225 (S. Chatzopoulos); 0000-0001-9613-6639 (C. Atzori); 0000-0001-7291-3210 (P. Manghi); 0000-0003-0555-4128 (T. Vergoulis) ones (e.g., the Microsoft Academic Graph [4]). Such initiatives strive to gather, clean, and integrate content from different and diverse data sources (e.g., libraries, publication repositories, publishers, etc) and assemble graphs whose nodes represent articles, datasets, researchers, etc. At the same time, scholarly content is inherently heterogeneous, comprising a variety of research object types and (meta-) data in diverse formats, curation levels, and even languages. In addition, best practices and standard procedures in research vary across disciplines, while the entities of interest are usually domain-specific. This heterogeneity in scholarly content is a major impediment to the acquisition, integration, and interlinking of content from different sources leading to disruptive duplication rates. Consequently, the developing teams of SKGs have implemented fully-fledged entity deduplication workflows for their needs.","refs":[{"start":118,"end":121,"marker":"bibr","target":"#b1"},{"start":157,"end":160,"marker":"bibr","target":"#b2"},{"start":942,"end":945,"marker":"bibr","target":"#b3"}]},{"text":"In this work, we conduct a preliminary evaluation of the effectiveness of the deduplication process currently used for the creation and update of the OpenAIRE Research Graph [2], one of the most widely known community-driven SKGs. Although the current process (to which we refer as fDup-2021) is based on gDup, a framework that has been introduced in a previous work [5], there are no hitherto experiments to assess its accuracy (or the accuracy of any other instance of gDup). Apart from the assessment of the particular gDup instance, another contribution of our work is the creation of a new curated dataset that contains expert judgements regarding the equivalence (or not) of research objects. This dataset can be useful for assessing the accuracy of other instances of the gDup framework, but also as a set of expert validated equivalent objects, each having its unique digital object identifier (DOI).","refs":[{"start":174,"end":177,"marker":"bibr","target":"#b1"},{"start":367,"end":370,"marker":"bibr","target":"#b4"}]}]},{"title":"Background & Related Work","paragraphs":[]},{"title":"Scholarly Knowledge Graphs (SKGs)","paragraphs":[{"text":"One of the most popular approaches for scientific knowledge representation is that of Scientific/Scholarly Knowledge Graphs (SKGs), many of which have been developed as industrydriven initiatives, such as the Web of Science (WoS) [6], Microsoft Academic Graph (MAG) [4], and Dimensions [7]. Among academic or non-profit initiatives, Crossref [8] is probably the largest source of scholarly metadata supporting 13 major content types (e.g., articles, datasets, peer reviews). The OpenAIRE Research Graph [2] encompasses scholarly metadata of a large variety and empowers the EOSC resource catalogue. Moreover, the Open Research Knowledge Graph (ORKG) [3] describes research papers in a structured manner. Finally, OurResearch has lately developed and released OpenAlex, a large scholarly dataset that attempts to cover the gap created by the discontinuation of MAG by the end of 2021.","refs":[{"start":230,"end":233,"marker":"bibr","target":"#b5"},{"start":266,"end":269,"marker":"bibr","target":"#b3"},{"start":286,"end":289,"marker":"bibr","target":"#b6"},{"start":342,"end":345,"marker":"bibr","target":"#b7"},{"start":503,"end":506,"marker":"bibr","target":"#b1"},{"start":650,"end":653,"marker":"bibr","target":"#b2"}]}]},{"title":"The OpenAIRE Research Graph","paragraphs":[{"text":"The OpenAIRE infrastructure1 is an initiative and Legal Entity whose purpose is to facilitate, foster and support Open Science in Europe. Among others, OpenAIRE supports the technical services that facilitate and monitor Open Science publishing trends. To this end, the OpenAIRE service infrastructure consists of metadata aggregation services and information inference services whose purpose is to populate the OpenAIRE Research Graph [2]. The graph's data model is depicted in Figure 1 and its main entities are described below:","refs":[{"start":27,"end":28,"marker":null,"target":"#foot_0"},{"start":436,"end":439,"marker":"bibr","target":"#b1"},{"start":486,"end":487,"marker":"figure","target":"#fig_0"}]},{"text":"• Research Products represent the outcomes of research activities.","refs":[]},{"text":"• Organizations correspond to companies or research institutions involved in projects, responsible for operating data sources or consisting the affiliations of Product creators. • Funders (e.g. EC, Wellcome Trust) are agencies responsible for a list of Funding Streams.","refs":[]},{"text":"• Funding Streams represent investments (funding actions) from Funders (e.g. FP7 or H2020).","refs":[]},{"text":"• Projects are research projects funded by a Funding Stream of a Funder.","refs":[]},{"text":"• Data Sources are the resources used to collect metadata for the graph objects.","refs":[]},{"text":"On top of the graph, OpenAIRE offers various services, such as a search and exploration portal and a number of dashboards (the Research Community Dashboard [9], the Funder Dashboard, etc.). Deduplication of products and organizations is therefore crucial to deliver meaningful statistics to the users. In addition, since all data are open by design, it is crucial for any added value services built on top of OpenAIRE's data, as well.","refs":[{"start":156,"end":159,"marker":"bibr","target":"#b8"}]}]},{"title":"OpenAIRE's deduplication framework","paragraphs":[{"text":"The entire deduplication process used to materialize the final version of the OpenAIRE Research Graph is managed by the gDup framework [5,10]. gDup is an integrated, scalable, generalpurpose system for entity deduplication over big SKGs. It supports practitioners with the typical functionalities needed to realize a full entity deduplication workflow over a generic input graph. The deduplication workflow of gDup (Figure 2) consists of the following main phases:","refs":[{"start":135,"end":138,"marker":"bibr","target":"#b4"},{"start":138,"end":141,"marker":"bibr","target":"#b9"},{"start":423,"end":424,"marker":"figure","target":"#fig_1"}]},{"text":"• Collection import: it loads the collection to be processed, by defining a set of labels (custom names) and values (extracted from the original entity). • Candidate identification: a preliminary grouping stage to divide the input space into smaller clusters, leveraging the object's DOI and title. • Duplicates identification: it involves intra-cluster pair-wise comparisons between entities;","refs":[]},{"text":"the number of comparisons is reduced using a sliding window mechanism after ordering the entities so that potentially equivalent entities will be in the same window. • Duplicates grouping: the final operation that creates representative objects and persistent identifiers for the newly created records.","refs":[]},{"text":"Of course, the similarity function used to compare pairs of entities should be able to capture record equivalence and should be flexible and configurable for every different entity type. In gDup, the similarity function was defined by a weighted sum of the similarity scores between entity attributes, while a set of conditions that implement early exits in the comparison have been defined. To make this task smarter, gDup was extended to a new framework, called fDup, which introduces a decision tree mechanism which enables early exits and different similarity match strategies based on intermediate results of the comparisons between entity attributes. The mechanism considers the Levenshtein distance (normalized to obtain a value between 0very different -and 1 -identical) of the entity titles to determine if two entities are equivalent or not. A threshold depending on the number of common IDs is applied to the similarity score: in case the entities have common IDs, the threshold on the score is lower than the other case (0.9 vs. 0.99). This means that a higher similarity score of the title is needed if two entities do not share IDs. In the last case, a further comparison on the title version (i.e. numbers in the title string) and the author lists is performed to guarantee the correct result. If the entities have different versions in the title and different sizes of author lists, the early exit tells that there is no need to compute the Levenshtein distance as the two entities are considered to be different. This specific deduplication configuration is currently used as the OpenAIRE's deduplication algorithm and it will be referred in the following as fDup-2021.","refs":[]}]},{"title":"Evaluation","paragraphs":[{"text":"In this section we elaborate on our assessment process to evaluate the accuracy of the fDup-2021 algorithm in identifying DOIs that correspond to equivalent objects (i.e., closely related entities). Our experiments can be divided into two groups: first we compare fDup-2021's output to sets of known DOI aliases (Section 3.1) and, then, we further investigate those fDup-2021's equivalent objects that do not correspond to known aliases (Section 3.2).","refs":[]}]},{"title":"Quantifying fDup-2021's false negatives using DOI aliases","paragraphs":[{"text":"To perform a preliminary analysis on the quality of the output of fDup-2021, in our first experiment, we leveraged information from doi.org's REST API2 regarding DOI aliases. Reporting DOI aliases is the default mechanism for registrants of DOIs to report duplicate DOIs 3 . Since not all duplicates are reported by the respective registrants, DOI aliases cannot be used to quantify the false positives that DOI deduplication algorithms produce. However, any DOIs that have been reported as aliases are guaranteed to refer to equivalent objects, hence they can be used as a ground truth to quantify false negatives and this is how we leveraged them in this experiment.","refs":[{"start":150,"end":151,"marker":null,"target":"#foot_1"},{"start":271,"end":272,"marker":null,"target":"#foot_2"}]},{"text":"Since gathering the aliases for all distinct DOIs in the OpenAIRE Research Graph (>120M) is a time-consuming process (especially, if the implemented process makes responsible usage of the API respecting request limits), we decided to restrict our analysis only to those DOIs that are reported to have at least one equivalent DOI according to the fDup-2021 algorithm (a more complete evaluation is planned for an extension of the current work). Our snapshot of the graph (produced on October 26th, 2021) contained 112 216 333 distinct deduplicated entries (i.e., distinct OpenAIRE IDs) in total, 5 885 861 of which contained at least two equivalent DOIs. Using doi.org's REST API we gathered all the aliases of the respective distinct DOIs (14 427 982 in total) and generated the corresponding groups of DOI aliases. It should be noted that 6 185 of the DOIs of the graph were problematic, i.e., unresolvable at the time of data gathering. 4We, then, compared these sets of aliases with the sets of equivalent entries provided by fDup-2021. During this comparison, we ignored all unresolvable DOIs (i.e., the analysis was performed using the rest). A summarisation of the results is presented in Table 1. In particular, we found that a lot of fDup-2021's deduplicated entries (32 476) were completely compliant with the list of known aliases (i.e., were confirmed true positives). Also 1 100 of the entries could be considered as false negatives, since they did not contain even one known alias. However, the vast majority of the deduplicated entries were containing groups of known aliases (hence, implying missing aliases or false positives). Finally, only a negligible number of the deduplicated entries contained only unresolvable DOIs.","refs":[{"start":939,"end":940,"marker":null,"target":"#foot_3"},{"start":1201,"end":1202,"marker":"table","target":"#tab_0"}]},{"text":"It is evident that fDup-2021 produces a very small number of confirmed false negatives (they account for less than 0.02% of the examined entries). In addition, it seems that fDup-2021 identifies a very large number of equivalent DOIs which are not reported as aliases in doi.org. In the next section, we attempt to determine whether this can be mainly attributed to a large number of false positives, or if a huge number of equivalent DOIs are not reported as aliases.","refs":[]}]},{"title":"Investigating reported equivalent objects with no DOI aliases","paragraphs":[{"text":"In this experiment, we further investigated fDup-2021's deduplicated entries that involve sets of DOIs that have not been reported as aliases (line 3 in Table 1). Our main objective was to get insights about the scale of false positives in fDup-2021's output. The only way to fulfil this objective is to have expert judgements on the sets of equivalent objects that the deduplication algorithm produces. The experts use DOI-related metadata and the corresponding content (e.g., the manuscript in case of publications) and provide judgements regarding the correctness of the algorithm output (i.e., if the reported DOIs correspond to equivalent objects or not). We followed this approach assigning the respective task to 4 experts (computer engineers, two of them PhDs). However, since the manual inspection is time consuming and the data to be examined is immense (more than 5.8M entries), we opted to assign a sample of 300 randomly selected entries per expert, resulting in a dataset of 1 200 entries. Each expert was given the task of assigning each set of equivalent DOIs with one of 8 predetermined class labels (Table 2). DOIs once pointing to the same research object, currently deleted.","refs":[{"start":159,"end":160,"marker":"table","target":"#tab_0"},{"start":1124,"end":1125,"marker":"table","target":"#tab_1"}]}]},{"title":"True multi-published","paragraphs":[{"text":"Article published in more than one locations (full or abstract).","refs":[]}]},{"title":"Versions","paragraphs":[{"text":"Multiple versions of the same research object (e.g. pre-prints, post-prints etc).","refs":[]}]},{"title":"Erroneous","paragraphs":[{"text":"Unrelated set of objects.","refs":[]}]},{"title":"False paper-extensions","paragraphs":[{"text":"Extended version of a conference paper in a journal.","refs":[]}]},{"title":"Part-of-a-group","paragraphs":[{"text":"Multiple parts of the same research object (e.g., photos of the same collection).","refs":[]}]},{"title":"Supplementary","paragraphs":[{"text":"Article and its supplementary material (including errata).","refs":[]},{"text":"Each of the classes has particular semantics, explained in the 'Interpretation' column. These semantics determine whether the objects in the respective group are equivalent or not ('Judgement' column). The dataset that has been generated by the aforementioned process, was made openly available on Zenodo5 under CC-BY license.","refs":[{"start":304,"end":305,"marker":null,"target":"#foot_4"}]},{"text":"Figure 3a illustrates the proportion of deduplicated entries that have been annotated with each of the classes, while Figure 3b summarises the proportion of true and false positives; due to the existence of the AMBIGUOUS class, there were also a lot of entries for which it was not possible to provide a judgement (denoted by 'N/A' in Figure 3). It is evident that the majority of deduplicated entries (64.9%) produced by fDup-2021 are correct; most of them contain different versions of the same object and extensions of older works. The false positives, on the other hand, correspond to a significantly smaller percentage (23%).","refs":[{"start":7,"end":9,"marker":"figure","target":"#fig_3"},{"start":125,"end":127,"marker":"figure","target":"#fig_3"},{"start":342,"end":343,"marker":"figure","target":"#fig_3"}]}]},{"title":"Discussion","paragraphs":[{"text":"Our main findings can be summarized as follows: deduplication algorthims are useful and bring significant added-value; this is highlighted by the fact that manually curated collections (like the DOI aliases) fail to report a large number of true positive equivalent objects. Specifically, for more than 5.8M sets of equivalent objects (according to fDup-2021) there is no reported DOI alias. Furthermore, fDup-2021 has adequate results, producing a lot of useful true positives; however, there is room for improvements since the proportion of false positives is relatively large. This is   expected since fDup-2021 is fairly inclusive (favoring false positives instead of false negatives). Some common errors were related to the fact that the algorithm is oblivious of the author lists, grouping together articles of different authors having the same title. Another common mistake was that it could not distinguish between main articles and their supplementary materials.","refs":[]},{"text":"It is worth noting that this work contains a preliminary analysis on this subject. Our analysis has important limitations. For instance, for efficiency reasons, we used only deduplicated entries with at least two equivalent objects for our analysis. To alleviate this issue, more time is required to collect the DOI alias info from doi.org's REST API; we plan it as an extension of the current work along with extending our ground truth that currently consists of 1 200 expert judgements.","refs":[]}]},{"title":"Conclusions & Future Work","paragraphs":[{"text":"In this work, we conducted a preliminary assessment on the effectiveness of fDup-2021, the deduplication process used for the creation and update of the OpenAIRE Research Graph. The main contributions of our work were the following: we explain why DOI deduplication algorithms are important; we introduce a ground truth dataset that can be used for the assessment of deduplication processes for Scholarly Knowledge Graphs (SKGs) and leveraged it to perform a first assessment of fDup-2021, providing insights on its major weaknesses. In the future we plan to perform more thorough experiments to confirm the results of the current study and we aim to design an improved instance of the gDup framework that alleviates all identified issues.","refs":[]}]}],"tables":{"tab_0":{"heading":"Table 1","description":"Statistics for the various types of fDup-2021's deduplicated entries.","rows":[["Types of deduplicated entries","# of entries"],["Completely matching sets of aliases (true positives)","32 476"],["Involving unreported aliases (false negatives)","1 100"],["Not compliant to aliases (false positives or missing aliases)","5 852 174"],["Containing only unresolvable DOIs","111"]]},"tab_1":{"heading":"Table 2","description":"Annotation classes.","rows":[["Name","Interpretation","Judgement"],["AMBIGUOUS","At least one DOIs is invalid (no metadata are available).","N/A"],["DELETED-DUPLICATES","",""]]}},"abstract":{"title":"Abstract","paragraphs":[{"text":"In recent years, a large number of Scholarly Knowledge Graphs (SKGs) have been introduced in the literature. The communities behind these graphs strive to gather, clean, and integrate scholarly metadata from various sources to produce clean and easy-to-process knowledge graphs. In this context, a very important task of the respective cleaning and integration workflows is deduplication. In this paper, we briefly describe and evaluate the accuracy of the deduplication algorithm used for the OpenAIRE Research Graph. Our experiments show that the algorithm has an adequate performance producing a small number of false positives and an even smaller number of false negatives.","refs":[]}]}}